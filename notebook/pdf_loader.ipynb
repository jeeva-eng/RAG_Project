{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8320ee4c",
   "metadata": {},
   "source": [
    "#### RAG Pipelines - Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f5a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader,PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3395aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 PDF files to process\n",
      "\n",
      " Processing:Cross Validation.pdf\n",
      " Loaded 12 pages\n",
      "\n",
      " Processing:Data Modelling.pdf\n",
      " Loaded 19 pages\n",
      "\n",
      " Processing:DBMS.pdf\n",
      " Loaded 7 pages\n",
      "\n",
      " Processing:ML Notes.pdf\n",
      " Loaded 47 pages\n",
      "\n",
      " Total documents loaded:85\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents=[]\n",
    "    pdf_dir=Path(pdf_directory)\n",
    "\n",
    "    ### Find all PDF files recursively\n",
    "    pdf_files=list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\n Processing:{pdf_file.name}\")\n",
    "        try:\n",
    "            loader=PyPDFLoader(str(pdf_file))\n",
    "            documents=loader.load()\n",
    "\n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file']=pdf_file.name\n",
    "                doc.metadata['file_type']='pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\" Loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error:{e}\")\n",
    "    print(f\"\\n Total documents loaded:{len(all_documents)}\")\n",
    "    return all_documents     \n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "\n",
    "all_pdf_documents=process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61e810ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n \\n \\nUNIT V       DESIGN AND ANALYSIS OF MACHINE LEARNING EXPERIMENTS         8 \\nGuidelines for machine learning experiments, Cross Validation (CV) and resampling â€“ K- \\nfold CV, bootstrapping, measuring classifier performance, assessing a single classification \\nalgorithm and comparing two classification algorithms â€“ t test, Mc Nemarâ€™s test, K -fold \\nCV paired t test \\n \\n5.1 Guidelines for Machine Learning Experiments \\n \\nThe steps in machine learning are the same as for any type of \\nexperimentation, that at this point, it is  not important whether the task  \\nis classiï¬cation or regression, or whether it is an unsupervised or a  \\nreinforcement learning application. The same overall discussion \\napplies; the diï¬€erence is only in the sampling distribu- tion of the \\nresponse data that is collected. \\n \\nA. Aim of the Study \\nGiven two learning algorithms and a particular problem as deï¬ned  \\nbya dataset, we may want to determine which one has less generalization \\nerror. These can be two diï¬€erent algorithms, or one can be a proposed  \\nimprovement of the other, for example, by using a better feature extrac - \\ntor.In the general case, we may have more than two learning algorithms,  \\nand we may want to choose the one with the least error, or order them in \\nterms of error, for a given dataset.In an even more general setting, instead  of \\non a single dataset, we may want to compare two or more algorithms  on \\ntwo or more datasets. \\n \\nB. Selection of the Response Variable \\nWe need to decide on what we should use as the quality measure.  \\nMost frequently, error is used that is the misclassiï¬cation error for \\nclassiï¬ca- tion and mean square error for regression. We may also use  \\nsome variant;for example, generalizing from 0/1 to an arbitrary  loss, we \\nmay use a riskmeasure. In information retrieval, we use measures such as \\nprecision andrecall. In a cost-sensitive setting, not only the output but also \\nsystem parameters, for example, its complexity, are taken into account. \\n \\nC. Choice of Factors and Levels \\nWhat the factors are depend on the aim of the study. If we ï¬x an  \\nal- gorithm and want to ï¬nd the best hyperparameters,  then those are \\nthe factors. If we are comparing algorithms, the learning algorithm is a  \\nfac-tor. If we have diï¬€erent datasets, they also become a factor. \\nThe levels of a factor should be carefully chosen so as not to miss a'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ngood conï¬guration and avoid doing unnecessary experimentation. It is  \\nalways good to try to normalize factor levels. For example, in optimizing  \\nk of k-nearest neighbor, one can try values such as 1, 3, 5, and so on, but  \\nin optimizing the spread h of Parzen windows, we should not try absolute  \\nvalues such as 1.0, 2.0, and so on, because that depends on the scale of  \\nthe input; it is better to ï¬nd some statistic that is an indicator of scale â€” \\nfor example, the average distance between an instance and its nearest  \\nneighborâ€”and try h as diï¬€erent multiples of that statistic. \\n \\nD. Choice of Experimental Design \\nIt is always bett er to do a factorial design unless we are sure that  \\nthe factors do not interact, because mostly they do. Replication \\nnumber de -pends on the dataset size; it can be kept small when the  \\ndataset is large;we will discuss this in the next section when we talk  \\nabout resampling.However, too few replicates generate few data and  \\nthis will make com-paring distributions diï¬ƒcult; in the particular case of \\nparametric tests, the assumptions of Gaussianity may not be tenable. \\nGenerally, given some dataset, we leave some part as the test set and \\nuse the rest for training and validation, probably many times by resam - \\npling. How this division is done is important. In practice, using small  \\ndatasets leads to responses with high variance, and the diï¬€erences will  \\nnot be signiï¬cant and results will not be conclusive. \\nIt is also important to avoid as much as possible toy,  synthetic data \\nand use datasets that are collected from real -world under real -life cir - \\ncumstances. Didactic one - or two -dimensional datasets may help pro vide \\nintuition, but the behavior of the algorithms may be completely diï¬€erent \\nin high-dimensional spaces. \\n \\nE. Performing the Experiment \\nBefore running a large factorial experiment with many factors and  \\nlevels,it is best if one does a few trial runs for some r andom settings to  \\ncheck that all is as expected. In a large experiment, it is always a good idea \\nto save intermediate results (or seeds of the random number generator),  \\nso that a part of the whole experiment can be rerun when desired. All the \\nresults should be reproducable. In running a large experiment with many \\nfactors and factor levels, one should be aware of the possible negative  \\neï¬€ects of software aging. \\nIt is important that an experimenter be unbiased during experimen- \\ntation. In comparing oneâ€™s favorite algorithm with a competitor, both  \\nshould be investigated equally diligently. In large -scale studies, it may  \\neven be envisaged that testers be diï¬€erent from developers. \\nOne should avoid the temptation to write oneâ€™s own â€œlibraryâ€ and \\nin- stead, as much as possible, use code from  reliable  sources;  such code \\nwould have been better tested and optimized. \\nAs in any software development study, the advantages of good docu-\\nmentation cannot be underestimated, especially when working in'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ngroups.All the methods developed for high -quality software engineering  \\nshould also be used in machine learning experiments. \\n \\nF. Statistical Analysis of the Data \\nThis corresponds to analyzing data in a way so that whatever \\nconclusion we  get is not subjective or due to chance. We cast the \\nquestions thatwe want to answer in a hypothesis testing framework and  \\ncheck whether the sample supports the hypothesis.  For example, the  \\nquestion \"Is A a more accurate algorithm than B?\" becomes the \\nhypothesis \"Can we say tha t the average error of learners trained by A is \\nsigniï¬cantly lower than the average error of learners trained by B?\" \\nAs always, visual analysis is helpful, and we can use histograms of  \\nerrordistributions, whisker-and-box plots, range plots, and so on \\n \\nG. Conclusions and Recommendations \\nOnce all data is collected and analyzed, we can draw objective \\nconclu- sions. One frequently encountered conclusion is the need for  \\nfurther experimentation. Most statistical, and hence machine learning or \\ndata mining, studies are iterative. It is for this reason that we never start \\nwith all the experimentation. It is suggested that no more than 25 \\npercent of the available resources should be invested in the ï¬rst \\nexperiment (Mont - gomery 2005). The ï¬rst runs are for investigation \\nonly. That is also why it is a good idea not to start with high expectations, \\nor promises to oneâ€™s boss or thesis advisor. \\nWe should always remember that statistical testing never tells us \\nif the hypothesis is correct or false, but how much the sample seems  \\nto concur with the hypothesis. There is always a risk that we do not  \\nhave aconclusive result or that our conclusions be wrong, especially if  \\nthe data is small and noisy. \\nWhen our expectations are not met, it is most helpful to investigate  \\nwhythey are not. For example, in checking why our favorite algorithm A \\nhas worked awfully bad on some cases, we can get a splendid idea for  \\nsome improved version of A. All improvements are due to the \\ndeï¬ciencies of the previous version;  ï¬nding a deï¬ciency is but a helpful  \\nhint that there is an improvement we can make! \\nBut we should not go to the next step of testing the improved version  \\nbefore we are sure that we have completely analyzed the current data  \\nandlearned all we could learn from it. Ideas are cheap, and useless unless \\ntested, which is costly. \\n \\n5.2 Cross-Validation and Resampling Methods \\n\\uf0b7 For replication purposes, our first need is to get a number of training \\nand validation set pairs from a dataset X (after having left out some \\npart as the test set). \\n\\uf0b7 To get them, if the sample X is large enough, we can randomly divide it \\ninto K parts, then randomly divide each part into two and use one half  \\nfor training and the other half for validation.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 K is typically 10 or 30. Unfortunately, datasets are never large enough \\nto do this. \\n\\uf0b7 So we should do our best with small datasets. \\n\\uf0b7 This is done cross-validation by repeated use of the same data split \\ndifferently; this is called crossvalidation. \\n\\uf0b7 The catch is that this makes the error percentages dependent as these \\ndifferent sets share data. \\n\\uf0b7 So, given a dataset X, we would like to generate K training/validation \\nset pairs, {Ti, Vi}K i=1, from this dataset. \\n\\uf0b7 We would like to keep the training and validation sets as large as \\npossible so that the error estimates are robust, and at the same time, \\nwe would like to keep the overlap between different sets as small as \\npossible. \\n\\uf0b7 We also need to make sure that classes are represented in the right \\nproportions when subsets of data are held out, not to disturb the class \\nprior probabilities; this is called stratification. \\n\\uf0b7 If a class has 20 percent examples in the whole dataset, in all samples  \\ndrawn from the dataset, it should also have approximately 20 percent \\nexamples. \\n5.3K-Fold Cross-Validation \\n\\uf0b7 K-fold In K-fold cross-validation, the dataset X is divided randomly into K \\nequalcross-validation sized parts, Xi, i = 1,...,K. \\n\\uf0b7 To generate each pair, we keep one of the K parts out as the validation set \\nand combine the remaining K âˆ’ 1 parts to form the training set. \\n\\uf0b7 Doing this K times, each time leaving out another one of the K parts out, we \\nget K pairs: V1 = X1 T1 = X2 ð–´ X3 ð–´Â·Â·Â·ð–´XK V2 = X2 T2 = X1 ð–´ X3 ð–´Â·Â·Â·ð–´XK . . . \\nVK = XK TK = X1 ð–´ X2 ð–´Â·Â·Â·ð–´XKâˆ’1 \\n\\uf0b7 There are two problems with this. First, to keep the training set large, we \\nallow validation sets that are small. \\n\\uf0b7 Second, the training sets overlap considerably, namely, any two training sets \\nshare K âˆ’ 2 parts. K is typically 10 or 30. \\n\\uf0b7 As K increases, the percentage of training instances increases and we get \\nmore robust estimators, but the validation set becomes smaller. \\n\\uf0b7 Furthermore, there is the cost of training the classifier K times, which \\nincreases as K is increased. \\n\\uf0b7 As N increases, K can be smaller; if N is small, K should be large to allow large \\nenough training leave-one-out sets. \\n\\uf0b7 One extreme case of K-fold cross-validation is leave-one-out where given a \\ndataset of N instances, only one instance is left out as the validation set \\n(instance) and training uses the N âˆ’ 1 instances.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 We then get N separate pairs by leaving out a different instance at each \\niteration. \\n\\uf0b7 This is typically used in applications such as medical diagnosis, where \\nlabeled data is hard to find. \\n\\uf0b7  Leave-one-out does not permit stratification. Recently, with computation \\ngetting cheaper, it has also become possible to have multiple runs of K-fold \\ncross-validation, for example, 10Ã—10- fold, and use average over averages to \\nget more reliable error estimates \\n5Ã—2 Cross-Validation \\n\\uf0b7 Dietterich (1998) proposed the 5 Ã— 2 cross-validation, which uses training \\nand validation sets of equal size. \\n\\uf0b7 We divide the dataset X randomly into two parts, X(1) 1and X(2) 1, which gives \\nour first pair of training and validation sets, T1 = X(1) 1and V1 = X(2) 1. \\n\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we \\nshuffle X randomly and divide this new fold into two, X(1) 2and X(2) 2. \\n\\uf0b7 This can be implemented by drawing these from X randomly without \\nreplacement, namely, X(1) 1ð–´ X(2) 1= X(1) 2ð–´ X(2) 2 = X. \\n\\uf0b7 We then swap these two halves to get another pair. We do this for three \\nmore folds and because from each fold, we get two pairs, doing five folds, we \\nget ten training and validation sets: T1 = X(1) 1V1 = X(2) 1T2 = X(2) 1 V2 = X(1) 1 \\nT3 = X(1) 2 V3 = X(2) 2 T4 = X(2) 2 V4 = X(1) 2  . . . T9 = X(1) 5 V9 = X(2) 5 T10 = X(2) \\n5 V10 = X(1) 5 Of course, we can do this for more than five folds and get more \\ntraining/validation sets, but Dietterich (1998) points out that after five \\nfolds, the sets share many instances and overlap so much that the statistics \\ncalculated from these sets, namely, validation error rates, become too \\ndependent and do not add new information. \\n\\uf0b7 Even with five folds, the sets overlap and the statistics are dependent, but \\nwe can get away with this until five folds. On the other hand, if we do have \\nfewer than five folds, we get less data (fewer than ten sets) and will not have \\na large enough sample to fit a distribution to and test our hypothesis on \\nTable 19.1 Confusion matrix for two  \\nclasses. \\n \\n Predicted \\nclass \\nTrue \\nClass \\nPositi \\nve \\nNegati \\nve \\nTot \\nal \\nPositive \\nNegative \\ntp : true \\npositive \\nfp : false \\npositive \\nfn : false \\nnegative \\ntn : true \\nnegative \\np \\nn \\nTotal pÃ— nÃ— N'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n \\nBootstrapping \\n\\uf0b7 To generate multiple samples from a single sample, an alternative to \\nbootstrap cross-validation is the bootstrap that generates new samples by \\ndrawing instances from the original sample with replacement. \\n\\uf0b7 We saw the use of bootstrapping in section 17.6 to generate training sets for \\ndifferent learners in bagging. \\n\\uf0b7 The bootstrap samples may overlap more than cross-validation samples and \\nhence their estimates are more dependent; but is considered the best way to \\ndo resampling for very small datasets. \\n\\uf0b7 In the bootstrap, we sample N instances from a dataset of size N with \\nreplacement. \\n\\uf0b7 The original dataset is used as the validation set. The probability that we pick \\nan instance is 1/N; the probability that we do not pick it is 1 âˆ’ 1/N. \\n\\uf0b7 The probability that we do not pick it after N draws is \\n( 1 âˆ’ 1 /N)N â‰ˆ eâˆ’1 = 0.368 \\nThis means that the training data contains approximately 63.2 percent of the \\ninstances; that is, the system will not have been trained on 36.8 percent of the data, \\nand the error estimate will be pessimistic. The solution is replication, that is, to \\nrepeat the process many times and look at the average behavior. \\n \\n5.3 Measuring Classifier Performance \\nFor classification, especially for two-class problems, a variety of measures \\nhas been proposed. There are four possible cases, as shown in table 19.1. For a \\npositive example, if the prediction is also positive, this is a true positive; if our \\nprediction is negative for a positive example, this is a false negative. For a negative \\nexample, if the prediction is also negative, we \\nTable 19.2 Performance measures used in two - \\nclass problems. \\n \\nName Formula \\nerror \\naccuracy \\n(f  p  + fn)/N \\n(tp + tn)/N = 1- \\nerror \\ntp-rate \\nfp-rate \\ntp/p \\nfp/n \\nprecision \\nrecall \\ntp/pâ€™ \\ntp/p = tp-rate \\nsensitivity \\nspeciï¬city \\ntp/p = tp-rate \\ntn/n = 1- fp-rate \\nhave a true negative, and we have a false positive if we predict a negative example as \\npositive.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nIn some two-class problems, we make a distinction between the two classes \\nand hence the two type of errors, false positives and false negatives. Different \\nmeasures appropriate in different settings are given in table 19.2. Let us envisage an \\nauthentication application where, for example, users log on to their accounts by \\nvoice. A false positive is wrongly logging on an impostor and a false negative is \\nrefusing a valid user. It is clear that the two type of errors are not equally bad; the \\nformer is much worse. True positive rate, tp-rate, also known as hit rate, measures \\nwhat proportion of valid users we authenticate and false positive rate, fp-rate, also \\nknown as false alarm rate, is the proportion of impostors we wrongly accept. \\nLet us say the system returns P(C Ë† 1|x), the probability of the positive class, and \\nfor the negative class, we have P(C Ë† 2|x) = 1 âˆ’ P (C Ë† 1|x), and we choose â€œpositiveâ€ if \\nP (C Ë† 1|x) > Î¸. If Î¸ is close to 1, we hardly choose the positive class; that is, we will \\nhave no false positives but also few true positives. As we decrease Î¸ to increase the \\nnumber of true positives, we risk introducing false positives. \\nFor different values of Î¸, we can get a number of pairs of (tp-rate, fp-rate) \\nvalues and by connecting them we get the receiver operating characteristics \\ncharacteristics (ROC) curve, as shown in figure 19.3a. Note that different values of Î¸ \\ncorrespond to different loss matrices for the two types of error and the ROC curve \\ncan also be seen as the behavior of a classifier \\nFigure 19.3 (a) Typical ROC curve. Each classifier has a threshold that allows us \\nto move over this curve, and we decide on a point, based on the relative importance \\nof hits versus false alarms, namely, true positives and false positives. The area below \\nthe ROC curve is called AUC. (b) A classifier is preferred if its ROC curve is closer to \\nthe upper-left corner (larger AUC). B and C are preferred over A; B and C are \\npreferred under different loss matrices \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIdeally, a classifier has a tp-rate of 1 and a fp-rate of 0, and hence a classifier is \\nbetter the more it gets closer to the upper-left corner. On the diagonal, we make as \\nmany true decisions as false ones, and this is the worst one can do (any classifier \\nthat is below the diagonal can be improved by flipping its decision). Given two \\nclassifiers, we can say one is better than the other one if it is above the other one; if \\ntwo ROC curves intersect, we can say that the two classifiers are better under'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ndifferent loss conditions, as seen in figure 19.3b. \\nROC allows a visual analysis; if we want to reduce the curve to a single the \\nnumber we can do this by calculating the area under the curve (AUC).A classifier \\nideally has an AUC of 1 and AUC values of different classifiers can be compared to \\ngive us a general performance averaged over different loss conditions. \\nIn information retrieval, there is a database of records; we make a \\n \\n \\nPrecision = a/a+b \\nRecall = a/a+c \\n \\n \\n \\n(a) Precision and recall \\n \\n \\nFigure 19.4 (a) Definition of precision and recall using Venn diagrams. (b) Precision is 1; \\nall the retrieved records are relevant but there may be relevant ones not retrieved. (c) \\nRecall is 1; all the relevant records are retrieved but there may also be irrelevant \\nrecords that are retrieved. \\nPrecision=1 Recall=1 \\n \\n \\n \\n \\nquery, for example, by using some keywords, and a system (basically a two-class \\nclassifier) returns a number of records. In the database, there are relevant records and \\nfor a query, the system may retrieve some of them (true positives) but probably not all \\n(false negatives); it may also wrongly retrieve records that are not relevant (false \\npositives). The set of relevant and retrieved records can be visualized using a Venn \\ndiagram, as shown in figure 19.4a. Precision is the number of retrieved and relevant \\nrecords divided by the total number of retrieved records; if precision is 1, all the \\nretrieved records may be relevant but there may still be records that are relevant but \\nnot retrieved. Recall is the number of retrieved relevant records divided by the total \\nnumber of relevant records; even if recall is 1, all the relevant records may be retrieved \\nbut there may also be irrelevant records that are retrieved, as shown in figure19.4c. As \\nin the ROC curve, for different threshold values, one can draw a curve for precision vs. \\nrecall. \\nFrom another perspective but with the same aim, there are the two measures of \\nsensitivity and specificity. Sensitivity is the same as tp-rate and recall. Specificity is how'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nwell we detect the negatives, which is the number of true negatives divided by the total \\nnumber of negatives; this is equal to 1 minus the false alarm rate. One can also draw a \\nsensitivity vs. specificity curve using different thresholds. \\nIn the case of K > 2 classes, if we are using 0/1 error, the class confumatrix sion \\nmatrix is a KÃ—K matrix whose entry (i, j) contains the number of instances that belong to \\nCi but are assigned to Cj . Ideally, all off-diagonals should be 0, for no misclassification. \\nThe class confusion matrix allows us to pinpoint what types of misclassification occur, \\nnamely, if there are two classes that are frequently confused. Or, one can define K \\nseparate two-class problems, each one separating one class from the other K âˆ’ 1. \\n \\n5.4 Assessing a Classification Algorithmâ€™s Performance \\nWe will discuss the case of classification error, but the same methodology applies \\nfor squared error in regression, log likelihoods in unsupervised learning, expected \\nreward in reinforcement learning, and so on, as long as we can write the appropriate \\nparametric form for the sampling distribution. We will also discuss nonparametric \\ntests when no such parametric form can be found. \\n \\nBinomial Test \\nLet us start with the case where we have a single training set T and a single \\nvalidation set V . We train our classifier on T and test it on V . We denote by p the \\nprobability that the classifier makes a misclassification error. We do not know p; it is \\nwhat we would like to estimate or test a hypothesis about. On the instance with \\nindex t from the validation set V , let us say xt denotes the correctness of the \\nclassifierâ€™s decision: xt is a 0/1 Bernoulli random variable that takes the value 1 \\nwhen the classifier commits an error and 0 when the classifier is correct. The \\nbinomial random variable X denotes the total number of errors: \\n \\nX = âˆ‘t=1N xt \\nWe would like to test whether the error probability p is less than or equal to some \\nvalue p0 we specify: \\nH0 : p â‰¤ p0 vs. H1 : p>p0 \\nIf the probability of error is p, the probability that the classifier commits j errors out \\nof N is \\nP{X = j} = ( N/ j ) pj (1 âˆ’ p)N-j \\nIt is reasonable to reject p â‰¤ p0 if in such a case, the probability that binomial test we \\nsee X = e errors or more is very unlikely. That is, the binomial test rejects the hypothesis \\nif \\nP{X â‰¥ e} = âˆ‘x=eN ( N/ x ) p0x(1-p0 )N-x < Î± (19.10) \\nwhere Î± is the significance, for example, 0.05. \\n \\nApproximate Normal Test \\nIf p is the probability of error, our point estimate is pË† = X/N. Then, it is reasonable \\nto reject the null hypothesis if pË† is much larger than p0. How large is large enough is \\ngiven by the sampling distribution of pË† and the significance Î±. \\nBecause X is the sum of independent random variables from the same distribution, \\nthe central limit theorem states that for large N, X/N is approximately normal with \\nmean p0 and variance p0(1 â€“ p0). Then \\nX/N â€“ p0 / âˆšp0(1 âˆ’ p0) âˆ¼ZË™ (19.11) \\nwhere Ë™âˆ¼ denotes â€œapproximately distributed.â€ Then, using equation 19.7, the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\napproximate normal test rejects the null hypothesis if this value for X = e is greater than \\nzÎ±. Z0.05 is 1.64. This approximation will work well as long as N is not too small and p is \\nnot very close to 0 or 1; as a rule of thumb, we require Np â‰¥ 5 and N(1 âˆ’ p) â‰¥ 5. \\n \\nT Test \\nThe two tests we discussed earlier use a single validation set. If we run the algorithm \\nK times, on K training/validation set pairs, we get K error percentages, pi, i = 1,...,K on \\nthe K validation sets. Let xt i be 1 if the classifier trained on Ti makes a misclassification \\nerror on instance t of Vi; xti is 0 otherwise. Then \\npi = âˆ‘t=1N xt i/ N Given that m = âˆ‘i=1K pi /K , S2 = âˆ‘i=1K (p i-m)2 /K â€“ 1 \\nfrom equation 19.8, we know that we have \\nâˆš K(m â€“ p0)/ S  âˆ¼ tK-1 (19.12) \\nand the t test rejects the null hypothesis that the classification algorithm has p 0 or less \\nerror percentage at significance level Î± if this  value is greater than t á¼€,K-1. Typically, K is \\ntaken as 10 or 30. T0.05,9= 1.83 and t0.05,29 = 1.70. \\n \\n5.5 Comparing Two Classification Algorithms \\nGiven two learning algorithms, we want to compare and test whether they \\nconstruct classifiers that have the same expected error rate. \\n \\nMcNemarâ€™s Test \\nGiven a training set and a validation set, we use two algorithms to train two \\nclassifiers on the training set and test them on the validation set and compute their \\nerrors. A contingency table, like the one shown here, is an array of natural numbers in \\nmatrix form representing counts, or frequencies: \\ne00: Number of \\nexamples \\nmisclassiï¬ed by both \\ne01: Number of \\nexamples \\nmisclassiï¬ed by 1 \\nbut not 2 \\ne10: Number of \\nexamples \\ne11: Number of \\nexamples \\nmisclassiï¬ed by 2 \\nbut not 1 \\ncorrectly classiï¬ed \\nby both \\n \\nUnder the null hypothesis that the classification algorithms have the same error \\nrate, we expect e01 = e10 and these to be equal to (e01+e10)/2. We have the chi-square \\nstatistic with one degree of freedom \\n((|e01 â€“ e10| âˆ’ 1)2 /e01 + e10 ) âˆ¼ X2 1 \\nand McNemarâ€™s test rejects the hypothesis that the two classification algorithms \\nhave the same error rate at significance level Î± if this value is greater than X2 Î±,1. For \\nÎ± = 0.05, X2 0.05,1 = 3.84 \\n \\nK-Fold Cross-Validated Paired t Test \\nThis set uses K-fold cross-validation to get K training/validation set pairs. We use \\nthe two classification algorithms to train on the training sets Ti, i = 1,...,K, and test on the \\nvalidation sets Vi. The error percentages of the classifiers on the validation sets are \\nrecorded as p1i and p2 i . \\nIf the two classification algorithms have the same error rate, then we expect them \\nto have the same mean, or equivalently, that the difference of their means is 0. The'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ndifference in error rates on fold i is pi= p1 i âˆ’p2 i. This is a paired test; that is, for each i, \\nboth algorithms see the same training and validation sets. When this is done K times, we \\nhave a distribution of pi containing K points. Given that p1i and p2 i are both \\n(approximately) normal, their difference pi is also normal. The null hypothesis is that \\nthis distribution has 0 mean: \\nH0 : Î¼ = 0 vs. H1 : Î¼ â‰  0 \\nWe define \\nm = âˆ‘i=1K pi /K ,  S2 = âˆ‘i=1K (p i-m)2 /K â€“ 1 \\nUnder the null hypothesis that Î¼ = 0, we have a statistic that is tdistributed with K âˆ’ 1 \\ndegrees of freedom: \\nâˆš K(m âˆ’ 0)/ S = âˆš K Â· m/ S  âˆ¼ tK-1 (19.14) \\nThus the K-fold cv paired t test rejects the hypothesis that two clastest sification \\nalgorithms have the same error rate at significance level Î± if this value is outside the \\ninterval (âˆ’tá¼€/2,K-1, tá¼€/2,K-1). T0.025,9 = 2.26 and t0.025,29 = 2.05. \\nIf we want to test whether the first algorithm has less error than the second, we \\nneed a one-sided hypothesis and use a one-tailed test: \\nH0 : Î¼ â‰¥ 0 vs. H1 : Î¼ < 0 \\nIf the test rejects, our claim that the first one has significantly less error is supported. \\n \\n5 Ã— 2 cv Paired t Test \\nIn the 5 Ã— 2 cv t test, proposed by Dietterich (1998), we perform five replications of \\ntwofold cross-validation. In each replication, the dataset is divided into two equal-sized \\nsets. P(j)i is the difference between the error rates of the two classifiers on fold j = 1, 2 of \\nreplication i = 1,..., 5. The average on replication i is pâ€¾ i = (p(1) i+p(2) i)/2, and the \\nestimated variance is s2 i= (p(1)i  âˆ’ p- i)2+ (p(2) iâˆ’ p- i)2. \\nUnder the null hypothesis that the two classification algorithms have the same error \\nrate, p(j) i is the difference of two identically distributed proportions, and ignoring the \\nfact that these proportions are not independent, p(j) i can be treated as approximately \\nnormal distributed with 0 mean and unknown variance Ïƒ2. Then p(j) i /Ïƒ is \\napproximately unit normal. If we assume p(1) i and p(2) i are independent normals (which \\nis not strictly true because their training and test sets are not drawn independently of \\neach other), then s2 i /Ïƒ+2 has a chi-square distribution with one degree of freedom. If \\neach of the \\ns2 i are assumed to be independent (which is not true because they are all computed \\nfrom the same set of available data), then their sum is chi-square with five degrees of \\nfreedom: \\nM = âˆ‘5 i=1 s2 i  /Ïƒ2 âˆ¼ X2 5 \\nand \\nt = p(1) 1 /Ïƒ /âˆšM/5 = p(1) 1 / âˆšâˆ‘5 i=1 s2 i/5 âˆ¼ t5 (19.15) \\ngiving us a t statistic with five degrees of freedom. The 5 Ã— 2 cv paired t test rejects the \\nhypothesis that the two classification algorithms have the same error rate at \\nsignificance level Î± if this value is outside the interval (âˆ’tá¼€/2,5, tá¼€/2,5). T0.025,5 = 2.57. \\n \\n5 Ã— 2 cv Paired F Test \\nWe note that the numerator in equation 19.15, p(1) 1 , is arbitrary; actually, ten \\ndifferent values can be placed in the numerator, namely, p(j) i, j = 1, 2, i = 1,..., 5, leading \\nto ten possible statistics: \\nt(j) i= p(j) i /âˆšâˆ‘5 i=1s2 i /5 (19.16) \\nAlpaydÄ±n (1999) proposed an extension to the 5 Ã— 2 cv t test that combines the results of'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nthe ten possible statistics. If p(j) i /Ïƒ âˆ¼ Z, then (p(j) i )2 /Ïƒ2 âˆ¼ X2 1 and their sum is chi- \\nsquare with ten degrees of freedom: \\nN = âˆ‘5 i=1âˆ‘2 j=1 (p(j) i)2 /Ïƒ2 âˆ¼ X2 10 \\nPlacing this in the numerator of equation 19.15, we get a statistic that is the ratio of \\ntwo chi-square distributed random variables. Two such variables divided by their \\nrespective degrees of freedom is F-distributed with ten and five degrees of freedom \\n(section A.3.8): \\nf = (N/10)/( M/5) = âˆ‘5 i=1âˆ‘2 j=1 (p(j) i)2 /2âˆ‘5i=1 s2 iâˆ¼F10,5 \\n5 Ã— 2 cv paired F test rejects the hypothesis that the classification algotest rithms have \\nthe same error rate at significance level Î± if this value is greater than Fá¼€,10.5. F0.05,10.5 = \\n4.74.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='DATABASE SYSTEM DEVELOPMENT LIFECYCLE: \\n \\nDatabase Planning: \\nThe management activities that allow the stages of the database system development lifecycle to be realized as efficiently \\nand effectively as possible. \\nAn important first step in database planning  is to clearly define the mission statement for the database system. The \\nmission statement defines the major aims of the database system. Those driving the database project within the \\norganization (such as the Director and/or owner) normally define the mis sion statement. A mission statement helps to \\nclarify the purpose of the database system and provide a clearer path towards the efficient and effective creation of the \\nrequired database system. \\nOnce the mission statement is defined, the next activity involves identifying the mission objectives. Each mission objective \\nshould identify a particular task that the database system must support. The assumption is that if the database system \\nsupports the mission objectives, then the mission statement should be met. \\nDatabase planning should also include the development of standards that govern how data will be collected, how the \\nformat should be specified, what documentation will be needed, and how design and implementation should proceed. \\nSystem Definition: \\nDescribes the scope and boundaries of the database system and the major user views.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='User Views: Defines what is required of a database system from the perspective of a particular job role (such as Manager \\nor Supervisor) or enterprise application area (such as marketing, personnel, or stock control). \\nA database system may have one or more user views. Identifying user views is an important aspect of developing a \\ndatabase system because it helps to ensure that no major users of the database are forgotten when developin g the \\nrequirements for the new database system. \\n \\nRepresentation of a database system with multiple user views: user views \\n \\nThere are three main approaches to managing the requirements of a database system with multiple user views: \\n\\uf0b7 the centralized approach \\n\\uf0b7 the view integration approach \\n\\uf0b7 a combination of both approaches \\nCentralized Approach: Requirements for each user view are merged into a single set of requirements for the new database \\nsystem. A data model representing all user views is created during the database design stage.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='The centralized (or one -shot) approach involves collating the requirements for different user views into a single list of \\nrequirements. The collection of user views is given a name that provides some indication of the application area covered \\nby all the merged user views. In the database design stage, a global data model is created, which represents all user views. \\nView Integration Approach: Requirements for each user view remain as separate lists. Data models representing each user \\nview are created and then merged later during the database design stage. \\nThe view integration approach involves leaving the requirements for each user view as separate lists of requirements. In \\nthe database design stage, we  first create a data model for ea ch user view. A data model that represents a single user \\nview (or a subset of all user views) is called a local data model. Each model is composed of diagrams and documentation \\nthat formally describes the requirements of one or moreâ€”but not allâ€”user views of the database. The local data models \\nare then merged at a later stage of database design to produce a global data model, which represents all user \\nrequirements for the database. \\n \\nDatabase Design: \\nThe process of creating a design that will support the en terpriseâ€™s mission statement and mission objectives for the \\nrequired database system. \\nThe two main approaches to the design of a database are: \\n\\uf0b7 â€œbottom-upâ€ \\n\\uf0b7 â€œtop-down.â€ \\nThe bottom-up approach begins at the fundamental level of attributes (that is, properties  of entities and relationships), \\nwhich through analysis of the associations between attributes are grouped into relations that represent types of entities \\nand relationships between entities.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='A more appropriate strategy for the design of complex databases is to use the top-down approach. This approach starts \\nwith the development of data models that contain a few high-level entities and relationships and then applies successive \\ntop-down refinements to identify lower-level entities, relationships, and the associated attributes. \\nThere are other approaches to database design, such as the inside -out approach and the mixed strategy approach. The \\ninside-out approach is related to the bottom- up approach, but differs by first identifying a set of major entities and then \\nspreading out to consider other entities, relationships, and attributes associated with those first identified. The mixed \\nstrategy approach uses both the bottom -up and top -down approach for various parts of the model before finally \\ncombining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design \\n \\nConceptual Database Design: The process of constructing a model of the data used in an enterprise, independent of all \\nphysical considerations. \\nLogical Database Design: The process of constructing a model of the data used in an enterprise based on a specific data \\nmodel, but independent of a particular DBMS and other physical considerations. \\nPhysical Database Design: The process of producing a description  of the implementation of the database on secondary \\nstorage; it describes the base relations, file organizations, and indexes used to achieve efficient access to the data, and \\nany associated integrity constraints and security measures. \\nDBMS Selection:  \\nThe selection of an appropriate DBMS to support the database system. \\nThe steps involved in database selection are: \\n\\uf0b7 Define Terms of Reference of study \\n\\uf0b7 Shortlist two or three products \\n\\uf0b7 Evaluate products \\n\\uf0b7 Recommend selection and produce report \\nApplication Design: \\nThe design of the user interface and the application programs that use and process the database.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Database and application design are parallel activities of the database system development lifecycle. In most cases, it is \\nnot possible to complete the application design until the design of the database itself has taken place. \\nThe steps involved in application design are: \\n\\uf0b7 Transaction Design \\n\\uf0b7 User interface Design Guidelines \\nTransaction Design: An action, or series of actions, carried out by a single user or app lication program, that accesses or \\nchanges the content of the database. \\nThe purpose of transaction design is to define and document the high-level characteristics of the transactions required on \\nthe database, including: \\n\\uf0b7 data to be used by the transaction \\n\\uf0b7 functional characteristics of the transaction \\n\\uf0b7 output of the transaction \\n\\uf0b7 importance to the users \\n\\uf0b7 expected rate of usage \\nUser interface Design Guidelines: \\n\\uf0b7 Meaningful title \\n\\uf0b7 Comprehensible instructions \\n\\uf0b7 Logical grouping and sequencing of fields \\n\\uf0b7 Visually appealing layout of the form/report \\n\\uf0b7 Familiar field labels \\n\\uf0b7 Consistent terminology and abbreviations \\n\\uf0b7 Consistent use of color \\n\\uf0b7 Visible space and boundaries for data entry fields \\n\\uf0b7 Convenient cursor movement \\n\\uf0b7 Error correction for individual characters and entire fields \\n\\uf0b7 Error messages for unacceptable values \\n\\uf0b7 Optional fields marked clearly \\n\\uf0b7 Explanatory messages for fields \\n\\uf0b7 Completion signal \\nPrototyping: \\nBuilding a working model of a database system. \\nA prototype is a working model that does not normally have all the required fe atures or provide all the functionality of \\nthe final system. The main purpose of developing a prototype database system is to allow users to use the prototype to \\nidentify the features of the system that work well or are inadequate, and if possible to suggest improvements or even new \\nfeatures to the database system. \\nThere are two prototyping strategies: \\n\\uf0b7 requirements prototyping - uses a prototype to determine the requirements of a proposed database system, and \\nonce the requirements are complete, the prototype is discarded \\n\\uf0b7 evolutionary prototyping - used for the same purposes, the important difference is that the prototype is not \\ndiscarded, but with further development becomes the working database system'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Implementation: \\nThe physical realization of the database and application designs. \\nThe database implementation is achieved using the DDL of the selected DBMS or a GUI, which provides the same \\nfunctionality while hiding the low-level DDL statements. The application programs are implemented using the preferred \\nthird- or fourth generation language (3GL or 4GL). \\nData Conversion and Loading: \\nTransferring any existing data into the new database and converting any existing applications to run on the new database. \\nThis stage is required only when a new database system is replacing an old system. \\nTesting: \\nThe process of running the database system with the intent of finding errors. \\nBefore going live, the newly developed database system should be thoroughly tested. This is achieved using carefully \\nplanned test strategies and realistic data, so that the entire testing process is methodically and rigorously carried out. \\nOperational Maintenance: \\nThe process of monitoring and maintaining the database system following installation. \\n\\uf0b7 Monitoring the performance of the system. If th e performance falls below an acceptable level, tuning or \\nreorganization of the database may be required. \\n\\uf0b7 Maintaining and upgrading the database system (when required). New requirements are incorporated into the \\ndatabase system through the preceding stages of the lifecycle. \\n \\nCASE Tools: \\nA computer -aided software engineering (CASE) tool is a software package that provides support for the design and \\nimplementation of information systems. It can document a database design and provide invaluable help in maintain ing \\nthe consistency of a design. By integrating many of the techniques used to document a system design  including the data \\ndictionary, data flows, and entity relationships, CASE tool can increase the consistency and accuracy of a database design. \\nIt can also ease the task of creating the diagrams that accompany a system design. \\nThere is no software in the world that can examine a database environment and identify the entities, attributes, and \\nrelationships that should be represented in a database. The model created with CASE tool is therefore only as good as the \\nanalysis of the database environment provided by the people using the tool. \\nCASE support may include: \\n\\uf0b7 a data dictionary to store information about the database systemâ€™s data \\n\\uf0b7 design tools to support data analysis \\n\\uf0b7 tools to permit development of the corporate data model, and the conceptual and logical data models \\n\\uf0b7 tools to enable the prototyping of applications'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Requirements Collection: \\nFact Finding Technique: \\nThe formal process of using techniques suc h as interviews and questionnaires to collect facts about systems, \\nrequirements, and preferences.  Fact-finding is particularly crucial to the early stages of the lifecycle, including the \\ndatabase planning, system definition, and requirements collection and analysis stages. \\nThere are five commonly used fact-finding techniques: \\n\\uf0b7 examining documentation \\n\\uf0b7 interviewing \\n\\uf0b7 observing the enterprise in operation \\n\\uf0b7 research \\n\\uf0b7 questionnaires \\nthe below diagram depicts the examples of data captured in each of the stages of the development life cycle.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='DreamHome Case Study: \\nDreamHome specializes in property management, taking an intermediate role between owners who wish to rent out their \\nfurnished property and clients of DreamHome who require to rent furnished property for a fi xed period. DreamHome \\ncurrently has about 2000 staff working in 100 branches. \\n \\nMission Statement for the Case Study: \\n \\n \\nMission Objectives for the Case Study:'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='System boundary for the Case Study: \\n \\n \\nENTITY-RELATIONSHIP MODELING: \\nAn entity is a \"thing\" or \"object\" in the real world that is distinguishable from all other objects. For example, each person \\nin an enterprise is an entity. An entity set is a set of entities of the same type that share the same properties, or attributes. \\nThe set of all persons who are customers at a given bank, for example, can be defined as the entity set customer. \\nAn entity is represented by a set of attributes. Attributes are descriptive properties possessed by each member of an \\nentity set. \\nAttribute domain: The set of allowable values (data type) for one or more attributes. \\nTypes of Attributes: \\nSimple Attribute: An attribute composed of a single component with an independent existence.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Composite Attribute: An attribute composed of multiple components, each with an independent existence. \\nSingle-Valued Attributes: An attribute that holds a single value for each occurrence of an entity type. \\nMulti-Valued Attributes: An attribute that holds multiple values for each occurrence of an entity type. \\nDerived Attributes: An attribute that represents a value that is derivable from the value of a related attribute or set of \\nattributes, not necessarily in the same entity type. \\n \\nA relationship is an association among several entities.  Relationship set is a set of relationships of the same type. \\nThe association between entity set is referred to as participation. That is, the entity sets E1, E2, . ..,En participate in \\nrelationship set R. \\nA uniquely identifiable association that includes one occurrence from each participating entity type. A relatio nship \\noccurrence indicates the particular entity occurrences that are related. Relationship type and Relationship occurrences \\nare one and the same.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Degree of a relationship: The number of participating entity types in a relationship. Binary relationship set is of degree 2; \\na tertiary relationship set is of degree 3. \\nUnary relationship: A unary relationship exists when an association is maintained within a single entity. \\n \\nBinary relationship: A binary relationship exists when two entities are associated. \\n \\n \\nTernary relationship: A ternary relationship exists when there are three entities associated. \\n \\n \\nQuaternary relationship: A quaternary relationship exists when there are four entities associated. \\n \\n \\nEntity role: The function that an entity plays in a relationship is called that entityâ€˜s role. A role is one end of an association. \\nIn the below ER model, the publisher entity plays the publishes role. \\n \\n \\nRecursive Relationship: A relationship type in which the same entity type participates more than once in different roles.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Keys: \\nSuper Key: Super key is a single attribute or a group of multiple attributes that can uniquely identify each occurrence of \\nan entity type. \\nCandidate Key: The minimal set of attributes that uniquely identifies each occurrence of an entity type. \\nPrimary Key: The candidate key that is selected to uniquely identify each occurrence of an entity type. \\nComposite Key: A candidate key that consists of two or more attributes. \\nForeign Key: Foreign key is an attribute which is a Primary key in its parent entity, but is included as an attribute in another \\nentity. A Foreign key generates a relationship between the parent entity and the child entity. \\nAlternate or Secondary Key: Alternate keys are those candidate keys which are not the Primary key. \\n \\nAn entity set may not have sufficient attributes to form a primary key. Such an entity set is termed a weak entity set. An \\nentity set that has a primary key is termed a strong entity set. \\nWeak entity set is associated with another entity set called the identifying or owner entity set. i.e., weak entity set is said \\nto be existence dependent on the identifying entity set. Identifying entity set is said to own the weak entity set. \\nThe relationship among the weak and identifying entity set is called the identifying relationship. \\n \\nSTRUCTURAL CONSTRAINTS: \\nMultiplicity: The number (or range) of possible occurrences of an entity type that may relate to a single occurrence of an \\nassociated entity type through a particular relationship. \\n\\uf0b7 one-to-one (1:1) \\n\\uf0b7 one-tomany (1:*) \\n\\uf0b7 many-to-many (*:*)'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='One-to-one: An entity in A is associated with at most one entity in B, and an entity in B is associated  with at most one \\nentity in A. \\n \\nExample: Relationship between Manager and Branch of a Bank. \\n \\nOne-to-many: An entity in A is associated with any number of entities (zero or more) in B. An entity in B, however, can be \\nassociated with at most one entity in A. \\n \\nExample: Relationship between Department and Employee. \\n \\nMany-to-many: An entity in A is associated with any number (zero or more) of entities in B, and an entity in B is associated \\nwith any number (zero or more) of entities in A. \\n \\nExample: Relationship between Supplier and Products. \\n \\nCardinality and Participation Constraints : Multiplicity actually consists of two separate constra ints known as cardinality \\nand participation.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Cardinality: Describes the maximum number of possible relationship occurrences for an entity participating in a given \\nrelationship type. \\n \\nParticipation: Determines whether all or only some entity occurrences participate in a relationship \\nThe participation constraint represents whether all entity occurrences are involved in a particular relationship (referred \\nto as mandatory participation) or only some (referred to as optional participation). \\n \\n \\nProblems with ER Models: \\nFan Trap: Where a model represents a relationship between entity types, but the pathway between certain entity \\noccurrences is ambiguous. \\nChasm Trap: Where a model suggests the existence of a relationship between entity types, but the pathway does not exist \\nbetween certain entity occurrences \\n \\n \\nENHANCED ER MODEL \\nIt is a diagrammatic technique for displaying the following concepts \\n\\uf0b7 Sub Class and Super Class \\n\\uf0b7 Specialization and Generalization \\n\\uf0b7 Aggregation \\n\\uf0b7 Composition'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Super Class: An entity type that includes one or more distinct subgroupings of its occurrences, which must be represented \\nin a data model. \\nSub Class: A distinct subgrouping of occurrences of an entity type, which must be represented in a data model. \\nSpecialization: Specialization is the process of defining a set of subclasses of an entity type. The process of maximizing the \\ndifferences between members of an entity by identifying their distinguishing characteristics. The set of subclasses that \\nforms a specialization is defined on the basis of some distinguishing characteristic of the entities in the superclass. \\nGeneralization: A reverse process of abstraction . Suppress the differences among several entity types . The process of \\nminimizing the differences between entities by identifying their common characteristics. Identify their common features, \\nand generalize them into a single superclass of which the original entity types are special subclasses.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Constraints on Specialization/Generalization : In some specializations we can determine exa ctly the entities that will \\nbecome members of each subclass by placing a condition on the value of some attribute of the superclass. Such subclasses \\nare called predicate-defined (or condition-defined) subclasses. \\nâ€¢ Participation Constraints: Determines whether every member in the superclass must participate as a member of \\na subclass \\nâ€¢ Disjoint Constraints: Describes the relationship between members of the subclasses and indicates whether it is \\npossible for a member of a superclass to be a member of one, or more than one, subclass. \\nIf all subclasses in a specialization have their membership condition on the same attribute of the superclass, the \\nspecialization itself is called an attribute -defined specialization . The attribute is called the defining attribute of t he \\nspecialization. When we do not have a condition for determining membership in a subclass, the subclass is called user -\\ndefined subclass. \\nA total specialization constraint specifies that every entity in the superclass must be a member of at least one subclass in \\nthe specialization. A partial specialization, which allows an entity not to belong to any of the subclasses. \\nA specialization Lattice: \\nA set of entities that are at two or more levels is called as a specialization lattice. It is also called as mul ti-level \\nspecialization.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Aggregation: \\nâ€¢ Aggregation is an abstraction concept for building composite objects from their component objects.  \\nâ€¢ Represents a â€œhas-aâ€ or â€œis-part-ofâ€ relationship between entity types, where one represents the â€œwholeâ€ and the \\nother the â€œpart.â€ \\nThree Cases \\nâ€¢ We aggregate attribute values of an object to form the whole object \\nâ€¢ We represent an aggregation relationship as an ordinary relationship \\nâ€¢ Combining objects that are related by a particular relationship instance into a higher-level aggregate \\nobject \\nâ€¢ IS-A-PART-OF and IS-A-COMPONENT-OF \\nComposition: \\nA specific form of aggregation that represents an association between entities, where there is a strong ownership and \\ncoincidental lifetime between the â€œwholeâ€ and the â€œpart.â€ \\nEg.: A newspaper displays an advertisement \\n \\nUML Class Diagram: \\nIn UML class diagrams, \\nâ€“ a class (similar to an entity type in ER) is displayed as a box that includes three sections: \\nâ€¢ The top section gives the class name (similar to entity type name) \\nâ€¢ the middle section includes the attributes \\nâ€¢ last section includes operations that can be applied to individual objects \\nâ€“ Operations are not specified in ER diagrams.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='â€¢ The designer can optionally specify the domain (or data type) of an attribute if desired, by placing a colon (: ) \\nfollowed by the domain name or description \\nâ€¢ A composite attribute is modeled as a structured domain \\nâ€¢ A multivalued attribute will generally be modeled as a separate class \\nâ€¢ Relationship types are called associations in UML terminology, and relationship instances are called links \\n \\nAssociations: \\nA binary association is represented as a line connecting the participating classes, and may optionally have a name \\nâ€¢ A relationship attribute, called a link attribute, is placed in a box that is connected to the associati onâ€™s line by a \\ndashed line \\nâ€¢ The (min, max) notation is used to specify relationship constraints, which are called multiplicities in UML \\nterminology \\nâ€“ Multiplicities are specified in the form min..max, and an asterisk (*) indicates no maximum limit on \\nparticipation  \\nIn UML, there are two types of relationships: \\nâ€“ Association \\nâ€“ Aggregation \\nAggregation is meant to represent a relationship between a whole object and its component parts, and it has a distinct \\ndiagrammatic notation. \\nUML also distinguishes between unidirectional and bidirectional associations/aggregations. In the unidirectional case, the \\nline connecting the classes is displayed with an arrow to indicate that only one direction for accessing related objects is \\nneeded. If no arrow is displayed, the bidirectional case is assumed, which is the default. In addition, relationship instances \\nmay be specified to be ordered.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='ER Model for a Banking System: \\n \\nER Model for a University System'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='AD8401 Database Design and Management \\n \\n \\nA database is an organized collection of data elements (facts) stored in a computer in a systematic way, \\nsuch that a computer program can consult it to answer questions. The answers to those questions become \\ninformation that can be used to make decisions t hat may not be made with the data elements alone. A \\nsoftware system that enables users to define, create, maintain, query, and control access to the database.is \\nknown as a database management system (DBMS). A computer program that interacts with the databa se \\nby issuing an appropriate request (typically an SQL statement) to the DBMS is known as a database \\napplication program. \\n \\nTraditional File Processing System: File-based systems were an early attempt to computerize the manual \\nfiling system. However, rather  than establish a centralized store for the organizationâ€™s operational data, a \\ndecentralized approach was taken, where each department stored and controlled its own data. \\n \\nIssues in File Based Systems: \\nâ— Separation and isolation of data: When data is isolated in separate files, it is more difficult to \\naccess data that should be available. \\nâ— Duplication of data: Owing to the decentralized approach taken by each department, the file-\\nbased approach encouraged, if not necessitated, the uncontrolled duplication of data. \\nâ— Difficulty in accessing data In order to retrieve, access and use stored data, need to write a \\nnew program to carry out each new task. \\nâ— Programâ€“Data dependence: The physical structure and storage of the data files and records \\nare defined in the application code.  \\nâ— Data Inconsistency: Data is updated in one file and not in other files and thus some data \\nbecomes invalid. \\nâ— Data Integrity: Allows some invalid data to enter into the system. \\nâ— Data Security: Everyone who has access to the file can view all the data. \\nâ— Atomicity of updates Failures of files may leave database in an inconsistent state with partial \\nupdates carried out.  \\n \\nThree Level Architecture (Abstraction): \\n \\nExternal View: The external or view level includes a number of external schemas or user views. Each external \\nschema describes the part of the database that a particular user group is interested in and hides the rest of \\nthe database from that user group.  \\nConceptual View: The conceptual level has a conceptual schema, which describes the structure of the whole \\ndatabase for a community of users. The conceptual schema hides the details of physical storage structures \\nand concentrates on describing entities, data types, relationships, user operations, and constraints \\nPhysical View (Internal V iew): The internal level has an internal schema, which describes the physical \\nstorage structure of the database. The internal schema uses a physical data model and describes the \\ncomplete details of data storage and access paths for the database.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 1, 'page_label': '2', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Logical data independence is the capacity to change the conceptual schema without having to change \\nexternal schemas or application programs. We may change the conceptual schema to expand the database \\n(by adding a record type or data item), to change constrai nts, or to reduce the database (by removing a \\nrecord type or data item).\\nPhysical data independence is the capacity to change the internal schema without having to change the \\nconceptual schema. Hence, the external schemas need not be changed as well. Changes to the internal \\nschema may be needed because some physical files were reorganizedâ€”for example, by creating additional \\naccess structuresâ€”to improve the performance of retrieval or update.  \\nUsers of the Database: \\n \\nNaive User: The end-users are the â€œclientsâ€ of the databaseNaÃ¯ve users are typically unaware of the DBMS. \\nThey access the database through specially written application programs that attempt to make the operations \\nas simple as possible.  \\n \\nApplication Programmer : Each program contains statements that request the DBMS to perform some \\noperation on the database, whi ch includes retrieving data, inserting, updating, and deleting data. The \\nprograms may be written in a third-generation or fourth-generation programming language. \\n \\nDatabase Designer: The logical database designer must have a thorough and complete understanding  of \\nthe organizationâ€™s data and any constraints on this data (the constraints are sometimes called business \\nrules).  \\n \\nDatabase Administrator: The Database Administrator (DBA) is responsible for the physical realization of the \\ndatabase, including physi cal database design and implementation, security and integrity control, \\nmaintenance of the operational system, and ensuring satisfactory performance of the applications for users.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Advantages of DBMSs\\nControl of data redundancy: the database approach attempts to eliminate the redundancy by integrating the \\nfiles so that multiple copies of the same data are not stored.\\nData consistency: By eliminating or controlling redundancy, we reduce the risk of inconsistencies occurring. \\nIf a data item is stored only once in the database, any update to its value has to be performed only once and \\nthe new value is available immediately to all users.\\nMore information from the same amount of data : With the integra tion of the operational data, it may be \\npossible for the organization to derive additional information from the same data. \\nSharing of data the database belongs to the entire organization and can be shared by all authorized users. \\nIn this way, more users share more of the data. \\nImproved data integrity: Integrity is usually expressed in terms of constraints, which are consistency rules \\nthat the database is not permitted to violate. Constraints may apply to data items within a single record or to \\nrelationships between records.\\nDatabase security is the protection of the database from unauthorized users. This security may take the form \\nof usernames and passwords to identify people authorized to use the database. Granti ng restricted access \\nto the users.\\nEnforcement of standards : integration allows the DBA to define and the DBMS to enforce the necessary \\nstandards.\\nEconomy of scale: Combining all the organizationâ€™s operational data into one database and creating a set of \\napplications that work on this one source of data can result in cost savings. \\nBalance of conflicting requirements : Each user or depart ment has needs that may be in conflict with the \\nneeds of other users. \\nImproved data accessibility and responsiveness : Again, as a result of integration, data that crosses \\ndepartmental boundaries is directly accessible to the end users. \\n \\nIncreased productivity: As mentioned previously, the DBMS provides many of the standard functions that the \\nprogrammer would normally have to write in a file based application. Eg: low-level file-handling routines \\nImproved maintenance  through data independence: A DBMS separates the data descriptions from the \\napplications, thereby making applications immune to changes in the data descriptions.\\nIncreased concurrency: Many DBMSs manage concurrent database access and ensure that multiple users \\ncan access the data simultaneously.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Improved backup and recovery services: Modern DBMSs provide facilities to minimize the amount of \\nprocessing that is lost following a failure.\\nDisadvantages of DBMSs\\nComplexity: The provision of the functionality that we expect of a good DBMS makes the DBMS an extremely \\ncomplex piece of software. \\nSize: The complexity and breadth of functionality makes the DBMS an extremely large piece of software, \\noccupying many megabytes of disk space and requiring substantial amounts of memory to run efficiently. \\nCost: The cost of DBMSs varies significantly, depending on the environment and functionality provided. For \\nexample, a single-user DBMS costs less than a large mainframe multi-user DBMS. There is also the recurrent \\nannual maintenance cost. \\nAdditional hardware costs The disk storage requirements for the DBMS and the database may necessitate \\nthe purchase of additional storage space. \\nCost of conversion: The cost of converting existing applications to run on the new DBMS and hardware.\\nPerformance: DBMS is written to be more general, to cater for many applications rather than just one. The \\nresult is that some applications may not run as fast as they used to. \\nGreater impact of a failure The centralization of resources increases the vulnerability of the system. Because \\nall users and applications rely on the availability of the DBMS, the failure of certain components can bring \\noperations to a halt.\\n \\nDBMS environment\\nThe DBMS and the applications require hardware to run. The hardware can range from a single personal \\ncomputer to a single mainframe or a network of computers. The particular hardware depends on the \\norganizationâ€™s requirements and the DBMS used.  \\n \\nThe software component comprises the DBMS software itself and the application programs, together with \\nthe operating system, including network software if the DBMS is being used over a network.  \\n \\nData:  Perhaps the most important component of the DBMS environment certainly from the end-usersâ€™ point \\nof view is the data. The data acts as a bridge between the machine and the human components.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Procedures: Procedures refer to the instructions and rules that govern the design and use of the database. \\nThe users of the system and the staff who manage the database require documented procedures on how to \\nuse or run the system. \\n \\nPeople: The final component is the people involved with the system.  \\n \\nDatabase Architecture:\\n \\n \\nData model: An integrated collection of concepts for describing and manipulating data, relationships between \\ndata, and constraints on the data in an organization. A model is a representation of real -world objects and \\nevents, and their associations.\\nA data model can be thought of as comprising three components: \\n(1) a structural part, consisting of a set of rules according to which databases can be constructed; \\n(2) a manipulative part, defining the  types of operation that are allowed on the data (updating or \\nretrieving data from the database and changing the structure of the database); \\n(3) a set of integrity constraints, which ensures that the data is accurate.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Types of Data Model: \\n(1) an external data model, to represent each userâ€™s view of the organization, sometimes called the \\nUniverse of Discourse (UoD); \\n(2) a conceptual data model, to represent the logical (or community) view that is DBMS-independent; \\n(3) an int ernal data model, to represent the conceptual schema in such a way that it can be \\nunderstood by the DBMS \\n \\nObject-based data models use concepts such as entities, attributes, and relationships. \\nIn a record-based model, the database consists of a number of f ixed-format records, possibly of differing \\ntypes. Each record type defines a fixed number of fields, typically of a fixed length. There are three principal \\ntypes of record -based logical data model: the relational data model, the network data model, and the  \\nhierarchical data model.  \\nThe relational data model is based on the concept of mathematical relations. In the relational model, data \\nand relationships are represented as tables, each of which has a number of columns with a unique name. \\nIn the network model, data is represented as collections of records, and relationships are represented by \\nsets.  \\n \\nThe hierarchical model is a restricted type of network model. Again, data is represented as collections of \\nrecords and relationships are represented by sets.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Physical data models describe how data is stored in the computer, representing information such as record \\nstructures, record orderings, and access paths. There are not as many physical data models as logical data \\nmodels; the most common ones are the unifying model and the frame memory.\\n \\nConceptual modeling or conceptual database design  is the process  of constructing a model of the \\ninformation use in an enterprise that is independent of implementation details, such as the target DBMS, \\napplication programs, programming languages, or any other physical considerations.\\n \\nFunctions of a DBMS \\n \\n(1) Data storage, retrieval, and update: A DBMS must furnish users with the ability to store, retrieve, and \\nupdate data in the database \\n \\n(2) A user-accessible catalog: A DBMS must furnish a catalog in which descriptions of data items are stored \\nand which is accessible to users.\\n(3) Transaction support: A DBMS must furnish a mechanism that will ensure either that all the updates \\ncorresponding to a given transaction are made or that none of them is made\\n(4) Concurrency control services: A DBMS must furnish a mechanism to ensure that the database is updated \\ncorrectly when multiple users are updating the database concurrently.\\n(5) Recovery services: A DBMS must furnish a mechanism for recovering the database in the event that the \\ndatabase is damaged in any way. \\n(6) Authorization services: A DBMS must furnish a mechanism to ensure that only authorized users can \\naccess the database.\\n \\n(7) Support for data communication: A DBMS must be capable of integrating with communication software. \\n(8) Integrity services: A DBMS must furnish a means to ensure that both the data in the database and \\nchanges to the data follow certain rules. \\n \\n(9) Services to promote data independence: A DBMS must include facilities to support the independence of \\nprograms from the actual structure of the database.\\n(10) Utility services: A DBMS should provide a set of utility services like backup, restore, etc.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 0, 'page_label': '1', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Introduction to Machine Learning \\n \\n \\nMachine learning is a method of data analysis that automates analytical \\nmodel building. It is a branch of artificial intelligence based on the idea that \\nsystems can learn from data,  identify patterns and make decisions with minimal \\nhuman intervention. \\nExample: Image recognition, Speech recognition, Medical diagnosis, Statistical \\narbitrage, Predictive analytics, etc. \\n \\n Artificial Intelligence, Machine Learning and Deep Learning \\n \\n\\uf0b7 Artificial Intelligence is defined as a program that exhibits cognitive \\nability similar to  that of a human being. It makes computers think like \\nhumans and solve problems the  way we do is one  of the main tenets of \\nartificial intelligence. \\n\\uf0b7 Any computer program that shows characteristi cs, such as self -\\nimprovement, learning  through inference, or even basic human tasks, \\nsuch as image recognition and language  processing, is considered to be a  \\nform of AI. \\n\\uf0b7 The field of artificial intelligence includes within it the sub -fields of \\nmachine learning and deep learning. \\n\\uf0b7 Deep Learning is a more specialized version of machine learning that \\nutilizes more complex methods for difficult problems.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 1, 'page_label': '2', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 2, 'page_label': '3', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Definition of machine learning \\nArthur Samuel, an early American leader in the field of  computer gaming and \\nartificial intelligence, coined the  term â€œMachine Learningâ€  in 1959  while at \\nIBM. \\nHe defined machine learning as â€œthe field of study that gives computers the \\nability to learn  without being explicitly programmed.â€ However, there is no \\nuniversally accepted definition  for machine learning. Different authors define \\nthe term differently. We give below two more definitions. \\n1. Machine learning is programming computers to optimize a performance \\ncriterion using example data or past experience. We have a model defined up to \\nsome parameters, and learning is the execution of a computer program to \\noptimize the parameters of the model using the  training data or past experience. \\nThe model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question \\nof how to  construct computer programs that automatically improve  with \\nexperience \\n \\n Definition of learning \\nA computer program is said to learn from experience E with respect to some \\nclass of tasks T  and performance measure P, if its performance at tasks T, as \\nmeasured by P, improves with experience E. \\n \\nExamples : \\ni) Handwriting recognition learning problem \\nâ€¢ Task T: Recognising and classifying handwritten words within images \\nâ€¢ Performance P: Percent of words correctly classified \\nâ€¢ Training experience E: A dataset of handwritten words with given classifications'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 3, 'page_label': '4', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='ii) A robot driving learning problem \\nâ€¢ Task T: Driving on highways using vision sensors'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 4, 'page_label': '5', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='â€¢ Performance measure P: Average distance traveled before an error \\nâ€¢ training experience: A sequence of images and steering commands recorded \\nwhile observing a human driver \\n \\niii) A chess learning problem \\nâ€¢ Task T: Playing chess \\nâ€¢ Performance measure P: Percent of games won against opponents \\nâ€¢ Training experience E: Playing practice games against itself \\n \\n \\nDefinition: A computer program which learns from experience is called a \\nmachine learning  program or simply a learning program. Such a program i s \\nsometimes also referred to as a learner. \\nBasic components of learning process \\nThe learning process, whether by a human or a machine, can be divided into four \\ncomponents, namely, data storage, abstraction, generalization and evaluation. \\nFigure 1.1 illustrates the  various components and  the steps involved in the  \\nlearning process. \\n \\n1. Data storage \\n \\n \\nFacilities for storing and retrieving huge amounts of data are an important \\ncomponent of the  learning process. Humans and computers alike utilize data \\nstorage as a foundation for advanced reasoning. \\nâ€¢ In a human being, the data is stored in the brain and data is retrieved using \\nelectrochemical signals. \\nâ€¢ Computers use hard disk drives, flash memory, random access memory and \\nsimilar devices  to store data and use cables and other  technology to retrieve'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 5, 'page_label': '6', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='data.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 6, 'page_label': '7', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='2. Abstraction \\n \\n \\nThe second component of the learning process is known as abstraction. \\nAbstraction is the  process of extracting knowledge about stored data. This \\ninvolves creating general concepts about the data as a whole. The creation of \\nknowledge involves application of known models  and creation of new models. \\nThe process of fitting a model to a dataset is known as training.  When the model \\nhas been trained, the data is transformed into an abstract form that summarizes the \\noriginal information. \\n \\n3. Generalization \\n \\n \\nThe third component of the learning process is known as generalisation. The \\nterm generalization describes the process of turning the knowledge about stored \\ndata into a form that can be utilized for future action. These actions are to be \\ncarried out on tasks that are similar,  but not identical, to those what have been \\nseen before. In generalization, the goal is to discover those properties of the data \\nthat will be most relevant to future tasks. \\n \\n4. Evaluation \\n \\n \\nEvaluation is the last component of the learning process. It is the process of \\ngiving feedback to the user to measure the utility of the learned knowledge. This \\nfeedback is then utilised to effect improvements in the whole learning process. \\n \\n        Applications of machine learning \\nThe following is a list of some of the typical applications of machine learning. \\n1. In retail business, machine learning is used to study consumer behaviour.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 7, 'page_label': '8', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='2. In finance, banks analyze their past data to build models to use in credit \\napplications, fraud detection, and the stock market. \\n3. In manufacturing, learning models are used for optimization, control, and troubleshooting. \\n4. In medicine, learning programs are used for medical diagnosis. \\n5. In telecommunications, call patterns are analyzed for network optimization \\nand maximizing the quality of service.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 8, 'page_label': '9', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='6. In science, large amounts of data in physics, astronomy, and biology can only \\nbe analyzed  fast enough by computers. The World Wide Web is huge; it is \\nconstantly growing and searching for relevant information  cannot be done \\nmanually. \\n7. In artificial intelligence, it is used to teach a system to learn and adapt to \\nchanges so that the system designer need  not foresee and provide solutions for \\nall possible situations. \\n8. It is used to find solutions to many problems in vision, speech recognition, and robotics. \\n9. Machine learning methods are applied in the design of computer-controlled \\nvehicles to steer correctly when driving on a variety of roads. \\n10. Machine learning methods have been used to develop programmes for \\nplaying games such as chess, backgammon and Go. \\n \\n Statistics vs Machine Learning \\n \\n \\nThe major difference between  machine learning and statistics is their purpose.  \\nMachine learning models are designed to make the most accurate predictions \\npossible. Statistical models are designed for  inference about the  relationships \\nbetween variables \\n1. Machine Learning is an algorithm that can learn from data without \\nrelying on rules- based programming. \\nStatistical modeling is a formalization of relationships between variables \\nin the data in the form of mathematical equations. \\n2. Machine learning is all about predictions, supervised learning, \\nunsupervised learning, etc. \\nStatistics is about sample, population, hypothesis, etc. \\n \\n3. Machine learning is a subfield of computer science and artificial \\nintelligence. It deals  with building systems that can learn from data, \\ninstead of explicitly programmed instructions.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 9, 'page_label': '10', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='A statistical model, on the other hand, is a subfield of mathematics. \\n4. Machine Learning is automated and requires less human intervention and \\nit deals with large datasets. \\nStatistics require a lot of human effort and deals with small datasets.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 10, 'page_label': '11', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Types of Machine Learning Algorithms: \\n \\nThese are three types of machine learning:  \\n \\n1. Supervised Learning \\n2. Unsupervised Learning \\n3. Reinforcement Learning \\n \\n \\n \\n \\n Supervised Learning: \\n \\n \\n\\uf0b7 Supervised learning is one of the most basic types of machine learning. \\n\\uf0b7 In this type, the machine learning algorithm is trained on labelled data. \\n\\uf0b7 In supervised learning, the ML algorithm is given a small training dataset to work \\nwith. \\n\\uf0b7 This training dataset is a smaller part of the bigger dataset and \\nserves to give the    algorithm a basic idea of the problem, solution, and \\ndata points to be dealt with. \\n\\uf0b7 At the end of the training, the algorithm has an idea of how the data'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 11, 'page_label': '12', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='works and the relationship between the input and the output. \\n\\uf0b7 Example: Risk Assessment, Image classification, Fraud Detection, spam filtering, \\netc. \\n \\n   How Supervised Learning Works? \\n \\nIn supervised learning, models are trained using labelled dataset, where the \\nmodel learns about each type of data. Once the training process is completed, the \\nmodel is tested on the basis of  test data (a subset of the training set), and then it \\npredicts the output. \\n \\nSuppose we have a dataset of different types of shapes which inclu des square, \\nrectangle, triangle, and Polygon. Now the first step is that we need to train the \\nmodel for each shape. \\n \\no If the given shape has four sides, and all the sides are equal, then it will \\nbe labelled as a Square. \\no If the given shape has three sides, then it will be labelled as a triangle. \\no If the given shape has six equal sides, then it will be labelled as hexagon. \\n \\nNow, after training, we test our model using the test set, and the task of the \\nmodel is to identify the shape. The machine is already trained on all types of \\nshapes, and when it finds a new shape, it classifies the shape  on the bases of a \\nnumber of sides, and predicts the output.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 12, 'page_label': '13', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 13, 'page_label': '14', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Advantages of Supervised learning: \\no With the help of supervised learning, the model can predict the output on \\nthe basis of prior experiences. \\no In supervised learning, we can have an exact idea about the classes of objects. \\n \\nDisadvantages of supervised learning: \\no Supervised learning models are not suitable for handling the complex tasks. \\no Supervised learning cannot predict the correct output if the test data is \\ndifferent from the training dataset. \\no Training required lots of computation times. \\n \\n Unsupervised Learning: \\n \\n\\uf0b7 Unsupervised machine learning holds the advantage of being able to work with \\nunlabelled data. \\n\\uf0b7 This means that human labour is not required to make the dataset \\nmachine-readable, allowing much larger datasets to be  worked on by  \\nthe program. \\n\\uf0b7 This offers more post-deployment development than supervised learning algorithms. \\n\\uf0b7 Example : Principal Component Analysis, Clustering \\n \\nHow Unsupervised Learning Works?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 14, 'page_label': '15', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=\"Here, we have taken an unlabelled input data, which \\nmeans it is not categorized and corresponding outputs \\nare also not given.  \\nNow, this unlabelled input data is fed to the machine \\nlearning model in order to train it. \\nFirstly, it will interpret the raw data  to find the hidden  \\npatterns from the data and then will apply suitable \\nalgorithms such as k-means clustering,  Decision tree, \\netc.  \\nOnce it applies the suitable algorithm, the algorithm \\ndivides the data objects into groups according to  the \\nsimilarities and difference between the objects. \\n \\nAdvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is used for more complex \\ntasks as compared to supervised learning because, \\nin unsupervised learning, we don't have labelled \\ninput data. \\n\\uf0b7 Unsupervised learning is preferable as it is easy to \\nget unlabelled data in comparison to labelled data. \\n \\nDisadvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is intrinsically more difficult \\nthan supervised learning as it does not have \\ncorresponding output.\"),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 15, 'page_label': '16', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 The result of the unsupervised learning algorithm \\nmight be less accurate as input data is not labelled, \\nand algorithms do not know the exact output in \\nadvance. \\n \\n Semi-Supervised learning \\nSemi-supervised learning bridges supervised learning \\nand unsupervised learning techniques  to solve their \\nkey challenges. With it, you train an initial model on a \\nfew labeled samples and then iteratively apply it to the  \\ngreater number of unlabeled data. \\n \\nâ€¢ SSL works for a variety of problems from \\nclassification and  regression to clustering  and \\nassociation. \\nâ€¢ uses small amounts of labeled data and also large  \\namounts of unlabeled data, which reduces expenses on \\nmanual annotation and cuts data preparation time. \\n \\nWorking of Semi-Supervised Learning \\nSemi-supervised learning uses pseudo labeling to train the \\nmodel with less labeled training data than supervised \\nlearning. The process can combine various neural network \\nmodels and training ways. \\nâ€¢ Firstly, it trains the model with less amount of \\ntraining data similar to the supervised learning \\nmodels. The training continues until the model gives'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 16, 'page_label': '17', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='accurate results. \\nâ€¢ The input data in labeled training data and unlabeled training \\ndata are also linked. \\nâ€¢ In the end, again train the model with the new \\ncombined input . \\nâ€¢ It will reduce errors and improve the accuracy of \\nthe model. \\n \\nSemi-supervised learning models applications \\no Speech Analysis \\no Web content classification \\no Text document classifier \\n \\n Reinforcement Learning \\n It is a part of ML where an agent is put in an \\nenvironment and he learns to behave in this \\nenvironment by performing certain actions and \\nobserving the rewards which it gets from those \\nactions. \\nFavourable outputs are encouraged or  â€˜reinforcedâ€™, \\nand non -favourable outputs  are discouraged or  \\nâ€˜punishedâ€™. \\n\\uf0b7 In every iteration of the algorithm, the output \\nresult is given to the interpreter, which  decides \\nwhether the outcome is favourable or not. \\n\\uf0b7 In case of the program finding the correct'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 17, 'page_label': '18', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='solution, the interpreter reinforces the solution by \\nproviding a reward to the algorithm.  \\n\\uf0b7 If the outcome is not favourable, the algorithm  is \\nforced to reiterate until it finds a better result.  \\n\\uf0b7 In most cases, the reward system is  directly tied to \\nthe effectiveness of the result. \\n\\uf0b7 In typical reinforcement learning use -cases, such \\nas finding the shortest route between  two points \\non a map. The higher this percentage value is,  the \\nmore reward is given to the algorithm. \\n\\uf0b7 Thus, the program is trained to give the best \\npossible solution for the best possible reward. \\nReinforcement Learning Applications'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 18, 'page_label': '19', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 19, 'page_label': '20', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 20, 'page_label': '21', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Difference Between Supervised, Unsupervised and Reinforcement \\nLearning'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 21, 'page_label': '22', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Types of Reinforcement learning \\n \\nThere are mainly two types of reinforcement learning, which are: \\n \\n\\uf0b7 Positive Reinforcement \\nThe positive reinforcement learning means \\nadding something to increase the tendency that expected \\nbehaviour would occur again. It impacts positively on \\nthe behaviour of the agent and increases the strength of \\nthe behaviour. This type of reinforcement can sustain the \\nchanges for a long time, but too much positive \\nreinforcement may lead to an overload of  states that can \\nreduce the consequences. \\n \\n\\uf0a7 Negative Reinforcement: \\nThe negative reinforcement learning is \\nopposite to the positive reinforcement as it increases the \\ntendency that the specific behaviour will occur again by \\navoiding the negative \\ncondition. It can be more effective than the positive \\nreinforcement depending on situation and behaviour, but it \\nprovides reinforcement only to meet minimum behaviour.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 22, 'page_label': '23', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='ML  Understanding Hypothesis \\n \\nIn most supervised machine learning algorithm, our main goal is to find \\nout a possible hypothesis from the hypothesis space that could \\npossibly map out the inputs to the proper outputs. \\nThe following figure shows the common method to find out the possible \\nhypothesis from the Hypothesis space: \\n \\n \\nHypothesis Space (H): \\nHypothesis space is the set of all the possible legal hypothesis. This is \\nthe set from which the machine learning algorithm would determine the \\nbest possible (only one) which would best describe the target function or \\nthe outputs. \\nHypothesis (h): \\nA hypothesis is a function that best describes the target in supervised'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 23, 'page_label': '24', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='machine learning. The hypothesis that an algorithm would come up \\ndepends upon the data and also depends upon the restrictions and \\nbias that we have imposed on the data. To better understand the \\nHypothesis Space and Hypothesis consider the following coordinate that \\nshows the distribution of some data:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 24, 'page_label': '25', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Say suppose we have test data for which we have to determine the \\noutputs or results. The test data is as shown below:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 25, 'page_label': '26', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='We can predict the outcomes by dividing the coordinate as shown \\nbelow:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 26, 'page_label': '27', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='So the test data would yield the following result: \\n \\nBut note here that we could have divided the coordinate plane as:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 27, 'page_label': '28', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The way in which the coordinate would be divided depends on the data, \\nalgorithm and constraints. \\n  All these legal possible ways in which we can divide the coordinate \\nplane to predict the outcome of the test data composes of the \\nHypothesis Space. \\n  Each individual possible way is known as the hypothesis. \\nHence, in this example the hypothesis space would be like:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 28, 'page_label': '29', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 29, 'page_label': '30', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Hypothesis Testing in statistics \\n \\nHypothesis are statement about the given problem. \\n Hypothesis testing is a statistical method that is used in making a \\nstatistical decision using experimental data. \\n Hypothesis testing is basically an assumption that we make about a \\npopulation parameter. It evaluates two mutually exclusive statements \\nabout a population to determine which statement is best supported by the \\nsampledata    \\nExample: \\nYou say an average student in the class is 30  or a boy is taller than \\ngirls. All those are an example in which we assume or need some \\nstatistic way to prove those. We need some mathematical conclusion \\nwhatever we are assuming is true. \\nNeed for Hypothesis Testing \\nHypothesis testing is an important procedure in statistics. Hypothesis \\ntesting evaluates two mutually exclusive population statements to \\ndetermine which statement is most supported by sample data. When we \\nsay that the findings are statistically significant. \\n \\nParameters of hypothesis testing \\n \\n\\uf0b7 Null hypothesis(H0):  In statistics, the null hypothesis is a general \\ngiven statement or default position that there is no relationship \\nbetween two measured cases or no relationship among groups.  \\nIn other words, it is a basic assumption or made based on the problem \\nknowledge. \\n\\uf0b7 This hypothesis is either rejected or not rejected based on the \\nviability of the given   population or sample . \\nExample: A company production is = 50 unit/per day etc. \\n\\uf0b7 Alternative hypothesis(H1):  The alternative hypothesis is the \\nhypothesis used in hypothesis testing that is contrary to the null \\nhypothesis.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 30, 'page_label': '31', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Example : A company production is not equal to 50 unit/per day etc. \\n\\uf0b7 Level of significance \\nIt refers to the degree of significance in which we accept or reject the \\nnull-hypothesis. 100% accuracy is not possible for accepting a \\nhypothesis, so we, therefore, select a level of significance that is \\nusually 5%. This is normally denoted with and generally, it is 0.05 or \\n5%, which means your output should be 95% confident(significance \\nlevel is accepted) to give similar kind of result in each sample. \\n\\uf0b7 P-value \\nThe P value, or calculated probability, is the probability of finding the \\nobserved/extreme results when the  null hypothesis(H0) of a study \\ngiven problem is true.  \\n-If your P-value is less than the chosen significance level then you \\nreject the null hypothesis i.e. accept that your sample claims to \\nsupport the alternative hypothesis. \\n-P-Value is a statistical measure, that helps to determine whether \\nthe hypothesis is correct or not. \\nExample : \\nGiven a coin and it is not known whether that is fair or tricky so letâ€™s \\ndecide null and alternate hypothesis \\n\\uf0b7 Null Hypothesis(H0): a coin is a fair coin. \\n\\uf0b7 Alternative Hypothesis(H1) : a coin is a tricky coin. \\n \\nNow letâ€™s toss the coin and calculate p-value (probability value). \\n\\uf0b7 Toss a coin 1st time and assume that result is head- P-value =50  (as \\nhead and tail have equal probability) \\n\\uf0b7 Toss a coin 2nd time and assume that result again is head, now p-\\nvalue = (1/2) * 50 ==50/2= 25 \\nError in Hypothesis Testing \\n\\uf0b7 Type I error: When we reject the null hypothesis, although that \\nhypothesis was true. Type I error is denoted by alpha. \\n\\uf0b7 Type II errors: When we accept the null hypothesis but it is false. \\nType II errors are denoted by beta.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 31, 'page_label': '32', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='What is Generalization in Machine Learning? \\nDefinition of generalization \\nIn machine learning, generalization is a definition to demonstrate how \\nwell is a trained model to classify or forecast unseen data.  \\nAn example is when we train a model to classify between dogs and \\ncats. If the model is provided with dogs images dataset with only two \\nbreeds, it may obtain a good performance.  \\nBut, it possibly gets a low classification score when it is tested by other \\nbreeds of dogs as well.  \\nTherefore, data diversity (decrease redundancy) is very important factor \\nin order to make a good prediction. In the sample above, the model may  \\nobtain 85% performance score when it is tested by only two dog breeds \\nand gains 70% if trained by all breeds. \\n However, the first possibly gets a very low score (e.g. 45%) if it is \\nevaluated by an unseen dataset with all breed dogs. This for the latter \\ncan be unchanged given than it has been trained by high data diversity \\nincluding all possible breeds. \\nIt should be taken into account that data diversity is not the only point to \\ncare in order to have a generalized model.  \\nIn this post we explain all determinant factors. There are some \\nmethods (regularization) to apply during model training to ensure \\nabout generalization. But before, we explain bias and variance as \\nwell as underfitting and overfitting. \\nVariance and bias (overfitting and underfitting) \\nVariance and bias are two important terms in machine learning.  \\nVariance means the variety of predictions values  made by a machine \\nlearning model (target function). (Variance describes how much a \\nrandom variable differs from its expected value. )'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 32, 'page_label': '33', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Bias means the distance of the predictions from the actual (true) target \\nvalues (bias is the amount that a modelâ€™s prediction differs from the \\ntarget value, compared to the training data. ) \\n A high -biased model means its prediction values (average) are far \\nfrom the actual values. (High bias would cause an algorithm to miss \\nrelevant relations between the input features and the target outputs. This \\nis sometimes referred to as underfitting.) \\nAlso, high-variance prediction means the prediction values are highly \\nvaried.(  a model that tries to fit most of the training dataset points making it \\ncomplex) \\nVariance-bias trade-off \\nThe prediction results of a machine learning model stand somewhere \\nbetween \\na) low-bias, low-variance,  \\nb) low-bias, high-variance (overfit) \\nc) high-bias, low-variance, and  \\nd) high-bias, high-variance.(underfit) \\n \\nA low-biased, high-variance model is called overfit and a high -biased, \\nlow-variance model is called underfit.  \\nBy generalization, we find the best trade -off between underfitting and \\noverfitting so that a trained model obtains the best performance. \\n An overfit model obtains a  high prediction score on seen data and low \\none from unseen datsets. (data new to the model that was not part of the \\ntraining. ) \\nAn underfit model has low performance in both seen and unseen \\ndatasets.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 33, 'page_label': '34', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Three models with underfitting (left), goodfit ( middle), and overfitting \\n(right). Credit: https://scikit -learn.org/\\nOverfitting/overtraining in supervised learning (e.g., neural network). \\nTraining error is shown in blue, validation error in red, both as a \\nfunction of the number of training cycles. I f th e validation error \\nincreases(positive slope) while the training error steadily \\ndecreases(negative slope) then a situation of overfitting may have'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 34, 'page_label': '35', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='occurred. The best predictive and fitted model would be where the \\nvalidation error has its global minimum.  \\nDeterminant factors to train generalized models \\nThere are different ways to secure that a machine learning model is \\ngeneralized. Below we explain them. \\nDataset \\nIn order to train a classifier and generate a generalized machine learning \\nmodel, a used dataset should contain diversity. It should be noted that it \\ndoesnâ€™t mean a huge dataset but a dataset containing all different \\nsamples. This helps classifier to be trained not only from a specific \\nsubset of data and therefore, the generalization is better fulfil led. In \\naddition, during training, it is recommended to use  \\ncross validation techniques such as K -fold or Monte -Carlo cross \\nvalidations. These techniques better secure to exploit all possible \\nportions of data and to avoid generating an overfit model. \\nMachine Learning algorithm \\nMachine learning algorithms differently act against overfitting, \\nunderfitting. Overfitting is more likely with nonlinear, non -parametric \\nmachine learning algorithms. For instance, Decision Tree is a non -\\nparametric machine learning algorithms, meaning its model is more \\nlikely with overfitting.  On the other hand, some machine learning \\nmodels are too simple to capture complex underlying patterns in data. \\nThis cause to build an underfit model. Examples are linear and \\nlogistic regression. \\nModel complexity \\nWhen a machine learning models becomes too complex, it is usually \\nprone to overfitting. There are methods that help to make the model \\nsimpler. They are called Regularization methods. Following we explain \\nit.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 35, 'page_label': '36', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Regularization \\nRegularization i s collection of methods to make a machine learning \\nmodel simpler. To this end, certain approaches are applied to different \\nmachine learning algorithms, for instance, pruning for decision trees, \\ndropout techniques for neural networks (reduction in overfittin g), \\nand adding a penalty parameters to the cost function in Regression.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 36, 'page_label': '37', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 37, 'page_label': '38', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Bias and Variance in Machine Learning \\n\\uf0b7 Machine learning is a branch of Artificial Intelligence, which allows machines to  \\nPerform data analysis and make predictions.  \\n\\uf0b7 However, if the machine learning model is not accurate, it can make predictions errors, \\n and these prediction errors are usually known as Bias and Variance. \\n\\uf0b7 In machine learning, these errors will always be present as there is always a slight  \\ndifference  between the model predictions and actual predictions.  \\n\\uf0b7 The main aim of ML/data science analysts is to reduce these errors in order to get more \\n accurate results. In this topic,  we are going to discuss bias and variance, Bias-variance \\n trade-off,  Underfitting  and Overfitting.  \\n \\n \\nwhat errors in Machine learning are?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 38, 'page_label': '39', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=\"Errors in Machine Learning? \\nIn machine learning, an error is a measure of how accurately an algorithm can make  \\npredictions for the previously unknown dataset. On the basis of these errors, the machine \\n learning model is selected that can perform best on the particular dataset. There are mainly  \\ntwo types of errors in machine learning, which are: \\no Reducible errors: These errors can be reduced to improve the model accuracy.  \\nSuch errors can further be classified into bias and  Variance. \\no Irreducible errors: These errors will always be present in the model \\n   regardless of which algorithm has been used. The cause of these errors is unknown  \\n   variables whose value can't be reduced. \\no\"),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 39, 'page_label': '40', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='What is Bias? \\n  In general, a machine learning model analyses the data, find patterns in it and make \\n predictions.  \\n While training, the model learns these patterns in the dataset and applies them to test data \\n for prediction.  \\nWhile making predictions, a difference occurs between prediction values  \\nmade by the model and actual values/expected values, and this difference is known as \\n bias errors or Errors due to bias.  \\nIt can be defined as an inability of machine learning algorithms such as Linear  \\nRegression to capture the true relationship between the data points.  \\nEach algorithm begins with some amount of bias because bias occurs from assumptions'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 40, 'page_label': '41', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='in the model, which makes the target function simple to learn. A model has either: \\no Low Bias: A low bias model will make fewer assumptions about the form of the target  \\nfunction. \\no High Bias: A model with a high bias makes more assumptions, and the model  \\nbecomes unable to capture the important features of our dataset. A high bias model  \\nalso cannot perform well on new data. \\nGenerally, a linear algorithm has a high bias, as it makes them learn fast. The simpler the \\n algorithm, the higher the bias it has likely to be introduced. Whereas a nonlinear algorithm  \\noften has low bias. \\nSome examples of machine learning algorithms with low bias are Decision Trees,  \\nk-Nearest  Neighbours and Support Vector Machines. At the same time, an algorithm  \\nwith high bias  is Linear Regression, Linear Discriminant Analysis and Logistic \\n Regression. \\nWays to reduce High Bias: \\nHigh bias mainly occurs due to a much simple model. Below are some ways to reduce \\n the high bias: \\no Increase the input features as the model is underfitted. \\no Decrease the regularization term. \\no Use more complex models, such as including some polynomial features. \\nWhat is a Variance Error?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 41, 'page_label': '42', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The variance would specify the amount of variation in the prediction if the different training  \\ndata was used. In simple words, variance tells that how much a random variable is  \\ndifferent from its expected value. Ideally, a model should not vary too much from one  \\ntraining dataset to another, which means the algorithm should be good in understanding \\n the hidden mapping between inputs and output variables. Variance errors are either of  \\nlow variance or high variance. \\nLow variance means there is a small variation in the prediction of the target function with  \\nchanges in the training data set.  \\nAt the same time, High variance shows a large variation in the prediction of the target \\n function with changes in the training dataset. \\nA model that shows high variance learns a lot and perform well with the training dataset,  \\nand does not generalize well with the unseen dataset. As a result, such a model gives  \\ngood results with the training dataset but shows high error rates on the test dataset. \\nSince, with high variance, the model learns too much from the dataset, it leads to overfitting  \\nof the model. A model with high variance has the below problems: \\no A high variance model leads to overfitting. \\no Increase model complexities. \\nUsually, nonlinear algorithms have a lot of flexibility to fit the model, have high variance.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 42, 'page_label': '43', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Some examples of machine learning algorithms with low variance are, Linear Regression,  \\nLogistic Regression, and Linear discriminant analysis. At the same time, algorithms with high  \\nvariance are decision tree, Support Vector Machine, and K-nearest neighbours. \\nWays to Reduce High Variance: \\no Reduce the input features or number of parameters as a model is overfitted. \\no Do not use a much complex model. \\no Increase the training data. \\no Increase the Regularization term. \\nDifferent Combinations of Bias-Variance \\nThere are four possible combinations of bias and variances, which are represented by the  \\nbelow diagram:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 43, 'page_label': '44', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='1. Low-Bias,LowVariance Low-Variance: \\nThe combination of low bias and low variance shows an ideal machine learning \\n model. However, it is not possible practically. \\n2. Low-Bias, High-Variance: With low bias and high variance, model predictions \\n are inconsistent and accurate on average. This case occurs when the model learns \\n with a large number of parameters and hence leads to an overfitting \\n3. High-Bias, Low-Variance: With High bias and low variance, predictions are  \\nconsistent but inaccurate on average. This case occurs when a model does not learn \\n well with the training dataset or uses few numbers of the parameter. It leads to \\n underfitting problems in the model. \\n4. HighBias,HighVariance  High-Variance:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 44, 'page_label': '45', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='With high bias and high variance, predictions are inconsistent and also inaccurate \\non average. \\nHow to identify High variance or High Bias? \\nHigh variance can be identified if the model has: \\n \\no Low training error and high test error. \\nHigh Bias can be identified if the model has: \\no High training error and the test error is almost similar to training error. \\n \\n \\nBias-Variance Trade-Off \\nWhile building the machine learning model, it is really important to take care of bias and \\n variance in order to avoid overfitting and underfitting in the model. If the model \\nis very simple with fewer parameters, it may have low variance and high bias. Whereas,'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 45, 'page_label': '46', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='if the model has a large number of parameters, it will have high variance and low bias.  \\nSo, it is required to make a balance between bias and variance errors, and this balance  \\nbetween the bias error and variance error is known as the Bias-Variance trade-off. \\n \\nFor an accurate prediction of the model, algorithms need a low variance and low bias.  \\nBut this is not possible because bias and variance are related to each other: \\no If we decrease the variance, it will increase the bias. \\no If we decrease the bias, it will increase the variance. \\nBias-Variance trade-off is a central issue in supervised learning. Ideally, we need a model \\n that accurately captures the regularities in training data and simultaneously generalizes \\n well with the unseen dataset. Unfortunately, doing this is not possible simultaneously.  \\nBecause a high variance algorithm may perform well with training data, but it may lead to'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 46, 'page_label': '47', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='overfitting to noisy data. Whereas, high bias algorithm generates a much simple model  \\nthat may not even capture important regularities in the data. So, we need to find a  \\nsweet spot between bias and variance to make an optimal model. \\nHence, the Bias-Variance trade-off is about finding the sweet spot to make a balance \\n between bias and variance errors.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d117d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\",\"\\n\",\" \", \"\"]\n",
    "    )\n",
    "    split_docs=text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample Chunk:\")\n",
    "        print(f\"Content:{split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata:{split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1606b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 85 documents into 146 chunks\n",
      "\n",
      "Example Chunk:\n",
      "Content:lOMoARcPSD|285 747 87 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "UNIT V       DESIGN AND ANALYSIS OF MACHINE LEARNING EXPERIMENTS         8 \n",
      "Guidelines for machine learning experiments, Cross Validation (CV) and resampling â€“ K- \n",
      "fold ...\n",
      "Metadata:{'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n \\n \\nUNIT V       DESIGN AND ANALYSIS OF MACHINE LEARNING EXPERIMENTS         8 \\nGuidelines for machine learning experiments, Cross Validation (CV) and resampling â€“ K- \\nfold CV, bootstrapping, measuring classifier performance, assessing a single classification \\nalgorithm and comparing two classification algorithms â€“ t test, Mc Nemarâ€™s test, K -fold \\nCV paired t test \\n \\n5.1 Guidelines for Machine Learning Experiments \\n \\nThe steps in machine learning are the same as for any type of \\nexperimentation, that at this point, it is  not important whether the task  \\nis classiï¬cation or regression, or whether it is an unsupervised or a  \\nreinforcement learning application. The same overall discussion \\napplies; the diï¬€erence is only in the sampling distribu- tion of the \\nresponse data that is collected. \\n \\nA. Aim of the Study \\nGiven two learning algorithms and a particular problem as deï¬ned  \\nbya dataset, we may want to determine which one has less generalization'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='response data that is collected. \\n \\nA. Aim of the Study \\nGiven two learning algorithms and a particular problem as deï¬ned  \\nbya dataset, we may want to determine which one has less generalization \\nerror. These can be two diï¬€erent algorithms, or one can be a proposed  \\nimprovement of the other, for example, by using a better feature extrac - \\ntor.In the general case, we may have more than two learning algorithms,  \\nand we may want to choose the one with the least error, or order them in \\nterms of error, for a given dataset.In an even more general setting, instead  of \\non a single dataset, we may want to compare two or more algorithms  on \\ntwo or more datasets. \\n \\nB. Selection of the Response Variable \\nWe need to decide on what we should use as the quality measure.  \\nMost frequently, error is used that is the misclassiï¬cation error for \\nclassiï¬ca- tion and mean square error for regression. We may also use  \\nsome variant;for example, generalizing from 0/1 to an arbitrary  loss, we'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='classiï¬ca- tion and mean square error for regression. We may also use  \\nsome variant;for example, generalizing from 0/1 to an arbitrary  loss, we \\nmay use a riskmeasure. In information retrieval, we use measures such as \\nprecision andrecall. In a cost-sensitive setting, not only the output but also \\nsystem parameters, for example, its complexity, are taken into account. \\n \\nC. Choice of Factors and Levels \\nWhat the factors are depend on the aim of the study. If we ï¬x an  \\nal- gorithm and want to ï¬nd the best hyperparameters,  then those are \\nthe factors. If we are comparing algorithms, the learning algorithm is a  \\nfac-tor. If we have diï¬€erent datasets, they also become a factor. \\nThe levels of a factor should be carefully chosen so as not to miss a'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ngood conï¬guration and avoid doing unnecessary experimentation. It is  \\nalways good to try to normalize factor levels. For example, in optimizing  \\nk of k-nearest neighbor, one can try values such as 1, 3, 5, and so on, but  \\nin optimizing the spread h of Parzen windows, we should not try absolute  \\nvalues such as 1.0, 2.0, and so on, because that depends on the scale of  \\nthe input; it is better to ï¬nd some statistic that is an indicator of scale â€” \\nfor example, the average distance between an instance and its nearest  \\nneighborâ€”and try h as diï¬€erent multiples of that statistic. \\n \\nD. Choice of Experimental Design \\nIt is always bett er to do a factorial design unless we are sure that  \\nthe factors do not interact, because mostly they do. Replication \\nnumber de -pends on the dataset size; it can be kept small when the  \\ndataset is large;we will discuss this in the next section when we talk  \\nabout resampling.However, too few replicates generate few data and'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='dataset is large;we will discuss this in the next section when we talk  \\nabout resampling.However, too few replicates generate few data and  \\nthis will make com-paring distributions diï¬ƒcult; in the particular case of \\nparametric tests, the assumptions of Gaussianity may not be tenable. \\nGenerally, given some dataset, we leave some part as the test set and \\nuse the rest for training and validation, probably many times by resam - \\npling. How this division is done is important. In practice, using small  \\ndatasets leads to responses with high variance, and the diï¬€erences will  \\nnot be signiï¬cant and results will not be conclusive. \\nIt is also important to avoid as much as possible toy,  synthetic data \\nand use datasets that are collected from real -world under real -life cir - \\ncumstances. Didactic one - or two -dimensional datasets may help pro vide \\nintuition, but the behavior of the algorithms may be completely diï¬€erent \\nin high-dimensional spaces. \\n \\nE. Performing the Experiment'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='intuition, but the behavior of the algorithms may be completely diï¬€erent \\nin high-dimensional spaces. \\n \\nE. Performing the Experiment \\nBefore running a large factorial experiment with many factors and  \\nlevels,it is best if one does a few trial runs for some r andom settings to  \\ncheck that all is as expected. In a large experiment, it is always a good idea \\nto save intermediate results (or seeds of the random number generator),  \\nso that a part of the whole experiment can be rerun when desired. All the \\nresults should be reproducable. In running a large experiment with many \\nfactors and factor levels, one should be aware of the possible negative  \\neï¬€ects of software aging. \\nIt is important that an experimenter be unbiased during experimen- \\ntation. In comparing oneâ€™s favorite algorithm with a competitor, both  \\nshould be investigated equally diligently. In large -scale studies, it may  \\neven be envisaged that testers be diï¬€erent from developers.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='should be investigated equally diligently. In large -scale studies, it may  \\neven be envisaged that testers be diï¬€erent from developers. \\nOne should avoid the temptation to write oneâ€™s own â€œlibraryâ€ and \\nin- stead, as much as possible, use code from  reliable  sources;  such code \\nwould have been better tested and optimized. \\nAs in any software development study, the advantages of good docu-\\nmentation cannot be underestimated, especially when working in'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ngroups.All the methods developed for high -quality software engineering  \\nshould also be used in machine learning experiments. \\n \\nF. Statistical Analysis of the Data \\nThis corresponds to analyzing data in a way so that whatever \\nconclusion we  get is not subjective or due to chance. We cast the \\nquestions thatwe want to answer in a hypothesis testing framework and  \\ncheck whether the sample supports the hypothesis.  For example, the  \\nquestion \"Is A a more accurate algorithm than B?\" becomes the \\nhypothesis \"Can we say tha t the average error of learners trained by A is \\nsigniï¬cantly lower than the average error of learners trained by B?\" \\nAs always, visual analysis is helpful, and we can use histograms of  \\nerrordistributions, whisker-and-box plots, range plots, and so on \\n \\nG. Conclusions and Recommendations \\nOnce all data is collected and analyzed, we can draw objective \\nconclu- sions. One frequently encountered conclusion is the need for'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='G. Conclusions and Recommendations \\nOnce all data is collected and analyzed, we can draw objective \\nconclu- sions. One frequently encountered conclusion is the need for  \\nfurther experimentation. Most statistical, and hence machine learning or \\ndata mining, studies are iterative. It is for this reason that we never start \\nwith all the experimentation. It is suggested that no more than 25 \\npercent of the available resources should be invested in the ï¬rst \\nexperiment (Mont - gomery 2005). The ï¬rst runs are for investigation \\nonly. That is also why it is a good idea not to start with high expectations, \\nor promises to oneâ€™s boss or thesis advisor. \\nWe should always remember that statistical testing never tells us \\nif the hypothesis is correct or false, but how much the sample seems  \\nto concur with the hypothesis. There is always a risk that we do not  \\nhave aconclusive result or that our conclusions be wrong, especially if  \\nthe data is small and noisy.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='to concur with the hypothesis. There is always a risk that we do not  \\nhave aconclusive result or that our conclusions be wrong, especially if  \\nthe data is small and noisy. \\nWhen our expectations are not met, it is most helpful to investigate  \\nwhythey are not. For example, in checking why our favorite algorithm A \\nhas worked awfully bad on some cases, we can get a splendid idea for  \\nsome improved version of A. All improvements are due to the \\ndeï¬ciencies of the previous version;  ï¬nding a deï¬ciency is but a helpful  \\nhint that there is an improvement we can make! \\nBut we should not go to the next step of testing the improved version  \\nbefore we are sure that we have completely analyzed the current data  \\nandlearned all we could learn from it. Ideas are cheap, and useless unless \\ntested, which is costly. \\n \\n5.2 Cross-Validation and Resampling Methods \\n\\uf0b7 For replication purposes, our first need is to get a number of training'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='tested, which is costly. \\n \\n5.2 Cross-Validation and Resampling Methods \\n\\uf0b7 For replication purposes, our first need is to get a number of training \\nand validation set pairs from a dataset X (after having left out some \\npart as the test set). \\n\\uf0b7 To get them, if the sample X is large enough, we can randomly divide it \\ninto K parts, then randomly divide each part into two and use one half  \\nfor training and the other half for validation.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 K is typically 10 or 30. Unfortunately, datasets are never large enough \\nto do this. \\n\\uf0b7 So we should do our best with small datasets. \\n\\uf0b7 This is done cross-validation by repeated use of the same data split \\ndifferently; this is called crossvalidation. \\n\\uf0b7 The catch is that this makes the error percentages dependent as these \\ndifferent sets share data. \\n\\uf0b7 So, given a dataset X, we would like to generate K training/validation \\nset pairs, {Ti, Vi}K i=1, from this dataset. \\n\\uf0b7 We would like to keep the training and validation sets as large as \\npossible so that the error estimates are robust, and at the same time, \\nwe would like to keep the overlap between different sets as small as \\npossible. \\n\\uf0b7 We also need to make sure that classes are represented in the right \\nproportions when subsets of data are held out, not to disturb the class \\nprior probabilities; this is called stratification. \\n\\uf0b7 If a class has 20 percent examples in the whole dataset, in all samples'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='prior probabilities; this is called stratification. \\n\\uf0b7 If a class has 20 percent examples in the whole dataset, in all samples  \\ndrawn from the dataset, it should also have approximately 20 percent \\nexamples. \\n5.3K-Fold Cross-Validation \\n\\uf0b7 K-fold In K-fold cross-validation, the dataset X is divided randomly into K \\nequalcross-validation sized parts, Xi, i = 1,...,K. \\n\\uf0b7 To generate each pair, we keep one of the K parts out as the validation set \\nand combine the remaining K âˆ’ 1 parts to form the training set. \\n\\uf0b7 Doing this K times, each time leaving out another one of the K parts out, we \\nget K pairs: V1 = X1 T1 = X2 ð–´ X3 ð–´Â·Â·Â·ð–´XK V2 = X2 T2 = X1 ð–´ X3 ð–´Â·Â·Â·ð–´XK . . . \\nVK = XK TK = X1 ð–´ X2 ð–´Â·Â·Â·ð–´XKâˆ’1 \\n\\uf0b7 There are two problems with this. First, to keep the training set large, we \\nallow validation sets that are small. \\n\\uf0b7 Second, the training sets overlap considerably, namely, any two training sets \\nshare K âˆ’ 2 parts. K is typically 10 or 30.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='allow validation sets that are small. \\n\\uf0b7 Second, the training sets overlap considerably, namely, any two training sets \\nshare K âˆ’ 2 parts. K is typically 10 or 30. \\n\\uf0b7 As K increases, the percentage of training instances increases and we get \\nmore robust estimators, but the validation set becomes smaller. \\n\\uf0b7 Furthermore, there is the cost of training the classifier K times, which \\nincreases as K is increased. \\n\\uf0b7 As N increases, K can be smaller; if N is small, K should be large to allow large \\nenough training leave-one-out sets. \\n\\uf0b7 One extreme case of K-fold cross-validation is leave-one-out where given a \\ndataset of N instances, only one instance is left out as the validation set \\n(instance) and training uses the N âˆ’ 1 instances.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 We then get N separate pairs by leaving out a different instance at each \\niteration. \\n\\uf0b7 This is typically used in applications such as medical diagnosis, where \\nlabeled data is hard to find. \\n\\uf0b7  Leave-one-out does not permit stratification. Recently, with computation \\ngetting cheaper, it has also become possible to have multiple runs of K-fold \\ncross-validation, for example, 10Ã—10- fold, and use average over averages to \\nget more reliable error estimates \\n5Ã—2 Cross-Validation \\n\\uf0b7 Dietterich (1998) proposed the 5 Ã— 2 cross-validation, which uses training \\nand validation sets of equal size. \\n\\uf0b7 We divide the dataset X randomly into two parts, X(1) 1and X(2) 1, which gives \\nour first pair of training and validation sets, T1 = X(1) 1and V1 = X(2) 1. \\n\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we \\nshuffle X randomly and divide this new fold into two, X(1) 2and X(2) 2. \\n\\uf0b7 This can be implemented by drawing these from X randomly without \\nreplacement, namely, X(1) 1ð–´ X(2) 1= X(1) 2ð–´ X(2) 2 = X. \\n\\uf0b7 We then swap these two halves to get another pair. We do this for three \\nmore folds and because from each fold, we get two pairs, doing five folds, we \\nget ten training and validation sets: T1 = X(1) 1V1 = X(2) 1T2 = X(2) 1 V2 = X(1) 1 \\nT3 = X(1) 2 V3 = X(2) 2 T4 = X(2) 2 V4 = X(1) 2  . . . T9 = X(1) 5 V9 = X(2) 5 T10 = X(2) \\n5 V10 = X(1) 5 Of course, we can do this for more than five folds and get more \\ntraining/validation sets, but Dietterich (1998) points out that after five \\nfolds, the sets share many instances and overlap so much that the statistics'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='training/validation sets, but Dietterich (1998) points out that after five \\nfolds, the sets share many instances and overlap so much that the statistics \\ncalculated from these sets, namely, validation error rates, become too \\ndependent and do not add new information. \\n\\uf0b7 Even with five folds, the sets overlap and the statistics are dependent, but \\nwe can get away with this until five folds. On the other hand, if we do have \\nfewer than five folds, we get less data (fewer than ten sets) and will not have \\na large enough sample to fit a distribution to and test our hypothesis on \\nTable 19.1 Confusion matrix for two  \\nclasses. \\n \\n Predicted \\nclass \\nTrue \\nClass \\nPositi \\nve \\nNegati \\nve \\nTot \\nal \\nPositive \\nNegative \\ntp : true \\npositive \\nfp : false \\npositive \\nfn : false \\nnegative \\ntn : true \\nnegative \\np \\nn \\nTotal pÃ— nÃ— N'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n \\nBootstrapping \\n\\uf0b7 To generate multiple samples from a single sample, an alternative to \\nbootstrap cross-validation is the bootstrap that generates new samples by \\ndrawing instances from the original sample with replacement. \\n\\uf0b7 We saw the use of bootstrapping in section 17.6 to generate training sets for \\ndifferent learners in bagging. \\n\\uf0b7 The bootstrap samples may overlap more than cross-validation samples and \\nhence their estimates are more dependent; but is considered the best way to \\ndo resampling for very small datasets. \\n\\uf0b7 In the bootstrap, we sample N instances from a dataset of size N with \\nreplacement. \\n\\uf0b7 The original dataset is used as the validation set. The probability that we pick \\nan instance is 1/N; the probability that we do not pick it is 1 âˆ’ 1/N. \\n\\uf0b7 The probability that we do not pick it after N draws is \\n( 1 âˆ’ 1 /N)N â‰ˆ eâˆ’1 = 0.368 \\nThis means that the training data contains approximately 63.2 percent of the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 The probability that we do not pick it after N draws is \\n( 1 âˆ’ 1 /N)N â‰ˆ eâˆ’1 = 0.368 \\nThis means that the training data contains approximately 63.2 percent of the \\ninstances; that is, the system will not have been trained on 36.8 percent of the data, \\nand the error estimate will be pessimistic. The solution is replication, that is, to \\nrepeat the process many times and look at the average behavior. \\n \\n5.3 Measuring Classifier Performance \\nFor classification, especially for two-class problems, a variety of measures \\nhas been proposed. There are four possible cases, as shown in table 19.1. For a \\npositive example, if the prediction is also positive, this is a true positive; if our \\nprediction is negative for a positive example, this is a false negative. For a negative \\nexample, if the prediction is also negative, we \\nTable 19.2 Performance measures used in two - \\nclass problems. \\n \\nName Formula \\nerror \\naccuracy \\n(f  p  + fn)/N \\n(tp + tn)/N = 1- \\nerror \\ntp-rate \\nfp-rate \\ntp/p \\nfp/n'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Table 19.2 Performance measures used in two - \\nclass problems. \\n \\nName Formula \\nerror \\naccuracy \\n(f  p  + fn)/N \\n(tp + tn)/N = 1- \\nerror \\ntp-rate \\nfp-rate \\ntp/p \\nfp/n \\nprecision \\nrecall \\ntp/pâ€™ \\ntp/p = tp-rate \\nsensitivity \\nspeciï¬city \\ntp/p = tp-rate \\ntn/n = 1- fp-rate \\nhave a true negative, and we have a false positive if we predict a negative example as \\npositive.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nIn some two-class problems, we make a distinction between the two classes \\nand hence the two type of errors, false positives and false negatives. Different \\nmeasures appropriate in different settings are given in table 19.2. Let us envisage an \\nauthentication application where, for example, users log on to their accounts by \\nvoice. A false positive is wrongly logging on an impostor and a false negative is \\nrefusing a valid user. It is clear that the two type of errors are not equally bad; the \\nformer is much worse. True positive rate, tp-rate, also known as hit rate, measures \\nwhat proportion of valid users we authenticate and false positive rate, fp-rate, also \\nknown as false alarm rate, is the proportion of impostors we wrongly accept. \\nLet us say the system returns P(C Ë† 1|x), the probability of the positive class, and \\nfor the negative class, we have P(C Ë† 2|x) = 1 âˆ’ P (C Ë† 1|x), and we choose â€œpositiveâ€ if'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Let us say the system returns P(C Ë† 1|x), the probability of the positive class, and \\nfor the negative class, we have P(C Ë† 2|x) = 1 âˆ’ P (C Ë† 1|x), and we choose â€œpositiveâ€ if \\nP (C Ë† 1|x) > Î¸. If Î¸ is close to 1, we hardly choose the positive class; that is, we will \\nhave no false positives but also few true positives. As we decrease Î¸ to increase the \\nnumber of true positives, we risk introducing false positives. \\nFor different values of Î¸, we can get a number of pairs of (tp-rate, fp-rate) \\nvalues and by connecting them we get the receiver operating characteristics \\ncharacteristics (ROC) curve, as shown in figure 19.3a. Note that different values of Î¸ \\ncorrespond to different loss matrices for the two types of error and the ROC curve \\ncan also be seen as the behavior of a classifier \\nFigure 19.3 (a) Typical ROC curve. Each classifier has a threshold that allows us \\nto move over this curve, and we decide on a point, based on the relative importance'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Figure 19.3 (a) Typical ROC curve. Each classifier has a threshold that allows us \\nto move over this curve, and we decide on a point, based on the relative importance \\nof hits versus false alarms, namely, true positives and false positives. The area below \\nthe ROC curve is called AUC. (b) A classifier is preferred if its ROC curve is closer to \\nthe upper-left corner (larger AUC). B and C are preferred over A; B and C are \\npreferred under different loss matrices \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIdeally, a classifier has a tp-rate of 1 and a fp-rate of 0, and hence a classifier is \\nbetter the more it gets closer to the upper-left corner. On the diagonal, we make as \\nmany true decisions as false ones, and this is the worst one can do (any classifier \\nthat is below the diagonal can be improved by flipping its decision). Given two \\nclassifiers, we can say one is better than the other one if it is above the other one; if \\ntwo ROC curves intersect, we can say that the two classifiers are better under'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ndifferent loss conditions, as seen in figure 19.3b. \\nROC allows a visual analysis; if we want to reduce the curve to a single the \\nnumber we can do this by calculating the area under the curve (AUC).A classifier \\nideally has an AUC of 1 and AUC values of different classifiers can be compared to \\ngive us a general performance averaged over different loss conditions. \\nIn information retrieval, there is a database of records; we make a \\n \\n \\nPrecision = a/a+b \\nRecall = a/a+c \\n \\n \\n \\n(a) Precision and recall \\n \\n \\nFigure 19.4 (a) Definition of precision and recall using Venn diagrams. (b) Precision is 1; \\nall the retrieved records are relevant but there may be relevant ones not retrieved. (c) \\nRecall is 1; all the relevant records are retrieved but there may also be irrelevant \\nrecords that are retrieved. \\nPrecision=1 Recall=1 \\n \\n \\n \\n \\nquery, for example, by using some keywords, and a system (basically a two-class'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='records that are retrieved. \\nPrecision=1 Recall=1 \\n \\n \\n \\n \\nquery, for example, by using some keywords, and a system (basically a two-class \\nclassifier) returns a number of records. In the database, there are relevant records and \\nfor a query, the system may retrieve some of them (true positives) but probably not all \\n(false negatives); it may also wrongly retrieve records that are not relevant (false \\npositives). The set of relevant and retrieved records can be visualized using a Venn \\ndiagram, as shown in figure 19.4a. Precision is the number of retrieved and relevant \\nrecords divided by the total number of retrieved records; if precision is 1, all the \\nretrieved records may be relevant but there may still be records that are relevant but \\nnot retrieved. Recall is the number of retrieved relevant records divided by the total \\nnumber of relevant records; even if recall is 1, all the relevant records may be retrieved'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='not retrieved. Recall is the number of retrieved relevant records divided by the total \\nnumber of relevant records; even if recall is 1, all the relevant records may be retrieved \\nbut there may also be irrelevant records that are retrieved, as shown in figure19.4c. As \\nin the ROC curve, for different threshold values, one can draw a curve for precision vs. \\nrecall. \\nFrom another perspective but with the same aim, there are the two measures of \\nsensitivity and specificity. Sensitivity is the same as tp-rate and recall. Specificity is how'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nwell we detect the negatives, which is the number of true negatives divided by the total \\nnumber of negatives; this is equal to 1 minus the false alarm rate. One can also draw a \\nsensitivity vs. specificity curve using different thresholds. \\nIn the case of K > 2 classes, if we are using 0/1 error, the class confumatrix sion \\nmatrix is a KÃ—K matrix whose entry (i, j) contains the number of instances that belong to \\nCi but are assigned to Cj . Ideally, all off-diagonals should be 0, for no misclassification. \\nThe class confusion matrix allows us to pinpoint what types of misclassification occur, \\nnamely, if there are two classes that are frequently confused. Or, one can define K \\nseparate two-class problems, each one separating one class from the other K âˆ’ 1. \\n \\n5.4 Assessing a Classification Algorithmâ€™s Performance \\nWe will discuss the case of classification error, but the same methodology applies'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='5.4 Assessing a Classification Algorithmâ€™s Performance \\nWe will discuss the case of classification error, but the same methodology applies \\nfor squared error in regression, log likelihoods in unsupervised learning, expected \\nreward in reinforcement learning, and so on, as long as we can write the appropriate \\nparametric form for the sampling distribution. We will also discuss nonparametric \\ntests when no such parametric form can be found. \\n \\nBinomial Test \\nLet us start with the case where we have a single training set T and a single \\nvalidation set V . We train our classifier on T and test it on V . We denote by p the \\nprobability that the classifier makes a misclassification error. We do not know p; it is \\nwhat we would like to estimate or test a hypothesis about. On the instance with \\nindex t from the validation set V , let us say xt denotes the correctness of the \\nclassifierâ€™s decision: xt is a 0/1 Bernoulli random variable that takes the value 1'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='index t from the validation set V , let us say xt denotes the correctness of the \\nclassifierâ€™s decision: xt is a 0/1 Bernoulli random variable that takes the value 1 \\nwhen the classifier commits an error and 0 when the classifier is correct. The \\nbinomial random variable X denotes the total number of errors: \\n \\nX = âˆ‘t=1N xt \\nWe would like to test whether the error probability p is less than or equal to some \\nvalue p0 we specify: \\nH0 : p â‰¤ p0 vs. H1 : p>p0 \\nIf the probability of error is p, the probability that the classifier commits j errors out \\nof N is \\nP{X = j} = ( N/ j ) pj (1 âˆ’ p)N-j \\nIt is reasonable to reject p â‰¤ p0 if in such a case, the probability that binomial test we \\nsee X = e errors or more is very unlikely. That is, the binomial test rejects the hypothesis \\nif \\nP{X â‰¥ e} = âˆ‘x=eN ( N/ x ) p0x(1-p0 )N-x < Î± (19.10) \\nwhere Î± is the significance, for example, 0.05. \\n \\nApproximate Normal Test'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='if \\nP{X â‰¥ e} = âˆ‘x=eN ( N/ x ) p0x(1-p0 )N-x < Î± (19.10) \\nwhere Î± is the significance, for example, 0.05. \\n \\nApproximate Normal Test \\nIf p is the probability of error, our point estimate is pË† = X/N. Then, it is reasonable \\nto reject the null hypothesis if pË† is much larger than p0. How large is large enough is \\ngiven by the sampling distribution of pË† and the significance Î±. \\nBecause X is the sum of independent random variables from the same distribution, \\nthe central limit theorem states that for large N, X/N is approximately normal with \\nmean p0 and variance p0(1 â€“ p0). Then \\nX/N â€“ p0 / âˆšp0(1 âˆ’ p0) âˆ¼ZË™ (19.11) \\nwhere Ë™âˆ¼ denotes â€œapproximately distributed.â€ Then, using equation 19.7, the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\napproximate normal test rejects the null hypothesis if this value for X = e is greater than \\nzÎ±. Z0.05 is 1.64. This approximation will work well as long as N is not too small and p is \\nnot very close to 0 or 1; as a rule of thumb, we require Np â‰¥ 5 and N(1 âˆ’ p) â‰¥ 5. \\n \\nT Test \\nThe two tests we discussed earlier use a single validation set. If we run the algorithm \\nK times, on K training/validation set pairs, we get K error percentages, pi, i = 1,...,K on \\nthe K validation sets. Let xt i be 1 if the classifier trained on Ti makes a misclassification \\nerror on instance t of Vi; xti is 0 otherwise. Then \\npi = âˆ‘t=1N xt i/ N Given that m = âˆ‘i=1K pi /K , S2 = âˆ‘i=1K (p i-m)2 /K â€“ 1 \\nfrom equation 19.8, we know that we have \\nâˆš K(m â€“ p0)/ S  âˆ¼ tK-1 (19.12) \\nand the t test rejects the null hypothesis that the classification algorithm has p 0 or less \\nerror percentage at significance level Î± if this  value is greater than t á¼€,K-1. Typically, K is'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='and the t test rejects the null hypothesis that the classification algorithm has p 0 or less \\nerror percentage at significance level Î± if this  value is greater than t á¼€,K-1. Typically, K is \\ntaken as 10 or 30. T0.05,9= 1.83 and t0.05,29 = 1.70. \\n \\n5.5 Comparing Two Classification Algorithms \\nGiven two learning algorithms, we want to compare and test whether they \\nconstruct classifiers that have the same expected error rate. \\n \\nMcNemarâ€™s Test \\nGiven a training set and a validation set, we use two algorithms to train two \\nclassifiers on the training set and test them on the validation set and compute their \\nerrors. A contingency table, like the one shown here, is an array of natural numbers in \\nmatrix form representing counts, or frequencies: \\ne00: Number of \\nexamples \\nmisclassiï¬ed by both \\ne01: Number of \\nexamples \\nmisclassiï¬ed by 1 \\nbut not 2 \\ne10: Number of \\nexamples \\ne11: Number of \\nexamples \\nmisclassiï¬ed by 2 \\nbut not 1 \\ncorrectly classiï¬ed \\nby both'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='misclassiï¬ed by both \\ne01: Number of \\nexamples \\nmisclassiï¬ed by 1 \\nbut not 2 \\ne10: Number of \\nexamples \\ne11: Number of \\nexamples \\nmisclassiï¬ed by 2 \\nbut not 1 \\ncorrectly classiï¬ed \\nby both \\n \\nUnder the null hypothesis that the classification algorithms have the same error \\nrate, we expect e01 = e10 and these to be equal to (e01+e10)/2. We have the chi-square \\nstatistic with one degree of freedom \\n((|e01 â€“ e10| âˆ’ 1)2 /e01 + e10 ) âˆ¼ X2 1 \\nand McNemarâ€™s test rejects the hypothesis that the two classification algorithms \\nhave the same error rate at significance level Î± if this value is greater than X2 Î±,1. For \\nÎ± = 0.05, X2 0.05,1 = 3.84 \\n \\nK-Fold Cross-Validated Paired t Test \\nThis set uses K-fold cross-validation to get K training/validation set pairs. We use \\nthe two classification algorithms to train on the training sets Ti, i = 1,...,K, and test on the \\nvalidation sets Vi. The error percentages of the classifiers on the validation sets are \\nrecorded as p1i and p2 i .'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='validation sets Vi. The error percentages of the classifiers on the validation sets are \\nrecorded as p1i and p2 i . \\nIf the two classification algorithms have the same error rate, then we expect them \\nto have the same mean, or equivalently, that the difference of their means is 0. The'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ndifference in error rates on fold i is pi= p1 i âˆ’p2 i. This is a paired test; that is, for each i, \\nboth algorithms see the same training and validation sets. When this is done K times, we \\nhave a distribution of pi containing K points. Given that p1i and p2 i are both \\n(approximately) normal, their difference pi is also normal. The null hypothesis is that \\nthis distribution has 0 mean: \\nH0 : Î¼ = 0 vs. H1 : Î¼ â‰  0 \\nWe define \\nm = âˆ‘i=1K pi /K ,  S2 = âˆ‘i=1K (p i-m)2 /K â€“ 1 \\nUnder the null hypothesis that Î¼ = 0, we have a statistic that is tdistributed with K âˆ’ 1 \\ndegrees of freedom: \\nâˆš K(m âˆ’ 0)/ S = âˆš K Â· m/ S  âˆ¼ tK-1 (19.14) \\nThus the K-fold cv paired t test rejects the hypothesis that two clastest sification \\nalgorithms have the same error rate at significance level Î± if this value is outside the \\ninterval (âˆ’tá¼€/2,K-1, tá¼€/2,K-1). T0.025,9 = 2.26 and t0.025,29 = 2.05. \\nIf we want to test whether the first algorithm has less error than the second, we'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='interval (âˆ’tá¼€/2,K-1, tá¼€/2,K-1). T0.025,9 = 2.26 and t0.025,29 = 2.05. \\nIf we want to test whether the first algorithm has less error than the second, we \\nneed a one-sided hypothesis and use a one-tailed test: \\nH0 : Î¼ â‰¥ 0 vs. H1 : Î¼ < 0 \\nIf the test rejects, our claim that the first one has significantly less error is supported. \\n \\n5 Ã— 2 cv Paired t Test \\nIn the 5 Ã— 2 cv t test, proposed by Dietterich (1998), we perform five replications of \\ntwofold cross-validation. In each replication, the dataset is divided into two equal-sized \\nsets. P(j)i is the difference between the error rates of the two classifiers on fold j = 1, 2 of \\nreplication i = 1,..., 5. The average on replication i is pâ€¾ i = (p(1) i+p(2) i)/2, and the \\nestimated variance is s2 i= (p(1)i  âˆ’ p- i)2+ (p(2) iâˆ’ p- i)2. \\nUnder the null hypothesis that the two classification algorithms have the same error \\nrate, p(j) i is the difference of two identically distributed proportions, and ignoring the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Under the null hypothesis that the two classification algorithms have the same error \\nrate, p(j) i is the difference of two identically distributed proportions, and ignoring the \\nfact that these proportions are not independent, p(j) i can be treated as approximately \\nnormal distributed with 0 mean and unknown variance Ïƒ2. Then p(j) i /Ïƒ is \\napproximately unit normal. If we assume p(1) i and p(2) i are independent normals (which \\nis not strictly true because their training and test sets are not drawn independently of \\neach other), then s2 i /Ïƒ+2 has a chi-square distribution with one degree of freedom. If \\neach of the \\ns2 i are assumed to be independent (which is not true because they are all computed \\nfrom the same set of available data), then their sum is chi-square with five degrees of \\nfreedom: \\nM = âˆ‘5 i=1 s2 i  /Ïƒ2 âˆ¼ X2 5 \\nand \\nt = p(1) 1 /Ïƒ /âˆšM/5 = p(1) 1 / âˆšâˆ‘5 i=1 s2 i/5 âˆ¼ t5 (19.15) \\ngiving us a t statistic with five degrees of freedom. The 5 Ã— 2 cv paired t test rejects the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='freedom: \\nM = âˆ‘5 i=1 s2 i  /Ïƒ2 âˆ¼ X2 5 \\nand \\nt = p(1) 1 /Ïƒ /âˆšM/5 = p(1) 1 / âˆšâˆ‘5 i=1 s2 i/5 âˆ¼ t5 (19.15) \\ngiving us a t statistic with five degrees of freedom. The 5 Ã— 2 cv paired t test rejects the \\nhypothesis that the two classification algorithms have the same error rate at \\nsignificance level Î± if this value is outside the interval (âˆ’tá¼€/2,5, tá¼€/2,5). T0.025,5 = 2.57. \\n \\n5 Ã— 2 cv Paired F Test \\nWe note that the numerator in equation 19.15, p(1) 1 , is arbitrary; actually, ten \\ndifferent values can be placed in the numerator, namely, p(j) i, j = 1, 2, i = 1,..., 5, leading \\nto ten possible statistics: \\nt(j) i= p(j) i /âˆšâˆ‘5 i=1s2 i /5 (19.16) \\nAlpaydÄ±n (1999) proposed an extension to the 5 Ã— 2 cv t test that combines the results of'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nthe ten possible statistics. If p(j) i /Ïƒ âˆ¼ Z, then (p(j) i )2 /Ïƒ2 âˆ¼ X2 1 and their sum is chi- \\nsquare with ten degrees of freedom: \\nN = âˆ‘5 i=1âˆ‘2 j=1 (p(j) i)2 /Ïƒ2 âˆ¼ X2 10 \\nPlacing this in the numerator of equation 19.15, we get a statistic that is the ratio of \\ntwo chi-square distributed random variables. Two such variables divided by their \\nrespective degrees of freedom is F-distributed with ten and five degrees of freedom \\n(section A.3.8): \\nf = (N/10)/( M/5) = âˆ‘5 i=1âˆ‘2 j=1 (p(j) i)2 /2âˆ‘5i=1 s2 iâˆ¼F10,5 \\n5 Ã— 2 cv paired F test rejects the hypothesis that the classification algotest rithms have \\nthe same error rate at significance level Î± if this value is greater than Fá¼€,10.5. F0.05,10.5 = \\n4.74.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='DATABASE SYSTEM DEVELOPMENT LIFECYCLE: \\n \\nDatabase Planning: \\nThe management activities that allow the stages of the database system development lifecycle to be realized as efficiently \\nand effectively as possible. \\nAn important first step in database planning  is to clearly define the mission statement for the database system. The \\nmission statement defines the major aims of the database system. Those driving the database project within the \\norganization (such as the Director and/or owner) normally define the mis sion statement. A mission statement helps to \\nclarify the purpose of the database system and provide a clearer path towards the efficient and effective creation of the \\nrequired database system. \\nOnce the mission statement is defined, the next activity involves identifying the mission objectives. Each mission objective \\nshould identify a particular task that the database system must support. The assumption is that if the database system'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='should identify a particular task that the database system must support. The assumption is that if the database system \\nsupports the mission objectives, then the mission statement should be met. \\nDatabase planning should also include the development of standards that govern how data will be collected, how the \\nformat should be specified, what documentation will be needed, and how design and implementation should proceed. \\nSystem Definition: \\nDescribes the scope and boundaries of the database system and the major user views.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='User Views: Defines what is required of a database system from the perspective of a particular job role (such as Manager \\nor Supervisor) or enterprise application area (such as marketing, personnel, or stock control). \\nA database system may have one or more user views. Identifying user views is an important aspect of developing a \\ndatabase system because it helps to ensure that no major users of the database are forgotten when developin g the \\nrequirements for the new database system. \\n \\nRepresentation of a database system with multiple user views: user views \\n \\nThere are three main approaches to managing the requirements of a database system with multiple user views: \\n\\uf0b7 the centralized approach \\n\\uf0b7 the view integration approach \\n\\uf0b7 a combination of both approaches \\nCentralized Approach: Requirements for each user view are merged into a single set of requirements for the new database \\nsystem. A data model representing all user views is created during the database design stage.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='The centralized (or one -shot) approach involves collating the requirements for different user views into a single list of \\nrequirements. The collection of user views is given a name that provides some indication of the application area covered \\nby all the merged user views. In the database design stage, a global data model is created, which represents all user views. \\nView Integration Approach: Requirements for each user view remain as separate lists. Data models representing each user \\nview are created and then merged later during the database design stage. \\nThe view integration approach involves leaving the requirements for each user view as separate lists of requirements. In \\nthe database design stage, we  first create a data model for ea ch user view. A data model that represents a single user \\nview (or a subset of all user views) is called a local data model. Each model is composed of diagrams and documentation'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='view (or a subset of all user views) is called a local data model. Each model is composed of diagrams and documentation \\nthat formally describes the requirements of one or moreâ€”but not allâ€”user views of the database. The local data models \\nare then merged at a later stage of database design to produce a global data model, which represents all user \\nrequirements for the database. \\n \\nDatabase Design: \\nThe process of creating a design that will support the en terpriseâ€™s mission statement and mission objectives for the \\nrequired database system. \\nThe two main approaches to the design of a database are: \\n\\uf0b7 â€œbottom-upâ€ \\n\\uf0b7 â€œtop-down.â€ \\nThe bottom-up approach begins at the fundamental level of attributes (that is, properties  of entities and relationships), \\nwhich through analysis of the associations between attributes are grouped into relations that represent types of entities \\nand relationships between entities.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='A more appropriate strategy for the design of complex databases is to use the top-down approach. This approach starts \\nwith the development of data models that contain a few high-level entities and relationships and then applies successive \\ntop-down refinements to identify lower-level entities, relationships, and the associated attributes. \\nThere are other approaches to database design, such as the inside -out approach and the mixed strategy approach. The \\ninside-out approach is related to the bottom- up approach, but differs by first identifying a set of major entities and then \\nspreading out to consider other entities, relationships, and attributes associated with those first identified. The mixed \\nstrategy approach uses both the bottom -up and top -down approach for various parts of the model before finally \\ncombining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='combining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design \\n \\nConceptual Database Design: The process of constructing a model of the data used in an enterprise, independent of all \\nphysical considerations. \\nLogical Database Design: The process of constructing a model of the data used in an enterprise based on a specific data \\nmodel, but independent of a particular DBMS and other physical considerations. \\nPhysical Database Design: The process of producing a description  of the implementation of the database on secondary \\nstorage; it describes the base relations, file organizations, and indexes used to achieve efficient access to the data, and \\nany associated integrity constraints and security measures. \\nDBMS Selection:  \\nThe selection of an appropriate DBMS to support the database system. \\nThe steps involved in database selection are: \\n\\uf0b7 Define Terms of Reference of study \\n\\uf0b7 Shortlist two or three products'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='The selection of an appropriate DBMS to support the database system. \\nThe steps involved in database selection are: \\n\\uf0b7 Define Terms of Reference of study \\n\\uf0b7 Shortlist two or three products \\n\\uf0b7 Evaluate products \\n\\uf0b7 Recommend selection and produce report \\nApplication Design: \\nThe design of the user interface and the application programs that use and process the database.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Database and application design are parallel activities of the database system development lifecycle. In most cases, it is \\nnot possible to complete the application design until the design of the database itself has taken place. \\nThe steps involved in application design are: \\n\\uf0b7 Transaction Design \\n\\uf0b7 User interface Design Guidelines \\nTransaction Design: An action, or series of actions, carried out by a single user or app lication program, that accesses or \\nchanges the content of the database. \\nThe purpose of transaction design is to define and document the high-level characteristics of the transactions required on \\nthe database, including: \\n\\uf0b7 data to be used by the transaction \\n\\uf0b7 functional characteristics of the transaction \\n\\uf0b7 output of the transaction \\n\\uf0b7 importance to the users \\n\\uf0b7 expected rate of usage \\nUser interface Design Guidelines: \\n\\uf0b7 Meaningful title \\n\\uf0b7 Comprehensible instructions \\n\\uf0b7 Logical grouping and sequencing of fields \\n\\uf0b7 Visually appealing layout of the form/report'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='User interface Design Guidelines: \\n\\uf0b7 Meaningful title \\n\\uf0b7 Comprehensible instructions \\n\\uf0b7 Logical grouping and sequencing of fields \\n\\uf0b7 Visually appealing layout of the form/report \\n\\uf0b7 Familiar field labels \\n\\uf0b7 Consistent terminology and abbreviations \\n\\uf0b7 Consistent use of color \\n\\uf0b7 Visible space and boundaries for data entry fields \\n\\uf0b7 Convenient cursor movement \\n\\uf0b7 Error correction for individual characters and entire fields \\n\\uf0b7 Error messages for unacceptable values \\n\\uf0b7 Optional fields marked clearly \\n\\uf0b7 Explanatory messages for fields \\n\\uf0b7 Completion signal \\nPrototyping: \\nBuilding a working model of a database system. \\nA prototype is a working model that does not normally have all the required fe atures or provide all the functionality of \\nthe final system. The main purpose of developing a prototype database system is to allow users to use the prototype to \\nidentify the features of the system that work well or are inadequate, and if possible to suggest improvements or even new'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='identify the features of the system that work well or are inadequate, and if possible to suggest improvements or even new \\nfeatures to the database system. \\nThere are two prototyping strategies: \\n\\uf0b7 requirements prototyping - uses a prototype to determine the requirements of a proposed database system, and \\nonce the requirements are complete, the prototype is discarded \\n\\uf0b7 evolutionary prototyping - used for the same purposes, the important difference is that the prototype is not \\ndiscarded, but with further development becomes the working database system'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Implementation: \\nThe physical realization of the database and application designs. \\nThe database implementation is achieved using the DDL of the selected DBMS or a GUI, which provides the same \\nfunctionality while hiding the low-level DDL statements. The application programs are implemented using the preferred \\nthird- or fourth generation language (3GL or 4GL). \\nData Conversion and Loading: \\nTransferring any existing data into the new database and converting any existing applications to run on the new database. \\nThis stage is required only when a new database system is replacing an old system. \\nTesting: \\nThe process of running the database system with the intent of finding errors. \\nBefore going live, the newly developed database system should be thoroughly tested. This is achieved using carefully \\nplanned test strategies and realistic data, so that the entire testing process is methodically and rigorously carried out. \\nOperational Maintenance:'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='planned test strategies and realistic data, so that the entire testing process is methodically and rigorously carried out. \\nOperational Maintenance: \\nThe process of monitoring and maintaining the database system following installation. \\n\\uf0b7 Monitoring the performance of the system. If th e performance falls below an acceptable level, tuning or \\nreorganization of the database may be required. \\n\\uf0b7 Maintaining and upgrading the database system (when required). New requirements are incorporated into the \\ndatabase system through the preceding stages of the lifecycle. \\n \\nCASE Tools: \\nA computer -aided software engineering (CASE) tool is a software package that provides support for the design and \\nimplementation of information systems. It can document a database design and provide invaluable help in maintain ing \\nthe consistency of a design. By integrating many of the techniques used to document a system design  including the data'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='the consistency of a design. By integrating many of the techniques used to document a system design  including the data \\ndictionary, data flows, and entity relationships, CASE tool can increase the consistency and accuracy of a database design. \\nIt can also ease the task of creating the diagrams that accompany a system design. \\nThere is no software in the world that can examine a database environment and identify the entities, attributes, and \\nrelationships that should be represented in a database. The model created with CASE tool is therefore only as good as the \\nanalysis of the database environment provided by the people using the tool. \\nCASE support may include: \\n\\uf0b7 a data dictionary to store information about the database systemâ€™s data \\n\\uf0b7 design tools to support data analysis \\n\\uf0b7 tools to permit development of the corporate data model, and the conceptual and logical data models \\n\\uf0b7 tools to enable the prototyping of applications'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Requirements Collection: \\nFact Finding Technique: \\nThe formal process of using techniques suc h as interviews and questionnaires to collect facts about systems, \\nrequirements, and preferences.  Fact-finding is particularly crucial to the early stages of the lifecycle, including the \\ndatabase planning, system definition, and requirements collection and analysis stages. \\nThere are five commonly used fact-finding techniques: \\n\\uf0b7 examining documentation \\n\\uf0b7 interviewing \\n\\uf0b7 observing the enterprise in operation \\n\\uf0b7 research \\n\\uf0b7 questionnaires \\nthe below diagram depicts the examples of data captured in each of the stages of the development life cycle.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='DreamHome Case Study: \\nDreamHome specializes in property management, taking an intermediate role between owners who wish to rent out their \\nfurnished property and clients of DreamHome who require to rent furnished property for a fi xed period. DreamHome \\ncurrently has about 2000 staff working in 100 branches. \\n \\nMission Statement for the Case Study: \\n \\n \\nMission Objectives for the Case Study:'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='System boundary for the Case Study: \\n \\n \\nENTITY-RELATIONSHIP MODELING: \\nAn entity is a \"thing\" or \"object\" in the real world that is distinguishable from all other objects. For example, each person \\nin an enterprise is an entity. An entity set is a set of entities of the same type that share the same properties, or attributes. \\nThe set of all persons who are customers at a given bank, for example, can be defined as the entity set customer. \\nAn entity is represented by a set of attributes. Attributes are descriptive properties possessed by each member of an \\nentity set. \\nAttribute domain: The set of allowable values (data type) for one or more attributes. \\nTypes of Attributes: \\nSimple Attribute: An attribute composed of a single component with an independent existence.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Composite Attribute: An attribute composed of multiple components, each with an independent existence. \\nSingle-Valued Attributes: An attribute that holds a single value for each occurrence of an entity type. \\nMulti-Valued Attributes: An attribute that holds multiple values for each occurrence of an entity type. \\nDerived Attributes: An attribute that represents a value that is derivable from the value of a related attribute or set of \\nattributes, not necessarily in the same entity type. \\n \\nA relationship is an association among several entities.  Relationship set is a set of relationships of the same type. \\nThe association between entity set is referred to as participation. That is, the entity sets E1, E2, . ..,En participate in \\nrelationship set R. \\nA uniquely identifiable association that includes one occurrence from each participating entity type. A relatio nship \\noccurrence indicates the particular entity occurrences that are related. Relationship type and Relationship occurrences'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='occurrence indicates the particular entity occurrences that are related. Relationship type and Relationship occurrences \\nare one and the same.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Degree of a relationship: The number of participating entity types in a relationship. Binary relationship set is of degree 2; \\na tertiary relationship set is of degree 3. \\nUnary relationship: A unary relationship exists when an association is maintained within a single entity. \\n \\nBinary relationship: A binary relationship exists when two entities are associated. \\n \\n \\nTernary relationship: A ternary relationship exists when there are three entities associated. \\n \\n \\nQuaternary relationship: A quaternary relationship exists when there are four entities associated. \\n \\n \\nEntity role: The function that an entity plays in a relationship is called that entityâ€˜s role. A role is one end of an association. \\nIn the below ER model, the publisher entity plays the publishes role. \\n \\n \\nRecursive Relationship: A relationship type in which the same entity type participates more than once in different roles.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Keys: \\nSuper Key: Super key is a single attribute or a group of multiple attributes that can uniquely identify each occurrence of \\nan entity type. \\nCandidate Key: The minimal set of attributes that uniquely identifies each occurrence of an entity type. \\nPrimary Key: The candidate key that is selected to uniquely identify each occurrence of an entity type. \\nComposite Key: A candidate key that consists of two or more attributes. \\nForeign Key: Foreign key is an attribute which is a Primary key in its parent entity, but is included as an attribute in another \\nentity. A Foreign key generates a relationship between the parent entity and the child entity. \\nAlternate or Secondary Key: Alternate keys are those candidate keys which are not the Primary key. \\n \\nAn entity set may not have sufficient attributes to form a primary key. Such an entity set is termed a weak entity set. An \\nentity set that has a primary key is termed a strong entity set.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='An entity set may not have sufficient attributes to form a primary key. Such an entity set is termed a weak entity set. An \\nentity set that has a primary key is termed a strong entity set. \\nWeak entity set is associated with another entity set called the identifying or owner entity set. i.e., weak entity set is said \\nto be existence dependent on the identifying entity set. Identifying entity set is said to own the weak entity set. \\nThe relationship among the weak and identifying entity set is called the identifying relationship. \\n \\nSTRUCTURAL CONSTRAINTS: \\nMultiplicity: The number (or range) of possible occurrences of an entity type that may relate to a single occurrence of an \\nassociated entity type through a particular relationship. \\n\\uf0b7 one-to-one (1:1) \\n\\uf0b7 one-tomany (1:*) \\n\\uf0b7 many-to-many (*:*)'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='One-to-one: An entity in A is associated with at most one entity in B, and an entity in B is associated  with at most one \\nentity in A. \\n \\nExample: Relationship between Manager and Branch of a Bank. \\n \\nOne-to-many: An entity in A is associated with any number of entities (zero or more) in B. An entity in B, however, can be \\nassociated with at most one entity in A. \\n \\nExample: Relationship between Department and Employee. \\n \\nMany-to-many: An entity in A is associated with any number (zero or more) of entities in B, and an entity in B is associated \\nwith any number (zero or more) of entities in A. \\n \\nExample: Relationship between Supplier and Products. \\n \\nCardinality and Participation Constraints : Multiplicity actually consists of two separate constra ints known as cardinality \\nand participation.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Cardinality: Describes the maximum number of possible relationship occurrences for an entity participating in a given \\nrelationship type. \\n \\nParticipation: Determines whether all or only some entity occurrences participate in a relationship \\nThe participation constraint represents whether all entity occurrences are involved in a particular relationship (referred \\nto as mandatory participation) or only some (referred to as optional participation). \\n \\n \\nProblems with ER Models: \\nFan Trap: Where a model represents a relationship between entity types, but the pathway between certain entity \\noccurrences is ambiguous. \\nChasm Trap: Where a model suggests the existence of a relationship between entity types, but the pathway does not exist \\nbetween certain entity occurrences \\n \\n \\nENHANCED ER MODEL \\nIt is a diagrammatic technique for displaying the following concepts \\n\\uf0b7 Sub Class and Super Class \\n\\uf0b7 Specialization and Generalization \\n\\uf0b7 Aggregation \\n\\uf0b7 Composition'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Super Class: An entity type that includes one or more distinct subgroupings of its occurrences, which must be represented \\nin a data model. \\nSub Class: A distinct subgrouping of occurrences of an entity type, which must be represented in a data model. \\nSpecialization: Specialization is the process of defining a set of subclasses of an entity type. The process of maximizing the \\ndifferences between members of an entity by identifying their distinguishing characteristics. The set of subclasses that \\nforms a specialization is defined on the basis of some distinguishing characteristic of the entities in the superclass. \\nGeneralization: A reverse process of abstraction . Suppress the differences among several entity types . The process of \\nminimizing the differences between entities by identifying their common characteristics. Identify their common features, \\nand generalize them into a single superclass of which the original entity types are special subclasses.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Constraints on Specialization/Generalization : In some specializations we can determine exa ctly the entities that will \\nbecome members of each subclass by placing a condition on the value of some attribute of the superclass. Such subclasses \\nare called predicate-defined (or condition-defined) subclasses. \\nâ€¢ Participation Constraints: Determines whether every member in the superclass must participate as a member of \\na subclass \\nâ€¢ Disjoint Constraints: Describes the relationship between members of the subclasses and indicates whether it is \\npossible for a member of a superclass to be a member of one, or more than one, subclass. \\nIf all subclasses in a specialization have their membership condition on the same attribute of the superclass, the \\nspecialization itself is called an attribute -defined specialization . The attribute is called the defining attribute of t he \\nspecialization. When we do not have a condition for determining membership in a subclass, the subclass is called user -'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='specialization. When we do not have a condition for determining membership in a subclass, the subclass is called user -\\ndefined subclass. \\nA total specialization constraint specifies that every entity in the superclass must be a member of at least one subclass in \\nthe specialization. A partial specialization, which allows an entity not to belong to any of the subclasses. \\nA specialization Lattice: \\nA set of entities that are at two or more levels is called as a specialization lattice. It is also called as mul ti-level \\nspecialization.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Aggregation: \\nâ€¢ Aggregation is an abstraction concept for building composite objects from their component objects.  \\nâ€¢ Represents a â€œhas-aâ€ or â€œis-part-ofâ€ relationship between entity types, where one represents the â€œwholeâ€ and the \\nother the â€œpart.â€ \\nThree Cases \\nâ€¢ We aggregate attribute values of an object to form the whole object \\nâ€¢ We represent an aggregation relationship as an ordinary relationship \\nâ€¢ Combining objects that are related by a particular relationship instance into a higher-level aggregate \\nobject \\nâ€¢ IS-A-PART-OF and IS-A-COMPONENT-OF \\nComposition: \\nA specific form of aggregation that represents an association between entities, where there is a strong ownership and \\ncoincidental lifetime between the â€œwholeâ€ and the â€œpart.â€ \\nEg.: A newspaper displays an advertisement \\n \\nUML Class Diagram: \\nIn UML class diagrams, \\nâ€“ a class (similar to an entity type in ER) is displayed as a box that includes three sections:'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Eg.: A newspaper displays an advertisement \\n \\nUML Class Diagram: \\nIn UML class diagrams, \\nâ€“ a class (similar to an entity type in ER) is displayed as a box that includes three sections: \\nâ€¢ The top section gives the class name (similar to entity type name) \\nâ€¢ the middle section includes the attributes \\nâ€¢ last section includes operations that can be applied to individual objects \\nâ€“ Operations are not specified in ER diagrams.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='â€¢ The designer can optionally specify the domain (or data type) of an attribute if desired, by placing a colon (: ) \\nfollowed by the domain name or description \\nâ€¢ A composite attribute is modeled as a structured domain \\nâ€¢ A multivalued attribute will generally be modeled as a separate class \\nâ€¢ Relationship types are called associations in UML terminology, and relationship instances are called links \\n \\nAssociations: \\nA binary association is represented as a line connecting the participating classes, and may optionally have a name \\nâ€¢ A relationship attribute, called a link attribute, is placed in a box that is connected to the associati onâ€™s line by a \\ndashed line \\nâ€¢ The (min, max) notation is used to specify relationship constraints, which are called multiplicities in UML \\nterminology \\nâ€“ Multiplicities are specified in the form min..max, and an asterisk (*) indicates no maximum limit on \\nparticipation  \\nIn UML, there are two types of relationships: \\nâ€“ Association \\nâ€“ Aggregation'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='â€“ Multiplicities are specified in the form min..max, and an asterisk (*) indicates no maximum limit on \\nparticipation  \\nIn UML, there are two types of relationships: \\nâ€“ Association \\nâ€“ Aggregation \\nAggregation is meant to represent a relationship between a whole object and its component parts, and it has a distinct \\ndiagrammatic notation. \\nUML also distinguishes between unidirectional and bidirectional associations/aggregations. In the unidirectional case, the \\nline connecting the classes is displayed with an arrow to indicate that only one direction for accessing related objects is \\nneeded. If no arrow is displayed, the bidirectional case is assumed, which is the default. In addition, relationship instances \\nmay be specified to be ordered.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='ER Model for a Banking System: \\n \\nER Model for a University System'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='AD8401 Database Design and Management \\n \\n \\nA database is an organized collection of data elements (facts) stored in a computer in a systematic way, \\nsuch that a computer program can consult it to answer questions. The answers to those questions become \\ninformation that can be used to make decisions t hat may not be made with the data elements alone. A \\nsoftware system that enables users to define, create, maintain, query, and control access to the database.is \\nknown as a database management system (DBMS). A computer program that interacts with the databa se \\nby issuing an appropriate request (typically an SQL statement) to the DBMS is known as a database \\napplication program. \\n \\nTraditional File Processing System: File-based systems were an early attempt to computerize the manual \\nfiling system. However, rather  than establish a centralized store for the organizationâ€™s operational data, a \\ndecentralized approach was taken, where each department stored and controlled its own data.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='decentralized approach was taken, where each department stored and controlled its own data. \\n \\nIssues in File Based Systems: \\nâ— Separation and isolation of data: When data is isolated in separate files, it is more difficult to \\naccess data that should be available. \\nâ— Duplication of data: Owing to the decentralized approach taken by each department, the file-\\nbased approach encouraged, if not necessitated, the uncontrolled duplication of data. \\nâ— Difficulty in accessing data In order to retrieve, access and use stored data, need to write a \\nnew program to carry out each new task. \\nâ— Programâ€“Data dependence: The physical structure and storage of the data files and records \\nare defined in the application code.  \\nâ— Data Inconsistency: Data is updated in one file and not in other files and thus some data \\nbecomes invalid. \\nâ— Data Integrity: Allows some invalid data to enter into the system. \\nâ— Data Security: Everyone who has access to the file can view all the data.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='becomes invalid. \\nâ— Data Integrity: Allows some invalid data to enter into the system. \\nâ— Data Security: Everyone who has access to the file can view all the data. \\nâ— Atomicity of updates Failures of files may leave database in an inconsistent state with partial \\nupdates carried out.  \\n \\nThree Level Architecture (Abstraction): \\n \\nExternal View: The external or view level includes a number of external schemas or user views. Each external \\nschema describes the part of the database that a particular user group is interested in and hides the rest of \\nthe database from that user group.  \\nConceptual View: The conceptual level has a conceptual schema, which describes the structure of the whole \\ndatabase for a community of users. The conceptual schema hides the details of physical storage structures \\nand concentrates on describing entities, data types, relationships, user operations, and constraints'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='and concentrates on describing entities, data types, relationships, user operations, and constraints \\nPhysical View (Internal V iew): The internal level has an internal schema, which describes the physical \\nstorage structure of the database. The internal schema uses a physical data model and describes the \\ncomplete details of data storage and access paths for the database.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 1, 'page_label': '2', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Logical data independence is the capacity to change the conceptual schema without having to change \\nexternal schemas or application programs. We may change the conceptual schema to expand the database \\n(by adding a record type or data item), to change constrai nts, or to reduce the database (by removing a \\nrecord type or data item).\\nPhysical data independence is the capacity to change the internal schema without having to change the \\nconceptual schema. Hence, the external schemas need not be changed as well. Changes to the internal \\nschema may be needed because some physical files were reorganizedâ€”for example, by creating additional \\naccess structuresâ€”to improve the performance of retrieval or update.  \\nUsers of the Database: \\n \\nNaive User: The end-users are the â€œclientsâ€ of the databaseNaÃ¯ve users are typically unaware of the DBMS. \\nThey access the database through specially written application programs that attempt to make the operations \\nas simple as possible.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 1, 'page_label': '2', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='They access the database through specially written application programs that attempt to make the operations \\nas simple as possible.  \\n \\nApplication Programmer : Each program contains statements that request the DBMS to perform some \\noperation on the database, whi ch includes retrieving data, inserting, updating, and deleting data. The \\nprograms may be written in a third-generation or fourth-generation programming language. \\n \\nDatabase Designer: The logical database designer must have a thorough and complete understanding  of \\nthe organizationâ€™s data and any constraints on this data (the constraints are sometimes called business \\nrules).  \\n \\nDatabase Administrator: The Database Administrator (DBA) is responsible for the physical realization of the \\ndatabase, including physi cal database design and implementation, security and integrity control, \\nmaintenance of the operational system, and ensuring satisfactory performance of the applications for users.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Advantages of DBMSs\\nControl of data redundancy: the database approach attempts to eliminate the redundancy by integrating the \\nfiles so that multiple copies of the same data are not stored.\\nData consistency: By eliminating or controlling redundancy, we reduce the risk of inconsistencies occurring. \\nIf a data item is stored only once in the database, any update to its value has to be performed only once and \\nthe new value is available immediately to all users.\\nMore information from the same amount of data : With the integra tion of the operational data, it may be \\npossible for the organization to derive additional information from the same data. \\nSharing of data the database belongs to the entire organization and can be shared by all authorized users. \\nIn this way, more users share more of the data. \\nImproved data integrity: Integrity is usually expressed in terms of constraints, which are consistency rules'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='In this way, more users share more of the data. \\nImproved data integrity: Integrity is usually expressed in terms of constraints, which are consistency rules \\nthat the database is not permitted to violate. Constraints may apply to data items within a single record or to \\nrelationships between records.\\nDatabase security is the protection of the database from unauthorized users. This security may take the form \\nof usernames and passwords to identify people authorized to use the database. Granti ng restricted access \\nto the users.\\nEnforcement of standards : integration allows the DBA to define and the DBMS to enforce the necessary \\nstandards.\\nEconomy of scale: Combining all the organizationâ€™s operational data into one database and creating a set of \\napplications that work on this one source of data can result in cost savings. \\nBalance of conflicting requirements : Each user or depart ment has needs that may be in conflict with the \\nneeds of other users.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Balance of conflicting requirements : Each user or depart ment has needs that may be in conflict with the \\nneeds of other users. \\nImproved data accessibility and responsiveness : Again, as a result of integration, data that crosses \\ndepartmental boundaries is directly accessible to the end users. \\n \\nIncreased productivity: As mentioned previously, the DBMS provides many of the standard functions that the \\nprogrammer would normally have to write in a file based application. Eg: low-level file-handling routines \\nImproved maintenance  through data independence: A DBMS separates the data descriptions from the \\napplications, thereby making applications immune to changes in the data descriptions.\\nIncreased concurrency: Many DBMSs manage concurrent database access and ensure that multiple users \\ncan access the data simultaneously.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Improved backup and recovery services: Modern DBMSs provide facilities to minimize the amount of \\nprocessing that is lost following a failure.\\nDisadvantages of DBMSs\\nComplexity: The provision of the functionality that we expect of a good DBMS makes the DBMS an extremely \\ncomplex piece of software. \\nSize: The complexity and breadth of functionality makes the DBMS an extremely large piece of software, \\noccupying many megabytes of disk space and requiring substantial amounts of memory to run efficiently. \\nCost: The cost of DBMSs varies significantly, depending on the environment and functionality provided. For \\nexample, a single-user DBMS costs less than a large mainframe multi-user DBMS. There is also the recurrent \\nannual maintenance cost. \\nAdditional hardware costs The disk storage requirements for the DBMS and the database may necessitate \\nthe purchase of additional storage space. \\nCost of conversion: The cost of converting existing applications to run on the new DBMS and hardware.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='the purchase of additional storage space. \\nCost of conversion: The cost of converting existing applications to run on the new DBMS and hardware.\\nPerformance: DBMS is written to be more general, to cater for many applications rather than just one. The \\nresult is that some applications may not run as fast as they used to. \\nGreater impact of a failure The centralization of resources increases the vulnerability of the system. Because \\nall users and applications rely on the availability of the DBMS, the failure of certain components can bring \\noperations to a halt.\\n \\nDBMS environment\\nThe DBMS and the applications require hardware to run. The hardware can range from a single personal \\ncomputer to a single mainframe or a network of computers. The particular hardware depends on the \\norganizationâ€™s requirements and the DBMS used.  \\n \\nThe software component comprises the DBMS software itself and the application programs, together with'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='organizationâ€™s requirements and the DBMS used.  \\n \\nThe software component comprises the DBMS software itself and the application programs, together with \\nthe operating system, including network software if the DBMS is being used over a network.  \\n \\nData:  Perhaps the most important component of the DBMS environment certainly from the end-usersâ€™ point \\nof view is the data. The data acts as a bridge between the machine and the human components.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Procedures: Procedures refer to the instructions and rules that govern the design and use of the database. \\nThe users of the system and the staff who manage the database require documented procedures on how to \\nuse or run the system. \\n \\nPeople: The final component is the people involved with the system.  \\n \\nDatabase Architecture:\\n \\n \\nData model: An integrated collection of concepts for describing and manipulating data, relationships between \\ndata, and constraints on the data in an organization. A model is a representation of real -world objects and \\nevents, and their associations.\\nA data model can be thought of as comprising three components: \\n(1) a structural part, consisting of a set of rules according to which databases can be constructed; \\n(2) a manipulative part, defining the  types of operation that are allowed on the data (updating or \\nretrieving data from the database and changing the structure of the database);'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='(2) a manipulative part, defining the  types of operation that are allowed on the data (updating or \\nretrieving data from the database and changing the structure of the database); \\n(3) a set of integrity constraints, which ensures that the data is accurate.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Types of Data Model: \\n(1) an external data model, to represent each userâ€™s view of the organization, sometimes called the \\nUniverse of Discourse (UoD); \\n(2) a conceptual data model, to represent the logical (or community) view that is DBMS-independent; \\n(3) an int ernal data model, to represent the conceptual schema in such a way that it can be \\nunderstood by the DBMS \\n \\nObject-based data models use concepts such as entities, attributes, and relationships. \\nIn a record-based model, the database consists of a number of f ixed-format records, possibly of differing \\ntypes. Each record type defines a fixed number of fields, typically of a fixed length. There are three principal \\ntypes of record -based logical data model: the relational data model, the network data model, and the  \\nhierarchical data model.  \\nThe relational data model is based on the concept of mathematical relations. In the relational model, data'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='hierarchical data model.  \\nThe relational data model is based on the concept of mathematical relations. In the relational model, data \\nand relationships are represented as tables, each of which has a number of columns with a unique name. \\nIn the network model, data is represented as collections of records, and relationships are represented by \\nsets.  \\n \\nThe hierarchical model is a restricted type of network model. Again, data is represented as collections of \\nrecords and relationships are represented by sets.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Physical data models describe how data is stored in the computer, representing information such as record \\nstructures, record orderings, and access paths. There are not as many physical data models as logical data \\nmodels; the most common ones are the unifying model and the frame memory.\\n \\nConceptual modeling or conceptual database design  is the process  of constructing a model of the \\ninformation use in an enterprise that is independent of implementation details, such as the target DBMS, \\napplication programs, programming languages, or any other physical considerations.\\n \\nFunctions of a DBMS \\n \\n(1) Data storage, retrieval, and update: A DBMS must furnish users with the ability to store, retrieve, and \\nupdate data in the database \\n \\n(2) A user-accessible catalog: A DBMS must furnish a catalog in which descriptions of data items are stored \\nand which is accessible to users.\\n(3) Transaction support: A DBMS must furnish a mechanism that will ensure either that all the updates'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='and which is accessible to users.\\n(3) Transaction support: A DBMS must furnish a mechanism that will ensure either that all the updates \\ncorresponding to a given transaction are made or that none of them is made\\n(4) Concurrency control services: A DBMS must furnish a mechanism to ensure that the database is updated \\ncorrectly when multiple users are updating the database concurrently.\\n(5) Recovery services: A DBMS must furnish a mechanism for recovering the database in the event that the \\ndatabase is damaged in any way. \\n(6) Authorization services: A DBMS must furnish a mechanism to ensure that only authorized users can \\naccess the database.\\n \\n(7) Support for data communication: A DBMS must be capable of integrating with communication software. \\n(8) Integrity services: A DBMS must furnish a means to ensure that both the data in the database and \\nchanges to the data follow certain rules.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='(8) Integrity services: A DBMS must furnish a means to ensure that both the data in the database and \\nchanges to the data follow certain rules. \\n \\n(9) Services to promote data independence: A DBMS must include facilities to support the independence of \\nprograms from the actual structure of the database.\\n(10) Utility services: A DBMS should provide a set of utility services like backup, restore, etc.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 0, 'page_label': '1', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Introduction to Machine Learning \\n \\n \\nMachine learning is a method of data analysis that automates analytical \\nmodel building. It is a branch of artificial intelligence based on the idea that \\nsystems can learn from data,  identify patterns and make decisions with minimal \\nhuman intervention. \\nExample: Image recognition, Speech recognition, Medical diagnosis, Statistical \\narbitrage, Predictive analytics, etc. \\n \\n Artificial Intelligence, Machine Learning and Deep Learning \\n \\n\\uf0b7 Artificial Intelligence is defined as a program that exhibits cognitive \\nability similar to  that of a human being. It makes computers think like \\nhumans and solve problems the  way we do is one  of the main tenets of \\nartificial intelligence. \\n\\uf0b7 Any computer program that shows characteristi cs, such as self -\\nimprovement, learning  through inference, or even basic human tasks, \\nsuch as image recognition and language  processing, is considered to be a  \\nform of AI.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 0, 'page_label': '1', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='improvement, learning  through inference, or even basic human tasks, \\nsuch as image recognition and language  processing, is considered to be a  \\nform of AI. \\n\\uf0b7 The field of artificial intelligence includes within it the sub -fields of \\nmachine learning and deep learning. \\n\\uf0b7 Deep Learning is a more specialized version of machine learning that \\nutilizes more complex methods for difficult problems.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 2, 'page_label': '3', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Definition of machine learning \\nArthur Samuel, an early American leader in the field of  computer gaming and \\nartificial intelligence, coined the  term â€œMachine Learningâ€  in 1959  while at \\nIBM. \\nHe defined machine learning as â€œthe field of study that gives computers the \\nability to learn  without being explicitly programmed.â€ However, there is no \\nuniversally accepted definition  for machine learning. Different authors define \\nthe term differently. We give below two more definitions. \\n1. Machine learning is programming computers to optimize a performance \\ncriterion using example data or past experience. We have a model defined up to \\nsome parameters, and learning is the execution of a computer program to \\noptimize the parameters of the model using the  training data or past experience. \\nThe model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 2, 'page_label': '3', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question \\nof how to  construct computer programs that automatically improve  with \\nexperience \\n \\n Definition of learning \\nA computer program is said to learn from experience E with respect to some \\nclass of tasks T  and performance measure P, if its performance at tasks T, as \\nmeasured by P, improves with experience E. \\n \\nExamples : \\ni) Handwriting recognition learning problem \\nâ€¢ Task T: Recognising and classifying handwritten words within images \\nâ€¢ Performance P: Percent of words correctly classified \\nâ€¢ Training experience E: A dataset of handwritten words with given classifications'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 3, 'page_label': '4', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='ii) A robot driving learning problem \\nâ€¢ Task T: Driving on highways using vision sensors'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 4, 'page_label': '5', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='â€¢ Performance measure P: Average distance traveled before an error \\nâ€¢ training experience: A sequence of images and steering commands recorded \\nwhile observing a human driver \\n \\niii) A chess learning problem \\nâ€¢ Task T: Playing chess \\nâ€¢ Performance measure P: Percent of games won against opponents \\nâ€¢ Training experience E: Playing practice games against itself \\n \\n \\nDefinition: A computer program which learns from experience is called a \\nmachine learning  program or simply a learning program. Such a program i s \\nsometimes also referred to as a learner. \\nBasic components of learning process \\nThe learning process, whether by a human or a machine, can be divided into four \\ncomponents, namely, data storage, abstraction, generalization and evaluation. \\nFigure 1.1 illustrates the  various components and  the steps involved in the  \\nlearning process. \\n \\n1. Data storage \\n \\n \\nFacilities for storing and retrieving huge amounts of data are an important'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 4, 'page_label': '5', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Figure 1.1 illustrates the  various components and  the steps involved in the  \\nlearning process. \\n \\n1. Data storage \\n \\n \\nFacilities for storing and retrieving huge amounts of data are an important \\ncomponent of the  learning process. Humans and computers alike utilize data \\nstorage as a foundation for advanced reasoning. \\nâ€¢ In a human being, the data is stored in the brain and data is retrieved using \\nelectrochemical signals. \\nâ€¢ Computers use hard disk drives, flash memory, random access memory and \\nsimilar devices  to store data and use cables and other  technology to retrieve'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 5, 'page_label': '6', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='data.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 6, 'page_label': '7', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='2. Abstraction \\n \\n \\nThe second component of the learning process is known as abstraction. \\nAbstraction is the  process of extracting knowledge about stored data. This \\ninvolves creating general concepts about the data as a whole. The creation of \\nknowledge involves application of known models  and creation of new models. \\nThe process of fitting a model to a dataset is known as training.  When the model \\nhas been trained, the data is transformed into an abstract form that summarizes the \\noriginal information. \\n \\n3. Generalization \\n \\n \\nThe third component of the learning process is known as generalisation. The \\nterm generalization describes the process of turning the knowledge about stored \\ndata into a form that can be utilized for future action. These actions are to be \\ncarried out on tasks that are similar,  but not identical, to those what have been \\nseen before. In generalization, the goal is to discover those properties of the data \\nthat will be most relevant to future tasks.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 6, 'page_label': '7', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='seen before. In generalization, the goal is to discover those properties of the data \\nthat will be most relevant to future tasks. \\n \\n4. Evaluation \\n \\n \\nEvaluation is the last component of the learning process. It is the process of \\ngiving feedback to the user to measure the utility of the learned knowledge. This \\nfeedback is then utilised to effect improvements in the whole learning process. \\n \\n        Applications of machine learning \\nThe following is a list of some of the typical applications of machine learning. \\n1. In retail business, machine learning is used to study consumer behaviour.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 7, 'page_label': '8', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='2. In finance, banks analyze their past data to build models to use in credit \\napplications, fraud detection, and the stock market. \\n3. In manufacturing, learning models are used for optimization, control, and troubleshooting. \\n4. In medicine, learning programs are used for medical diagnosis. \\n5. In telecommunications, call patterns are analyzed for network optimization \\nand maximizing the quality of service.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 8, 'page_label': '9', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='6. In science, large amounts of data in physics, astronomy, and biology can only \\nbe analyzed  fast enough by computers. The World Wide Web is huge; it is \\nconstantly growing and searching for relevant information  cannot be done \\nmanually. \\n7. In artificial intelligence, it is used to teach a system to learn and adapt to \\nchanges so that the system designer need  not foresee and provide solutions for \\nall possible situations. \\n8. It is used to find solutions to many problems in vision, speech recognition, and robotics. \\n9. Machine learning methods are applied in the design of computer-controlled \\nvehicles to steer correctly when driving on a variety of roads. \\n10. Machine learning methods have been used to develop programmes for \\nplaying games such as chess, backgammon and Go. \\n \\n Statistics vs Machine Learning \\n \\n \\nThe major difference between  machine learning and statistics is their purpose.  \\nMachine learning models are designed to make the most accurate predictions'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 8, 'page_label': '9', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Statistics vs Machine Learning \\n \\n \\nThe major difference between  machine learning and statistics is their purpose.  \\nMachine learning models are designed to make the most accurate predictions \\npossible. Statistical models are designed for  inference about the  relationships \\nbetween variables \\n1. Machine Learning is an algorithm that can learn from data without \\nrelying on rules- based programming. \\nStatistical modeling is a formalization of relationships between variables \\nin the data in the form of mathematical equations. \\n2. Machine learning is all about predictions, supervised learning, \\nunsupervised learning, etc. \\nStatistics is about sample, population, hypothesis, etc. \\n \\n3. Machine learning is a subfield of computer science and artificial \\nintelligence. It deals  with building systems that can learn from data, \\ninstead of explicitly programmed instructions.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 9, 'page_label': '10', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='A statistical model, on the other hand, is a subfield of mathematics. \\n4. Machine Learning is automated and requires less human intervention and \\nit deals with large datasets. \\nStatistics require a lot of human effort and deals with small datasets.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 10, 'page_label': '11', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Types of Machine Learning Algorithms: \\n \\nThese are three types of machine learning:  \\n \\n1. Supervised Learning \\n2. Unsupervised Learning \\n3. Reinforcement Learning \\n \\n \\n \\n \\n Supervised Learning: \\n \\n \\n\\uf0b7 Supervised learning is one of the most basic types of machine learning. \\n\\uf0b7 In this type, the machine learning algorithm is trained on labelled data. \\n\\uf0b7 In supervised learning, the ML algorithm is given a small training dataset to work \\nwith. \\n\\uf0b7 This training dataset is a smaller part of the bigger dataset and \\nserves to give the    algorithm a basic idea of the problem, solution, and \\ndata points to be dealt with. \\n\\uf0b7 At the end of the training, the algorithm has an idea of how the data'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 11, 'page_label': '12', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='works and the relationship between the input and the output. \\n\\uf0b7 Example: Risk Assessment, Image classification, Fraud Detection, spam filtering, \\netc. \\n \\n   How Supervised Learning Works? \\n \\nIn supervised learning, models are trained using labelled dataset, where the \\nmodel learns about each type of data. Once the training process is completed, the \\nmodel is tested on the basis of  test data (a subset of the training set), and then it \\npredicts the output. \\n \\nSuppose we have a dataset of different types of shapes which inclu des square, \\nrectangle, triangle, and Polygon. Now the first step is that we need to train the \\nmodel for each shape. \\n \\no If the given shape has four sides, and all the sides are equal, then it will \\nbe labelled as a Square. \\no If the given shape has three sides, then it will be labelled as a triangle. \\no If the given shape has six equal sides, then it will be labelled as hexagon. \\n \\nNow, after training, we test our model using the test set, and the task of the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 11, 'page_label': '12', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='o If the given shape has six equal sides, then it will be labelled as hexagon. \\n \\nNow, after training, we test our model using the test set, and the task of the \\nmodel is to identify the shape. The machine is already trained on all types of \\nshapes, and when it finds a new shape, it classifies the shape  on the bases of a \\nnumber of sides, and predicts the output.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 13, 'page_label': '14', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Advantages of Supervised learning: \\no With the help of supervised learning, the model can predict the output on \\nthe basis of prior experiences. \\no In supervised learning, we can have an exact idea about the classes of objects. \\n \\nDisadvantages of supervised learning: \\no Supervised learning models are not suitable for handling the complex tasks. \\no Supervised learning cannot predict the correct output if the test data is \\ndifferent from the training dataset. \\no Training required lots of computation times. \\n \\n Unsupervised Learning: \\n \\n\\uf0b7 Unsupervised machine learning holds the advantage of being able to work with \\nunlabelled data. \\n\\uf0b7 This means that human labour is not required to make the dataset \\nmachine-readable, allowing much larger datasets to be  worked on by  \\nthe program. \\n\\uf0b7 This offers more post-deployment development than supervised learning algorithms. \\n\\uf0b7 Example : Principal Component Analysis, Clustering \\n \\nHow Unsupervised Learning Works?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 14, 'page_label': '15', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=\"Here, we have taken an unlabelled input data, which \\nmeans it is not categorized and corresponding outputs \\nare also not given.  \\nNow, this unlabelled input data is fed to the machine \\nlearning model in order to train it. \\nFirstly, it will interpret the raw data  to find the hidden  \\npatterns from the data and then will apply suitable \\nalgorithms such as k-means clustering,  Decision tree, \\netc.  \\nOnce it applies the suitable algorithm, the algorithm \\ndivides the data objects into groups according to  the \\nsimilarities and difference between the objects. \\n \\nAdvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is used for more complex \\ntasks as compared to supervised learning because, \\nin unsupervised learning, we don't have labelled \\ninput data. \\n\\uf0b7 Unsupervised learning is preferable as it is easy to \\nget unlabelled data in comparison to labelled data. \\n \\nDisadvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is intrinsically more difficult\"),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 14, 'page_label': '15', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='get unlabelled data in comparison to labelled data. \\n \\nDisadvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is intrinsically more difficult \\nthan supervised learning as it does not have \\ncorresponding output.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 15, 'page_label': '16', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 The result of the unsupervised learning algorithm \\nmight be less accurate as input data is not labelled, \\nand algorithms do not know the exact output in \\nadvance. \\n \\n Semi-Supervised learning \\nSemi-supervised learning bridges supervised learning \\nand unsupervised learning techniques  to solve their \\nkey challenges. With it, you train an initial model on a \\nfew labeled samples and then iteratively apply it to the  \\ngreater number of unlabeled data. \\n \\nâ€¢ SSL works for a variety of problems from \\nclassification and  regression to clustering  and \\nassociation. \\nâ€¢ uses small amounts of labeled data and also large  \\namounts of unlabeled data, which reduces expenses on \\nmanual annotation and cuts data preparation time. \\n \\nWorking of Semi-Supervised Learning \\nSemi-supervised learning uses pseudo labeling to train the \\nmodel with less labeled training data than supervised \\nlearning. The process can combine various neural network \\nmodels and training ways.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 15, 'page_label': '16', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Semi-supervised learning uses pseudo labeling to train the \\nmodel with less labeled training data than supervised \\nlearning. The process can combine various neural network \\nmodels and training ways. \\nâ€¢ Firstly, it trains the model with less amount of \\ntraining data similar to the supervised learning \\nmodels. The training continues until the model gives'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 16, 'page_label': '17', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='accurate results. \\nâ€¢ The input data in labeled training data and unlabeled training \\ndata are also linked. \\nâ€¢ In the end, again train the model with the new \\ncombined input . \\nâ€¢ It will reduce errors and improve the accuracy of \\nthe model. \\n \\nSemi-supervised learning models applications \\no Speech Analysis \\no Web content classification \\no Text document classifier \\n \\n Reinforcement Learning \\n It is a part of ML where an agent is put in an \\nenvironment and he learns to behave in this \\nenvironment by performing certain actions and \\nobserving the rewards which it gets from those \\nactions. \\nFavourable outputs are encouraged or  â€˜reinforcedâ€™, \\nand non -favourable outputs  are discouraged or  \\nâ€˜punishedâ€™. \\n\\uf0b7 In every iteration of the algorithm, the output \\nresult is given to the interpreter, which  decides \\nwhether the outcome is favourable or not. \\n\\uf0b7 In case of the program finding the correct'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 17, 'page_label': '18', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='solution, the interpreter reinforces the solution by \\nproviding a reward to the algorithm.  \\n\\uf0b7 If the outcome is not favourable, the algorithm  is \\nforced to reiterate until it finds a better result.  \\n\\uf0b7 In most cases, the reward system is  directly tied to \\nthe effectiveness of the result. \\n\\uf0b7 In typical reinforcement learning use -cases, such \\nas finding the shortest route between  two points \\non a map. The higher this percentage value is,  the \\nmore reward is given to the algorithm. \\n\\uf0b7 Thus, the program is trained to give the best \\npossible solution for the best possible reward. \\nReinforcement Learning Applications'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 20, 'page_label': '21', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Difference Between Supervised, Unsupervised and Reinforcement \\nLearning'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 21, 'page_label': '22', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Types of Reinforcement learning \\n \\nThere are mainly two types of reinforcement learning, which are: \\n \\n\\uf0b7 Positive Reinforcement \\nThe positive reinforcement learning means \\nadding something to increase the tendency that expected \\nbehaviour would occur again. It impacts positively on \\nthe behaviour of the agent and increases the strength of \\nthe behaviour. This type of reinforcement can sustain the \\nchanges for a long time, but too much positive \\nreinforcement may lead to an overload of  states that can \\nreduce the consequences. \\n \\n\\uf0a7 Negative Reinforcement: \\nThe negative reinforcement learning is \\nopposite to the positive reinforcement as it increases the \\ntendency that the specific behaviour will occur again by \\navoiding the negative \\ncondition. It can be more effective than the positive \\nreinforcement depending on situation and behaviour, but it \\nprovides reinforcement only to meet minimum behaviour.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 22, 'page_label': '23', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='ML  Understanding Hypothesis \\n \\nIn most supervised machine learning algorithm, our main goal is to find \\nout a possible hypothesis from the hypothesis space that could \\npossibly map out the inputs to the proper outputs. \\nThe following figure shows the common method to find out the possible \\nhypothesis from the Hypothesis space: \\n \\n \\nHypothesis Space (H): \\nHypothesis space is the set of all the possible legal hypothesis. This is \\nthe set from which the machine learning algorithm would determine the \\nbest possible (only one) which would best describe the target function or \\nthe outputs. \\nHypothesis (h): \\nA hypothesis is a function that best describes the target in supervised'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 23, 'page_label': '24', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='machine learning. The hypothesis that an algorithm would come up \\ndepends upon the data and also depends upon the restrictions and \\nbias that we have imposed on the data. To better understand the \\nHypothesis Space and Hypothesis consider the following coordinate that \\nshows the distribution of some data:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 24, 'page_label': '25', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Say suppose we have test data for which we have to determine the \\noutputs or results. The test data is as shown below:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 25, 'page_label': '26', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='We can predict the outcomes by dividing the coordinate as shown \\nbelow:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 26, 'page_label': '27', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='So the test data would yield the following result: \\n \\nBut note here that we could have divided the coordinate plane as:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 27, 'page_label': '28', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The way in which the coordinate would be divided depends on the data, \\nalgorithm and constraints. \\n  All these legal possible ways in which we can divide the coordinate \\nplane to predict the outcome of the test data composes of the \\nHypothesis Space. \\n  Each individual possible way is known as the hypothesis. \\nHence, in this example the hypothesis space would be like:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 29, 'page_label': '30', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Hypothesis Testing in statistics \\n \\nHypothesis are statement about the given problem. \\n Hypothesis testing is a statistical method that is used in making a \\nstatistical decision using experimental data. \\n Hypothesis testing is basically an assumption that we make about a \\npopulation parameter. It evaluates two mutually exclusive statements \\nabout a population to determine which statement is best supported by the \\nsampledata    \\nExample: \\nYou say an average student in the class is 30  or a boy is taller than \\ngirls. All those are an example in which we assume or need some \\nstatistic way to prove those. We need some mathematical conclusion \\nwhatever we are assuming is true. \\nNeed for Hypothesis Testing \\nHypothesis testing is an important procedure in statistics. Hypothesis \\ntesting evaluates two mutually exclusive population statements to \\ndetermine which statement is most supported by sample data. When we \\nsay that the findings are statistically significant.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 29, 'page_label': '30', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='testing evaluates two mutually exclusive population statements to \\ndetermine which statement is most supported by sample data. When we \\nsay that the findings are statistically significant. \\n \\nParameters of hypothesis testing \\n \\n\\uf0b7 Null hypothesis(H0):  In statistics, the null hypothesis is a general \\ngiven statement or default position that there is no relationship \\nbetween two measured cases or no relationship among groups.  \\nIn other words, it is a basic assumption or made based on the problem \\nknowledge. \\n\\uf0b7 This hypothesis is either rejected or not rejected based on the \\nviability of the given   population or sample . \\nExample: A company production is = 50 unit/per day etc. \\n\\uf0b7 Alternative hypothesis(H1):  The alternative hypothesis is the \\nhypothesis used in hypothesis testing that is contrary to the null \\nhypothesis.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 30, 'page_label': '31', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Example : A company production is not equal to 50 unit/per day etc. \\n\\uf0b7 Level of significance \\nIt refers to the degree of significance in which we accept or reject the \\nnull-hypothesis. 100% accuracy is not possible for accepting a \\nhypothesis, so we, therefore, select a level of significance that is \\nusually 5%. This is normally denoted with and generally, it is 0.05 or \\n5%, which means your output should be 95% confident(significance \\nlevel is accepted) to give similar kind of result in each sample. \\n\\uf0b7 P-value \\nThe P value, or calculated probability, is the probability of finding the \\nobserved/extreme results when the  null hypothesis(H0) of a study \\ngiven problem is true.  \\n-If your P-value is less than the chosen significance level then you \\nreject the null hypothesis i.e. accept that your sample claims to \\nsupport the alternative hypothesis. \\n-P-Value is a statistical measure, that helps to determine whether \\nthe hypothesis is correct or not. \\nExample :'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 30, 'page_label': '31', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='support the alternative hypothesis. \\n-P-Value is a statistical measure, that helps to determine whether \\nthe hypothesis is correct or not. \\nExample : \\nGiven a coin and it is not known whether that is fair or tricky so letâ€™s \\ndecide null and alternate hypothesis \\n\\uf0b7 Null Hypothesis(H0): a coin is a fair coin. \\n\\uf0b7 Alternative Hypothesis(H1) : a coin is a tricky coin. \\n \\nNow letâ€™s toss the coin and calculate p-value (probability value). \\n\\uf0b7 Toss a coin 1st time and assume that result is head- P-value =50  (as \\nhead and tail have equal probability) \\n\\uf0b7 Toss a coin 2nd time and assume that result again is head, now p-\\nvalue = (1/2) * 50 ==50/2= 25 \\nError in Hypothesis Testing \\n\\uf0b7 Type I error: When we reject the null hypothesis, although that \\nhypothesis was true. Type I error is denoted by alpha. \\n\\uf0b7 Type II errors: When we accept the null hypothesis but it is false. \\nType II errors are denoted by beta.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 31, 'page_label': '32', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='What is Generalization in Machine Learning? \\nDefinition of generalization \\nIn machine learning, generalization is a definition to demonstrate how \\nwell is a trained model to classify or forecast unseen data.  \\nAn example is when we train a model to classify between dogs and \\ncats. If the model is provided with dogs images dataset with only two \\nbreeds, it may obtain a good performance.  \\nBut, it possibly gets a low classification score when it is tested by other \\nbreeds of dogs as well.  \\nTherefore, data diversity (decrease redundancy) is very important factor \\nin order to make a good prediction. In the sample above, the model may  \\nobtain 85% performance score when it is tested by only two dog breeds \\nand gains 70% if trained by all breeds. \\n However, the first possibly gets a very low score (e.g. 45%) if it is \\nevaluated by an unseen dataset with all breed dogs. This for the latter \\ncan be unchanged given than it has been trained by high data diversity'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 31, 'page_label': '32', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='evaluated by an unseen dataset with all breed dogs. This for the latter \\ncan be unchanged given than it has been trained by high data diversity \\nincluding all possible breeds. \\nIt should be taken into account that data diversity is not the only point to \\ncare in order to have a generalized model.  \\nIn this post we explain all determinant factors. There are some \\nmethods (regularization) to apply during model training to ensure \\nabout generalization. But before, we explain bias and variance as \\nwell as underfitting and overfitting. \\nVariance and bias (overfitting and underfitting) \\nVariance and bias are two important terms in machine learning.  \\nVariance means the variety of predictions values  made by a machine \\nlearning model (target function). (Variance describes how much a \\nrandom variable differs from its expected value. )'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 32, 'page_label': '33', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Bias means the distance of the predictions from the actual (true) target \\nvalues (bias is the amount that a modelâ€™s prediction differs from the \\ntarget value, compared to the training data. ) \\n A high -biased model means its prediction values (average) are far \\nfrom the actual values. (High bias would cause an algorithm to miss \\nrelevant relations between the input features and the target outputs. This \\nis sometimes referred to as underfitting.) \\nAlso, high-variance prediction means the prediction values are highly \\nvaried.(  a model that tries to fit most of the training dataset points making it \\ncomplex) \\nVariance-bias trade-off \\nThe prediction results of a machine learning model stand somewhere \\nbetween \\na) low-bias, low-variance,  \\nb) low-bias, high-variance (overfit) \\nc) high-bias, low-variance, and  \\nd) high-bias, high-variance.(underfit) \\n \\nA low-biased, high-variance model is called overfit and a high -biased, \\nlow-variance model is called underfit.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 32, 'page_label': '33', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='c) high-bias, low-variance, and  \\nd) high-bias, high-variance.(underfit) \\n \\nA low-biased, high-variance model is called overfit and a high -biased, \\nlow-variance model is called underfit.  \\nBy generalization, we find the best trade -off between underfitting and \\noverfitting so that a trained model obtains the best performance. \\n An overfit model obtains a  high prediction score on seen data and low \\none from unseen datsets. (data new to the model that was not part of the \\ntraining. ) \\nAn underfit model has low performance in both seen and unseen \\ndatasets.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 33, 'page_label': '34', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Three models with underfitting (left), goodfit ( middle), and overfitting \\n(right). Credit: https://scikit -learn.org/\\nOverfitting/overtraining in supervised learning (e.g., neural network). \\nTraining error is shown in blue, validation error in red, both as a \\nfunction of the number of training cycles. I f th e validation error \\nincreases(positive slope) while the training error steadily \\ndecreases(negative slope) then a situation of overfitting may have'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 34, 'page_label': '35', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='occurred. The best predictive and fitted model would be where the \\nvalidation error has its global minimum.  \\nDeterminant factors to train generalized models \\nThere are different ways to secure that a machine learning model is \\ngeneralized. Below we explain them. \\nDataset \\nIn order to train a classifier and generate a generalized machine learning \\nmodel, a used dataset should contain diversity. It should be noted that it \\ndoesnâ€™t mean a huge dataset but a dataset containing all different \\nsamples. This helps classifier to be trained not only from a specific \\nsubset of data and therefore, the generalization is better fulfil led. In \\naddition, during training, it is recommended to use  \\ncross validation techniques such as K -fold or Monte -Carlo cross \\nvalidations. These techniques better secure to exploit all possible \\nportions of data and to avoid generating an overfit model. \\nMachine Learning algorithm \\nMachine learning algorithms differently act against overfitting,'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 34, 'page_label': '35', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='portions of data and to avoid generating an overfit model. \\nMachine Learning algorithm \\nMachine learning algorithms differently act against overfitting, \\nunderfitting. Overfitting is more likely with nonlinear, non -parametric \\nmachine learning algorithms. For instance, Decision Tree is a non -\\nparametric machine learning algorithms, meaning its model is more \\nlikely with overfitting.  On the other hand, some machine learning \\nmodels are too simple to capture complex underlying patterns in data. \\nThis cause to build an underfit model. Examples are linear and \\nlogistic regression. \\nModel complexity \\nWhen a machine learning models becomes too complex, it is usually \\nprone to overfitting. There are methods that help to make the model \\nsimpler. They are called Regularization methods. Following we explain \\nit.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 35, 'page_label': '36', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Regularization \\nRegularization i s collection of methods to make a machine learning \\nmodel simpler. To this end, certain approaches are applied to different \\nmachine learning algorithms, for instance, pruning for decision trees, \\ndropout techniques for neural networks (reduction in overfittin g), \\nand adding a penalty parameters to the cost function in Regression.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 37, 'page_label': '38', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Bias and Variance in Machine Learning \\n\\uf0b7 Machine learning is a branch of Artificial Intelligence, which allows machines to  \\nPerform data analysis and make predictions.  \\n\\uf0b7 However, if the machine learning model is not accurate, it can make predictions errors, \\n and these prediction errors are usually known as Bias and Variance. \\n\\uf0b7 In machine learning, these errors will always be present as there is always a slight  \\ndifference  between the model predictions and actual predictions.  \\n\\uf0b7 The main aim of ML/data science analysts is to reduce these errors in order to get more \\n accurate results. In this topic,  we are going to discuss bias and variance, Bias-variance \\n trade-off,  Underfitting  and Overfitting.  \\n \\n \\nwhat errors in Machine learning are?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 38, 'page_label': '39', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=\"Errors in Machine Learning? \\nIn machine learning, an error is a measure of how accurately an algorithm can make  \\npredictions for the previously unknown dataset. On the basis of these errors, the machine \\n learning model is selected that can perform best on the particular dataset. There are mainly  \\ntwo types of errors in machine learning, which are: \\no Reducible errors: These errors can be reduced to improve the model accuracy.  \\nSuch errors can further be classified into bias and  Variance. \\no Irreducible errors: These errors will always be present in the model \\n   regardless of which algorithm has been used. The cause of these errors is unknown  \\n   variables whose value can't be reduced. \\no\"),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 39, 'page_label': '40', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='What is Bias? \\n  In general, a machine learning model analyses the data, find patterns in it and make \\n predictions.  \\n While training, the model learns these patterns in the dataset and applies them to test data \\n for prediction.  \\nWhile making predictions, a difference occurs between prediction values  \\nmade by the model and actual values/expected values, and this difference is known as \\n bias errors or Errors due to bias.  \\nIt can be defined as an inability of machine learning algorithms such as Linear  \\nRegression to capture the true relationship between the data points.  \\nEach algorithm begins with some amount of bias because bias occurs from assumptions'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 40, 'page_label': '41', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='in the model, which makes the target function simple to learn. A model has either: \\no Low Bias: A low bias model will make fewer assumptions about the form of the target  \\nfunction. \\no High Bias: A model with a high bias makes more assumptions, and the model  \\nbecomes unable to capture the important features of our dataset. A high bias model  \\nalso cannot perform well on new data. \\nGenerally, a linear algorithm has a high bias, as it makes them learn fast. The simpler the \\n algorithm, the higher the bias it has likely to be introduced. Whereas a nonlinear algorithm  \\noften has low bias. \\nSome examples of machine learning algorithms with low bias are Decision Trees,  \\nk-Nearest  Neighbours and Support Vector Machines. At the same time, an algorithm  \\nwith high bias  is Linear Regression, Linear Discriminant Analysis and Logistic \\n Regression. \\nWays to reduce High Bias: \\nHigh bias mainly occurs due to a much simple model. Below are some ways to reduce \\n the high bias:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 40, 'page_label': '41', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Regression. \\nWays to reduce High Bias: \\nHigh bias mainly occurs due to a much simple model. Below are some ways to reduce \\n the high bias: \\no Increase the input features as the model is underfitted. \\no Decrease the regularization term. \\no Use more complex models, such as including some polynomial features. \\nWhat is a Variance Error?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 41, 'page_label': '42', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The variance would specify the amount of variation in the prediction if the different training  \\ndata was used. In simple words, variance tells that how much a random variable is  \\ndifferent from its expected value. Ideally, a model should not vary too much from one  \\ntraining dataset to another, which means the algorithm should be good in understanding \\n the hidden mapping between inputs and output variables. Variance errors are either of  \\nlow variance or high variance. \\nLow variance means there is a small variation in the prediction of the target function with  \\nchanges in the training data set.  \\nAt the same time, High variance shows a large variation in the prediction of the target \\n function with changes in the training dataset. \\nA model that shows high variance learns a lot and perform well with the training dataset,  \\nand does not generalize well with the unseen dataset. As a result, such a model gives'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 41, 'page_label': '42', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='A model that shows high variance learns a lot and perform well with the training dataset,  \\nand does not generalize well with the unseen dataset. As a result, such a model gives  \\ngood results with the training dataset but shows high error rates on the test dataset. \\nSince, with high variance, the model learns too much from the dataset, it leads to overfitting  \\nof the model. A model with high variance has the below problems: \\no A high variance model leads to overfitting. \\no Increase model complexities. \\nUsually, nonlinear algorithms have a lot of flexibility to fit the model, have high variance.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 42, 'page_label': '43', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Some examples of machine learning algorithms with low variance are, Linear Regression,  \\nLogistic Regression, and Linear discriminant analysis. At the same time, algorithms with high  \\nvariance are decision tree, Support Vector Machine, and K-nearest neighbours. \\nWays to Reduce High Variance: \\no Reduce the input features or number of parameters as a model is overfitted. \\no Do not use a much complex model. \\no Increase the training data. \\no Increase the Regularization term. \\nDifferent Combinations of Bias-Variance \\nThere are four possible combinations of bias and variances, which are represented by the  \\nbelow diagram:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 43, 'page_label': '44', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='1. Low-Bias,LowVariance Low-Variance: \\nThe combination of low bias and low variance shows an ideal machine learning \\n model. However, it is not possible practically. \\n2. Low-Bias, High-Variance: With low bias and high variance, model predictions \\n are inconsistent and accurate on average. This case occurs when the model learns \\n with a large number of parameters and hence leads to an overfitting \\n3. High-Bias, Low-Variance: With High bias and low variance, predictions are  \\nconsistent but inaccurate on average. This case occurs when a model does not learn \\n well with the training dataset or uses few numbers of the parameter. It leads to \\n underfitting problems in the model. \\n4. HighBias,HighVariance  High-Variance:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 44, 'page_label': '45', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='With high bias and high variance, predictions are inconsistent and also inaccurate \\non average. \\nHow to identify High variance or High Bias? \\nHigh variance can be identified if the model has: \\n \\no Low training error and high test error. \\nHigh Bias can be identified if the model has: \\no High training error and the test error is almost similar to training error. \\n \\n \\nBias-Variance Trade-Off \\nWhile building the machine learning model, it is really important to take care of bias and \\n variance in order to avoid overfitting and underfitting in the model. If the model \\nis very simple with fewer parameters, it may have low variance and high bias. Whereas,'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 45, 'page_label': '46', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='if the model has a large number of parameters, it will have high variance and low bias.  \\nSo, it is required to make a balance between bias and variance errors, and this balance  \\nbetween the bias error and variance error is known as the Bias-Variance trade-off. \\n \\nFor an accurate prediction of the model, algorithms need a low variance and low bias.  \\nBut this is not possible because bias and variance are related to each other: \\no If we decrease the variance, it will increase the bias. \\no If we decrease the bias, it will increase the variance. \\nBias-Variance trade-off is a central issue in supervised learning. Ideally, we need a model \\n that accurately captures the regularities in training data and simultaneously generalizes \\n well with the unseen dataset. Unfortunately, doing this is not possible simultaneously.  \\nBecause a high variance algorithm may perform well with training data, but it may lead to'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 46, 'page_label': '47', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='overfitting to noisy data. Whereas, high bias algorithm generates a much simple model  \\nthat may not even capture important regularities in the data. So, we need to find a  \\nsweet spot between bias and variance to make an optimal model. \\nHence, the Bias-Variance trade-off is about finding the sweet spot to make a balance \\n between bias and variance errors.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae9212",
   "metadata": {},
   "source": [
    "### Embedding and VectorDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fef1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List,Dict,Any,Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17cd4c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model:all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 312.34it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succesfully. Embedding dimension:384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x185bdb138d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "\n",
    "    def __init__(self,model_name:str=\"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initalize the embedding manager\n",
    "\n",
    "        Args:\n",
    "            model_name=\"HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_name=model_name\n",
    "        self.model=None\n",
    "        self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model \"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model:{self.model_name}\")\n",
    "            self.model=SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded succesfully. Embedding dimension:{self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model{self.model_name}:{e}\")\n",
    "            raise    \n",
    "    def generate_embeddings(self,texts:List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "\n",
    "        Args:\n",
    "           texts:List of text strings to embed\n",
    "        Returns:\n",
    "           numpy array of embeddings with shape(len(texts),embedding_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings=self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape:{embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "\n",
    "### initalize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c860dd",
   "metadata": {},
   "source": [
    "### Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7cea7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection:pdf_documents\n",
      "Existing documents in collection:438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x185c332ed50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "\n",
    "    def __init__(self,collection_name:str=\"pdf_documents\",persist_directory:str=\"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "\n",
    "        Args:\n",
    "           collection_name:Name of the ChromaDB collection\n",
    "           persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name=collection_name\n",
    "        self.persist_directory=persist_directory\n",
    "        self.client=None\n",
    "        self.collection=None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB Client\n",
    "            os.makedirs(self.persist_directory,exist_ok=True)\n",
    "            self.client=chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "            self.collection=self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\":\"PDF document embeddings for RAG\"}\n",
    "\n",
    "            )    \n",
    "            print(f\"Vector store initialized. Collection:{self.collection_name}\")\n",
    "            print(f\"Existing documents in collection:{self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store:{e}\")\n",
    "            raise   \n",
    "\n",
    "    def add_documents(self,documents:List[Any],embeddings:np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embedings to the vector stor\n",
    "        \n",
    "        Args:\n",
    "            documents= List of Langchain documents\n",
    "            embeddings= Corresponding embeddings fro the documents                                                                                                                        \n",
    "            \n",
    "        \"\"\"\n",
    "        if len(documents)!=len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # prepare data for ChromaDB\n",
    "        ids=[]\n",
    "        metadatas=[]\n",
    "        documents_text=[]\n",
    "        embeddings_list=[]\n",
    "\n",
    "        for i,(doc,embeddings) in enumerate(zip(documents,embeddings)):\n",
    "            # Generate Unique ID\n",
    "            doc_id=f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #prepare metadata\n",
    "            metadata=dict(doc.metadata)\n",
    "            metadata['doc_index']=i\n",
    "            metadata['content_length']=len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            #Documents content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            #Embedding\n",
    "            embeddings_list.append(embeddings.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )   \n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection:{self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise     \n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8cba698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n \\n \\nUNIT V       DESIGN AND ANALYSIS OF MACHINE LEARNING EXPERIMENTS         8 \\nGuidelines for machine learning experiments, Cross Validation (CV) and resampling â€“ K- \\nfold CV, bootstrapping, measuring classifier performance, assessing a single classification \\nalgorithm and comparing two classification algorithms â€“ t test, Mc Nemarâ€™s test, K -fold \\nCV paired t test \\n \\n5.1 Guidelines for Machine Learning Experiments \\n \\nThe steps in machine learning are the same as for any type of \\nexperimentation, that at this point, it is  not important whether the task  \\nis classiï¬cation or regression, or whether it is an unsupervised or a  \\nreinforcement learning application. The same overall discussion \\napplies; the diï¬€erence is only in the sampling distribu- tion of the \\nresponse data that is collected. \\n \\nA. Aim of the Study \\nGiven two learning algorithms and a particular problem as deï¬ned  \\nbya dataset, we may want to determine which one has less generalization'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='response data that is collected. \\n \\nA. Aim of the Study \\nGiven two learning algorithms and a particular problem as deï¬ned  \\nbya dataset, we may want to determine which one has less generalization \\nerror. These can be two diï¬€erent algorithms, or one can be a proposed  \\nimprovement of the other, for example, by using a better feature extrac - \\ntor.In the general case, we may have more than two learning algorithms,  \\nand we may want to choose the one with the least error, or order them in \\nterms of error, for a given dataset.In an even more general setting, instead  of \\non a single dataset, we may want to compare two or more algorithms  on \\ntwo or more datasets. \\n \\nB. Selection of the Response Variable \\nWe need to decide on what we should use as the quality measure.  \\nMost frequently, error is used that is the misclassiï¬cation error for \\nclassiï¬ca- tion and mean square error for regression. We may also use  \\nsome variant;for example, generalizing from 0/1 to an arbitrary  loss, we'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='classiï¬ca- tion and mean square error for regression. We may also use  \\nsome variant;for example, generalizing from 0/1 to an arbitrary  loss, we \\nmay use a riskmeasure. In information retrieval, we use measures such as \\nprecision andrecall. In a cost-sensitive setting, not only the output but also \\nsystem parameters, for example, its complexity, are taken into account. \\n \\nC. Choice of Factors and Levels \\nWhat the factors are depend on the aim of the study. If we ï¬x an  \\nal- gorithm and want to ï¬nd the best hyperparameters,  then those are \\nthe factors. If we are comparing algorithms, the learning algorithm is a  \\nfac-tor. If we have diï¬€erent datasets, they also become a factor. \\nThe levels of a factor should be carefully chosen so as not to miss a'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ngood conï¬guration and avoid doing unnecessary experimentation. It is  \\nalways good to try to normalize factor levels. For example, in optimizing  \\nk of k-nearest neighbor, one can try values such as 1, 3, 5, and so on, but  \\nin optimizing the spread h of Parzen windows, we should not try absolute  \\nvalues such as 1.0, 2.0, and so on, because that depends on the scale of  \\nthe input; it is better to ï¬nd some statistic that is an indicator of scale â€” \\nfor example, the average distance between an instance and its nearest  \\nneighborâ€”and try h as diï¬€erent multiples of that statistic. \\n \\nD. Choice of Experimental Design \\nIt is always bett er to do a factorial design unless we are sure that  \\nthe factors do not interact, because mostly they do. Replication \\nnumber de -pends on the dataset size; it can be kept small when the  \\ndataset is large;we will discuss this in the next section when we talk  \\nabout resampling.However, too few replicates generate few data and'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='dataset is large;we will discuss this in the next section when we talk  \\nabout resampling.However, too few replicates generate few data and  \\nthis will make com-paring distributions diï¬ƒcult; in the particular case of \\nparametric tests, the assumptions of Gaussianity may not be tenable. \\nGenerally, given some dataset, we leave some part as the test set and \\nuse the rest for training and validation, probably many times by resam - \\npling. How this division is done is important. In practice, using small  \\ndatasets leads to responses with high variance, and the diï¬€erences will  \\nnot be signiï¬cant and results will not be conclusive. \\nIt is also important to avoid as much as possible toy,  synthetic data \\nand use datasets that are collected from real -world under real -life cir - \\ncumstances. Didactic one - or two -dimensional datasets may help pro vide \\nintuition, but the behavior of the algorithms may be completely diï¬€erent \\nin high-dimensional spaces. \\n \\nE. Performing the Experiment'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='intuition, but the behavior of the algorithms may be completely diï¬€erent \\nin high-dimensional spaces. \\n \\nE. Performing the Experiment \\nBefore running a large factorial experiment with many factors and  \\nlevels,it is best if one does a few trial runs for some r andom settings to  \\ncheck that all is as expected. In a large experiment, it is always a good idea \\nto save intermediate results (or seeds of the random number generator),  \\nso that a part of the whole experiment can be rerun when desired. All the \\nresults should be reproducable. In running a large experiment with many \\nfactors and factor levels, one should be aware of the possible negative  \\neï¬€ects of software aging. \\nIt is important that an experimenter be unbiased during experimen- \\ntation. In comparing oneâ€™s favorite algorithm with a competitor, both  \\nshould be investigated equally diligently. In large -scale studies, it may  \\neven be envisaged that testers be diï¬€erent from developers.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='should be investigated equally diligently. In large -scale studies, it may  \\neven be envisaged that testers be diï¬€erent from developers. \\nOne should avoid the temptation to write oneâ€™s own â€œlibraryâ€ and \\nin- stead, as much as possible, use code from  reliable  sources;  such code \\nwould have been better tested and optimized. \\nAs in any software development study, the advantages of good docu-\\nmentation cannot be underestimated, especially when working in'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ngroups.All the methods developed for high -quality software engineering  \\nshould also be used in machine learning experiments. \\n \\nF. Statistical Analysis of the Data \\nThis corresponds to analyzing data in a way so that whatever \\nconclusion we  get is not subjective or due to chance. We cast the \\nquestions thatwe want to answer in a hypothesis testing framework and  \\ncheck whether the sample supports the hypothesis.  For example, the  \\nquestion \"Is A a more accurate algorithm than B?\" becomes the \\nhypothesis \"Can we say tha t the average error of learners trained by A is \\nsigniï¬cantly lower than the average error of learners trained by B?\" \\nAs always, visual analysis is helpful, and we can use histograms of  \\nerrordistributions, whisker-and-box plots, range plots, and so on \\n \\nG. Conclusions and Recommendations \\nOnce all data is collected and analyzed, we can draw objective \\nconclu- sions. One frequently encountered conclusion is the need for'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='G. Conclusions and Recommendations \\nOnce all data is collected and analyzed, we can draw objective \\nconclu- sions. One frequently encountered conclusion is the need for  \\nfurther experimentation. Most statistical, and hence machine learning or \\ndata mining, studies are iterative. It is for this reason that we never start \\nwith all the experimentation. It is suggested that no more than 25 \\npercent of the available resources should be invested in the ï¬rst \\nexperiment (Mont - gomery 2005). The ï¬rst runs are for investigation \\nonly. That is also why it is a good idea not to start with high expectations, \\nor promises to oneâ€™s boss or thesis advisor. \\nWe should always remember that statistical testing never tells us \\nif the hypothesis is correct or false, but how much the sample seems  \\nto concur with the hypothesis. There is always a risk that we do not  \\nhave aconclusive result or that our conclusions be wrong, especially if  \\nthe data is small and noisy.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='to concur with the hypothesis. There is always a risk that we do not  \\nhave aconclusive result or that our conclusions be wrong, especially if  \\nthe data is small and noisy. \\nWhen our expectations are not met, it is most helpful to investigate  \\nwhythey are not. For example, in checking why our favorite algorithm A \\nhas worked awfully bad on some cases, we can get a splendid idea for  \\nsome improved version of A. All improvements are due to the \\ndeï¬ciencies of the previous version;  ï¬nding a deï¬ciency is but a helpful  \\nhint that there is an improvement we can make! \\nBut we should not go to the next step of testing the improved version  \\nbefore we are sure that we have completely analyzed the current data  \\nandlearned all we could learn from it. Ideas are cheap, and useless unless \\ntested, which is costly. \\n \\n5.2 Cross-Validation and Resampling Methods \\n\\uf0b7 For replication purposes, our first need is to get a number of training'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='tested, which is costly. \\n \\n5.2 Cross-Validation and Resampling Methods \\n\\uf0b7 For replication purposes, our first need is to get a number of training \\nand validation set pairs from a dataset X (after having left out some \\npart as the test set). \\n\\uf0b7 To get them, if the sample X is large enough, we can randomly divide it \\ninto K parts, then randomly divide each part into two and use one half  \\nfor training and the other half for validation.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 K is typically 10 or 30. Unfortunately, datasets are never large enough \\nto do this. \\n\\uf0b7 So we should do our best with small datasets. \\n\\uf0b7 This is done cross-validation by repeated use of the same data split \\ndifferently; this is called crossvalidation. \\n\\uf0b7 The catch is that this makes the error percentages dependent as these \\ndifferent sets share data. \\n\\uf0b7 So, given a dataset X, we would like to generate K training/validation \\nset pairs, {Ti, Vi}K i=1, from this dataset. \\n\\uf0b7 We would like to keep the training and validation sets as large as \\npossible so that the error estimates are robust, and at the same time, \\nwe would like to keep the overlap between different sets as small as \\npossible. \\n\\uf0b7 We also need to make sure that classes are represented in the right \\nproportions when subsets of data are held out, not to disturb the class \\nprior probabilities; this is called stratification. \\n\\uf0b7 If a class has 20 percent examples in the whole dataset, in all samples'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='prior probabilities; this is called stratification. \\n\\uf0b7 If a class has 20 percent examples in the whole dataset, in all samples  \\ndrawn from the dataset, it should also have approximately 20 percent \\nexamples. \\n5.3K-Fold Cross-Validation \\n\\uf0b7 K-fold In K-fold cross-validation, the dataset X is divided randomly into K \\nequalcross-validation sized parts, Xi, i = 1,...,K. \\n\\uf0b7 To generate each pair, we keep one of the K parts out as the validation set \\nand combine the remaining K âˆ’ 1 parts to form the training set. \\n\\uf0b7 Doing this K times, each time leaving out another one of the K parts out, we \\nget K pairs: V1 = X1 T1 = X2 ð–´ X3 ð–´Â·Â·Â·ð–´XK V2 = X2 T2 = X1 ð–´ X3 ð–´Â·Â·Â·ð–´XK . . . \\nVK = XK TK = X1 ð–´ X2 ð–´Â·Â·Â·ð–´XKâˆ’1 \\n\\uf0b7 There are two problems with this. First, to keep the training set large, we \\nallow validation sets that are small. \\n\\uf0b7 Second, the training sets overlap considerably, namely, any two training sets \\nshare K âˆ’ 2 parts. K is typically 10 or 30.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='allow validation sets that are small. \\n\\uf0b7 Second, the training sets overlap considerably, namely, any two training sets \\nshare K âˆ’ 2 parts. K is typically 10 or 30. \\n\\uf0b7 As K increases, the percentage of training instances increases and we get \\nmore robust estimators, but the validation set becomes smaller. \\n\\uf0b7 Furthermore, there is the cost of training the classifier K times, which \\nincreases as K is increased. \\n\\uf0b7 As N increases, K can be smaller; if N is small, K should be large to allow large \\nenough training leave-one-out sets. \\n\\uf0b7 One extreme case of K-fold cross-validation is leave-one-out where given a \\ndataset of N instances, only one instance is left out as the validation set \\n(instance) and training uses the N âˆ’ 1 instances.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 We then get N separate pairs by leaving out a different instance at each \\niteration. \\n\\uf0b7 This is typically used in applications such as medical diagnosis, where \\nlabeled data is hard to find. \\n\\uf0b7  Leave-one-out does not permit stratification. Recently, with computation \\ngetting cheaper, it has also become possible to have multiple runs of K-fold \\ncross-validation, for example, 10Ã—10- fold, and use average over averages to \\nget more reliable error estimates \\n5Ã—2 Cross-Validation \\n\\uf0b7 Dietterich (1998) proposed the 5 Ã— 2 cross-validation, which uses training \\nand validation sets of equal size. \\n\\uf0b7 We divide the dataset X randomly into two parts, X(1) 1and X(2) 1, which gives \\nour first pair of training and validation sets, T1 = X(1) 1and V1 = X(2) 1. \\n\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we \\nshuffle X randomly and divide this new fold into two, X(1) 2and X(2) 2. \\n\\uf0b7 This can be implemented by drawing these from X randomly without \\nreplacement, namely, X(1) 1ð–´ X(2) 1= X(1) 2ð–´ X(2) 2 = X. \\n\\uf0b7 We then swap these two halves to get another pair. We do this for three \\nmore folds and because from each fold, we get two pairs, doing five folds, we \\nget ten training and validation sets: T1 = X(1) 1V1 = X(2) 1T2 = X(2) 1 V2 = X(1) 1 \\nT3 = X(1) 2 V3 = X(2) 2 T4 = X(2) 2 V4 = X(1) 2  . . . T9 = X(1) 5 V9 = X(2) 5 T10 = X(2) \\n5 V10 = X(1) 5 Of course, we can do this for more than five folds and get more \\ntraining/validation sets, but Dietterich (1998) points out that after five \\nfolds, the sets share many instances and overlap so much that the statistics'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='training/validation sets, but Dietterich (1998) points out that after five \\nfolds, the sets share many instances and overlap so much that the statistics \\ncalculated from these sets, namely, validation error rates, become too \\ndependent and do not add new information. \\n\\uf0b7 Even with five folds, the sets overlap and the statistics are dependent, but \\nwe can get away with this until five folds. On the other hand, if we do have \\nfewer than five folds, we get less data (fewer than ten sets) and will not have \\na large enough sample to fit a distribution to and test our hypothesis on \\nTable 19.1 Confusion matrix for two  \\nclasses. \\n \\n Predicted \\nclass \\nTrue \\nClass \\nPositi \\nve \\nNegati \\nve \\nTot \\nal \\nPositive \\nNegative \\ntp : true \\npositive \\nfp : false \\npositive \\nfn : false \\nnegative \\ntn : true \\nnegative \\np \\nn \\nTotal pÃ— nÃ— N'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\n \\nBootstrapping \\n\\uf0b7 To generate multiple samples from a single sample, an alternative to \\nbootstrap cross-validation is the bootstrap that generates new samples by \\ndrawing instances from the original sample with replacement. \\n\\uf0b7 We saw the use of bootstrapping in section 17.6 to generate training sets for \\ndifferent learners in bagging. \\n\\uf0b7 The bootstrap samples may overlap more than cross-validation samples and \\nhence their estimates are more dependent; but is considered the best way to \\ndo resampling for very small datasets. \\n\\uf0b7 In the bootstrap, we sample N instances from a dataset of size N with \\nreplacement. \\n\\uf0b7 The original dataset is used as the validation set. The probability that we pick \\nan instance is 1/N; the probability that we do not pick it is 1 âˆ’ 1/N. \\n\\uf0b7 The probability that we do not pick it after N draws is \\n( 1 âˆ’ 1 /N)N â‰ˆ eâˆ’1 = 0.368 \\nThis means that the training data contains approximately 63.2 percent of the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 The probability that we do not pick it after N draws is \\n( 1 âˆ’ 1 /N)N â‰ˆ eâˆ’1 = 0.368 \\nThis means that the training data contains approximately 63.2 percent of the \\ninstances; that is, the system will not have been trained on 36.8 percent of the data, \\nand the error estimate will be pessimistic. The solution is replication, that is, to \\nrepeat the process many times and look at the average behavior. \\n \\n5.3 Measuring Classifier Performance \\nFor classification, especially for two-class problems, a variety of measures \\nhas been proposed. There are four possible cases, as shown in table 19.1. For a \\npositive example, if the prediction is also positive, this is a true positive; if our \\nprediction is negative for a positive example, this is a false negative. For a negative \\nexample, if the prediction is also negative, we \\nTable 19.2 Performance measures used in two - \\nclass problems. \\n \\nName Formula \\nerror \\naccuracy \\n(f  p  + fn)/N \\n(tp + tn)/N = 1- \\nerror \\ntp-rate \\nfp-rate \\ntp/p \\nfp/n'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Table 19.2 Performance measures used in two - \\nclass problems. \\n \\nName Formula \\nerror \\naccuracy \\n(f  p  + fn)/N \\n(tp + tn)/N = 1- \\nerror \\ntp-rate \\nfp-rate \\ntp/p \\nfp/n \\nprecision \\nrecall \\ntp/pâ€™ \\ntp/p = tp-rate \\nsensitivity \\nspeciï¬city \\ntp/p = tp-rate \\ntn/n = 1- fp-rate \\nhave a true negative, and we have a false positive if we predict a negative example as \\npositive.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nIn some two-class problems, we make a distinction between the two classes \\nand hence the two type of errors, false positives and false negatives. Different \\nmeasures appropriate in different settings are given in table 19.2. Let us envisage an \\nauthentication application where, for example, users log on to their accounts by \\nvoice. A false positive is wrongly logging on an impostor and a false negative is \\nrefusing a valid user. It is clear that the two type of errors are not equally bad; the \\nformer is much worse. True positive rate, tp-rate, also known as hit rate, measures \\nwhat proportion of valid users we authenticate and false positive rate, fp-rate, also \\nknown as false alarm rate, is the proportion of impostors we wrongly accept. \\nLet us say the system returns P(C Ë† 1|x), the probability of the positive class, and \\nfor the negative class, we have P(C Ë† 2|x) = 1 âˆ’ P (C Ë† 1|x), and we choose â€œpositiveâ€ if'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Let us say the system returns P(C Ë† 1|x), the probability of the positive class, and \\nfor the negative class, we have P(C Ë† 2|x) = 1 âˆ’ P (C Ë† 1|x), and we choose â€œpositiveâ€ if \\nP (C Ë† 1|x) > Î¸. If Î¸ is close to 1, we hardly choose the positive class; that is, we will \\nhave no false positives but also few true positives. As we decrease Î¸ to increase the \\nnumber of true positives, we risk introducing false positives. \\nFor different values of Î¸, we can get a number of pairs of (tp-rate, fp-rate) \\nvalues and by connecting them we get the receiver operating characteristics \\ncharacteristics (ROC) curve, as shown in figure 19.3a. Note that different values of Î¸ \\ncorrespond to different loss matrices for the two types of error and the ROC curve \\ncan also be seen as the behavior of a classifier \\nFigure 19.3 (a) Typical ROC curve. Each classifier has a threshold that allows us \\nto move over this curve, and we decide on a point, based on the relative importance'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Figure 19.3 (a) Typical ROC curve. Each classifier has a threshold that allows us \\nto move over this curve, and we decide on a point, based on the relative importance \\nof hits versus false alarms, namely, true positives and false positives. The area below \\nthe ROC curve is called AUC. (b) A classifier is preferred if its ROC curve is closer to \\nthe upper-left corner (larger AUC). B and C are preferred over A; B and C are \\npreferred under different loss matrices \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIdeally, a classifier has a tp-rate of 1 and a fp-rate of 0, and hence a classifier is \\nbetter the more it gets closer to the upper-left corner. On the diagonal, we make as \\nmany true decisions as false ones, and this is the worst one can do (any classifier \\nthat is below the diagonal can be improved by flipping its decision). Given two \\nclassifiers, we can say one is better than the other one if it is above the other one; if \\ntwo ROC curves intersect, we can say that the two classifiers are better under'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ndifferent loss conditions, as seen in figure 19.3b. \\nROC allows a visual analysis; if we want to reduce the curve to a single the \\nnumber we can do this by calculating the area under the curve (AUC).A classifier \\nideally has an AUC of 1 and AUC values of different classifiers can be compared to \\ngive us a general performance averaged over different loss conditions. \\nIn information retrieval, there is a database of records; we make a \\n \\n \\nPrecision = a/a+b \\nRecall = a/a+c \\n \\n \\n \\n(a) Precision and recall \\n \\n \\nFigure 19.4 (a) Definition of precision and recall using Venn diagrams. (b) Precision is 1; \\nall the retrieved records are relevant but there may be relevant ones not retrieved. (c) \\nRecall is 1; all the relevant records are retrieved but there may also be irrelevant \\nrecords that are retrieved. \\nPrecision=1 Recall=1 \\n \\n \\n \\n \\nquery, for example, by using some keywords, and a system (basically a two-class'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='records that are retrieved. \\nPrecision=1 Recall=1 \\n \\n \\n \\n \\nquery, for example, by using some keywords, and a system (basically a two-class \\nclassifier) returns a number of records. In the database, there are relevant records and \\nfor a query, the system may retrieve some of them (true positives) but probably not all \\n(false negatives); it may also wrongly retrieve records that are not relevant (false \\npositives). The set of relevant and retrieved records can be visualized using a Venn \\ndiagram, as shown in figure 19.4a. Precision is the number of retrieved and relevant \\nrecords divided by the total number of retrieved records; if precision is 1, all the \\nretrieved records may be relevant but there may still be records that are relevant but \\nnot retrieved. Recall is the number of retrieved relevant records divided by the total \\nnumber of relevant records; even if recall is 1, all the relevant records may be retrieved'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='not retrieved. Recall is the number of retrieved relevant records divided by the total \\nnumber of relevant records; even if recall is 1, all the relevant records may be retrieved \\nbut there may also be irrelevant records that are retrieved, as shown in figure19.4c. As \\nin the ROC curve, for different threshold values, one can draw a curve for precision vs. \\nrecall. \\nFrom another perspective but with the same aim, there are the two measures of \\nsensitivity and specificity. Sensitivity is the same as tp-rate and recall. Specificity is how'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nwell we detect the negatives, which is the number of true negatives divided by the total \\nnumber of negatives; this is equal to 1 minus the false alarm rate. One can also draw a \\nsensitivity vs. specificity curve using different thresholds. \\nIn the case of K > 2 classes, if we are using 0/1 error, the class confumatrix sion \\nmatrix is a KÃ—K matrix whose entry (i, j) contains the number of instances that belong to \\nCi but are assigned to Cj . Ideally, all off-diagonals should be 0, for no misclassification. \\nThe class confusion matrix allows us to pinpoint what types of misclassification occur, \\nnamely, if there are two classes that are frequently confused. Or, one can define K \\nseparate two-class problems, each one separating one class from the other K âˆ’ 1. \\n \\n5.4 Assessing a Classification Algorithmâ€™s Performance \\nWe will discuss the case of classification error, but the same methodology applies'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='5.4 Assessing a Classification Algorithmâ€™s Performance \\nWe will discuss the case of classification error, but the same methodology applies \\nfor squared error in regression, log likelihoods in unsupervised learning, expected \\nreward in reinforcement learning, and so on, as long as we can write the appropriate \\nparametric form for the sampling distribution. We will also discuss nonparametric \\ntests when no such parametric form can be found. \\n \\nBinomial Test \\nLet us start with the case where we have a single training set T and a single \\nvalidation set V . We train our classifier on T and test it on V . We denote by p the \\nprobability that the classifier makes a misclassification error. We do not know p; it is \\nwhat we would like to estimate or test a hypothesis about. On the instance with \\nindex t from the validation set V , let us say xt denotes the correctness of the \\nclassifierâ€™s decision: xt is a 0/1 Bernoulli random variable that takes the value 1'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='index t from the validation set V , let us say xt denotes the correctness of the \\nclassifierâ€™s decision: xt is a 0/1 Bernoulli random variable that takes the value 1 \\nwhen the classifier commits an error and 0 when the classifier is correct. The \\nbinomial random variable X denotes the total number of errors: \\n \\nX = âˆ‘t=1N xt \\nWe would like to test whether the error probability p is less than or equal to some \\nvalue p0 we specify: \\nH0 : p â‰¤ p0 vs. H1 : p>p0 \\nIf the probability of error is p, the probability that the classifier commits j errors out \\nof N is \\nP{X = j} = ( N/ j ) pj (1 âˆ’ p)N-j \\nIt is reasonable to reject p â‰¤ p0 if in such a case, the probability that binomial test we \\nsee X = e errors or more is very unlikely. That is, the binomial test rejects the hypothesis \\nif \\nP{X â‰¥ e} = âˆ‘x=eN ( N/ x ) p0x(1-p0 )N-x < Î± (19.10) \\nwhere Î± is the significance, for example, 0.05. \\n \\nApproximate Normal Test'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='if \\nP{X â‰¥ e} = âˆ‘x=eN ( N/ x ) p0x(1-p0 )N-x < Î± (19.10) \\nwhere Î± is the significance, for example, 0.05. \\n \\nApproximate Normal Test \\nIf p is the probability of error, our point estimate is pË† = X/N. Then, it is reasonable \\nto reject the null hypothesis if pË† is much larger than p0. How large is large enough is \\ngiven by the sampling distribution of pË† and the significance Î±. \\nBecause X is the sum of independent random variables from the same distribution, \\nthe central limit theorem states that for large N, X/N is approximately normal with \\nmean p0 and variance p0(1 â€“ p0). Then \\nX/N â€“ p0 / âˆšp0(1 âˆ’ p0) âˆ¼ZË™ (19.11) \\nwhere Ë™âˆ¼ denotes â€œapproximately distributed.â€ Then, using equation 19.7, the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\napproximate normal test rejects the null hypothesis if this value for X = e is greater than \\nzÎ±. Z0.05 is 1.64. This approximation will work well as long as N is not too small and p is \\nnot very close to 0 or 1; as a rule of thumb, we require Np â‰¥ 5 and N(1 âˆ’ p) â‰¥ 5. \\n \\nT Test \\nThe two tests we discussed earlier use a single validation set. If we run the algorithm \\nK times, on K training/validation set pairs, we get K error percentages, pi, i = 1,...,K on \\nthe K validation sets. Let xt i be 1 if the classifier trained on Ti makes a misclassification \\nerror on instance t of Vi; xti is 0 otherwise. Then \\npi = âˆ‘t=1N xt i/ N Given that m = âˆ‘i=1K pi /K , S2 = âˆ‘i=1K (p i-m)2 /K â€“ 1 \\nfrom equation 19.8, we know that we have \\nâˆš K(m â€“ p0)/ S  âˆ¼ tK-1 (19.12) \\nand the t test rejects the null hypothesis that the classification algorithm has p 0 or less \\nerror percentage at significance level Î± if this  value is greater than t á¼€,K-1. Typically, K is'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='and the t test rejects the null hypothesis that the classification algorithm has p 0 or less \\nerror percentage at significance level Î± if this  value is greater than t á¼€,K-1. Typically, K is \\ntaken as 10 or 30. T0.05,9= 1.83 and t0.05,29 = 1.70. \\n \\n5.5 Comparing Two Classification Algorithms \\nGiven two learning algorithms, we want to compare and test whether they \\nconstruct classifiers that have the same expected error rate. \\n \\nMcNemarâ€™s Test \\nGiven a training set and a validation set, we use two algorithms to train two \\nclassifiers on the training set and test them on the validation set and compute their \\nerrors. A contingency table, like the one shown here, is an array of natural numbers in \\nmatrix form representing counts, or frequencies: \\ne00: Number of \\nexamples \\nmisclassiï¬ed by both \\ne01: Number of \\nexamples \\nmisclassiï¬ed by 1 \\nbut not 2 \\ne10: Number of \\nexamples \\ne11: Number of \\nexamples \\nmisclassiï¬ed by 2 \\nbut not 1 \\ncorrectly classiï¬ed \\nby both'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='misclassiï¬ed by both \\ne01: Number of \\nexamples \\nmisclassiï¬ed by 1 \\nbut not 2 \\ne10: Number of \\nexamples \\ne11: Number of \\nexamples \\nmisclassiï¬ed by 2 \\nbut not 1 \\ncorrectly classiï¬ed \\nby both \\n \\nUnder the null hypothesis that the classification algorithms have the same error \\nrate, we expect e01 = e10 and these to be equal to (e01+e10)/2. We have the chi-square \\nstatistic with one degree of freedom \\n((|e01 â€“ e10| âˆ’ 1)2 /e01 + e10 ) âˆ¼ X2 1 \\nand McNemarâ€™s test rejects the hypothesis that the two classification algorithms \\nhave the same error rate at significance level Î± if this value is greater than X2 Î±,1. For \\nÎ± = 0.05, X2 0.05,1 = 3.84 \\n \\nK-Fold Cross-Validated Paired t Test \\nThis set uses K-fold cross-validation to get K training/validation set pairs. We use \\nthe two classification algorithms to train on the training sets Ti, i = 1,...,K, and test on the \\nvalidation sets Vi. The error percentages of the classifiers on the validation sets are \\nrecorded as p1i and p2 i .'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='validation sets Vi. The error percentages of the classifiers on the validation sets are \\nrecorded as p1i and p2 i . \\nIf the two classification algorithms have the same error rate, then we expect them \\nto have the same mean, or equivalently, that the difference of their means is 0. The'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\ndifference in error rates on fold i is pi= p1 i âˆ’p2 i. This is a paired test; that is, for each i, \\nboth algorithms see the same training and validation sets. When this is done K times, we \\nhave a distribution of pi containing K points. Given that p1i and p2 i are both \\n(approximately) normal, their difference pi is also normal. The null hypothesis is that \\nthis distribution has 0 mean: \\nH0 : Î¼ = 0 vs. H1 : Î¼ â‰  0 \\nWe define \\nm = âˆ‘i=1K pi /K ,  S2 = âˆ‘i=1K (p i-m)2 /K â€“ 1 \\nUnder the null hypothesis that Î¼ = 0, we have a statistic that is tdistributed with K âˆ’ 1 \\ndegrees of freedom: \\nâˆš K(m âˆ’ 0)/ S = âˆš K Â· m/ S  âˆ¼ tK-1 (19.14) \\nThus the K-fold cv paired t test rejects the hypothesis that two clastest sification \\nalgorithms have the same error rate at significance level Î± if this value is outside the \\ninterval (âˆ’tá¼€/2,K-1, tá¼€/2,K-1). T0.025,9 = 2.26 and t0.025,29 = 2.05. \\nIf we want to test whether the first algorithm has less error than the second, we'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='interval (âˆ’tá¼€/2,K-1, tá¼€/2,K-1). T0.025,9 = 2.26 and t0.025,29 = 2.05. \\nIf we want to test whether the first algorithm has less error than the second, we \\nneed a one-sided hypothesis and use a one-tailed test: \\nH0 : Î¼ â‰¥ 0 vs. H1 : Î¼ < 0 \\nIf the test rejects, our claim that the first one has significantly less error is supported. \\n \\n5 Ã— 2 cv Paired t Test \\nIn the 5 Ã— 2 cv t test, proposed by Dietterich (1998), we perform five replications of \\ntwofold cross-validation. In each replication, the dataset is divided into two equal-sized \\nsets. P(j)i is the difference between the error rates of the two classifiers on fold j = 1, 2 of \\nreplication i = 1,..., 5. The average on replication i is pâ€¾ i = (p(1) i+p(2) i)/2, and the \\nestimated variance is s2 i= (p(1)i  âˆ’ p- i)2+ (p(2) iâˆ’ p- i)2. \\nUnder the null hypothesis that the two classification algorithms have the same error \\nrate, p(j) i is the difference of two identically distributed proportions, and ignoring the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='Under the null hypothesis that the two classification algorithms have the same error \\nrate, p(j) i is the difference of two identically distributed proportions, and ignoring the \\nfact that these proportions are not independent, p(j) i can be treated as approximately \\nnormal distributed with 0 mean and unknown variance Ïƒ2. Then p(j) i /Ïƒ is \\napproximately unit normal. If we assume p(1) i and p(2) i are independent normals (which \\nis not strictly true because their training and test sets are not drawn independently of \\neach other), then s2 i /Ïƒ+2 has a chi-square distribution with one degree of freedom. If \\neach of the \\ns2 i are assumed to be independent (which is not true because they are all computed \\nfrom the same set of available data), then their sum is chi-square with five degrees of \\nfreedom: \\nM = âˆ‘5 i=1 s2 i  /Ïƒ2 âˆ¼ X2 5 \\nand \\nt = p(1) 1 /Ïƒ /âˆšM/5 = p(1) 1 / âˆšâˆ‘5 i=1 s2 i/5 âˆ¼ t5 (19.15) \\ngiving us a t statistic with five degrees of freedom. The 5 Ã— 2 cv paired t test rejects the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='freedom: \\nM = âˆ‘5 i=1 s2 i  /Ïƒ2 âˆ¼ X2 5 \\nand \\nt = p(1) 1 /Ïƒ /âˆšM/5 = p(1) 1 / âˆšâˆ‘5 i=1 s2 i/5 âˆ¼ t5 (19.15) \\ngiving us a t statistic with five degrees of freedom. The 5 Ã— 2 cv paired t test rejects the \\nhypothesis that the two classification algorithms have the same error rate at \\nsignificance level Î± if this value is outside the interval (âˆ’tá¼€/2,5, tá¼€/2,5). T0.025,5 = 2.57. \\n \\n5 Ã— 2 cv Paired F Test \\nWe note that the numerator in equation 19.15, p(1) 1 , is arbitrary; actually, ten \\ndifferent values can be placed in the numerator, namely, p(j) i, j = 1, 2, i = 1,..., 5, leading \\nto ten possible statistics: \\nt(j) i= p(j) i /âˆšâˆ‘5 i=1s2 i /5 (19.16) \\nAlpaydÄ±n (1999) proposed an extension to the 5 Ã— 2 cv t test that combines the results of'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T16:08:48+00:00', 'title': 'Untitled', 'author': 'Lakshmanan Kathiresan', 'moddate': '2024-01-30T16:08:48+00:00', 'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12', 'source_file': 'Cross Validation.pdf', 'file_type': 'pdf'}, page_content='lOMoARcPSD|285 747 87 \\n \\n \\nthe ten possible statistics. If p(j) i /Ïƒ âˆ¼ Z, then (p(j) i )2 /Ïƒ2 âˆ¼ X2 1 and their sum is chi- \\nsquare with ten degrees of freedom: \\nN = âˆ‘5 i=1âˆ‘2 j=1 (p(j) i)2 /Ïƒ2 âˆ¼ X2 10 \\nPlacing this in the numerator of equation 19.15, we get a statistic that is the ratio of \\ntwo chi-square distributed random variables. Two such variables divided by their \\nrespective degrees of freedom is F-distributed with ten and five degrees of freedom \\n(section A.3.8): \\nf = (N/10)/( M/5) = âˆ‘5 i=1âˆ‘2 j=1 (p(j) i)2 /2âˆ‘5i=1 s2 iâˆ¼F10,5 \\n5 Ã— 2 cv paired F test rejects the hypothesis that the classification algotest rithms have \\nthe same error rate at significance level Î± if this value is greater than Fá¼€,10.5. F0.05,10.5 = \\n4.74.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='DATABASE SYSTEM DEVELOPMENT LIFECYCLE: \\n \\nDatabase Planning: \\nThe management activities that allow the stages of the database system development lifecycle to be realized as efficiently \\nand effectively as possible. \\nAn important first step in database planning  is to clearly define the mission statement for the database system. The \\nmission statement defines the major aims of the database system. Those driving the database project within the \\norganization (such as the Director and/or owner) normally define the mis sion statement. A mission statement helps to \\nclarify the purpose of the database system and provide a clearer path towards the efficient and effective creation of the \\nrequired database system. \\nOnce the mission statement is defined, the next activity involves identifying the mission objectives. Each mission objective \\nshould identify a particular task that the database system must support. The assumption is that if the database system'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='should identify a particular task that the database system must support. The assumption is that if the database system \\nsupports the mission objectives, then the mission statement should be met. \\nDatabase planning should also include the development of standards that govern how data will be collected, how the \\nformat should be specified, what documentation will be needed, and how design and implementation should proceed. \\nSystem Definition: \\nDescribes the scope and boundaries of the database system and the major user views.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 1, 'page_label': '2', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='User Views: Defines what is required of a database system from the perspective of a particular job role (such as Manager \\nor Supervisor) or enterprise application area (such as marketing, personnel, or stock control). \\nA database system may have one or more user views. Identifying user views is an important aspect of developing a \\ndatabase system because it helps to ensure that no major users of the database are forgotten when developin g the \\nrequirements for the new database system. \\n \\nRepresentation of a database system with multiple user views: user views \\n \\nThere are three main approaches to managing the requirements of a database system with multiple user views: \\n\\uf0b7 the centralized approach \\n\\uf0b7 the view integration approach \\n\\uf0b7 a combination of both approaches \\nCentralized Approach: Requirements for each user view are merged into a single set of requirements for the new database \\nsystem. A data model representing all user views is created during the database design stage.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='The centralized (or one -shot) approach involves collating the requirements for different user views into a single list of \\nrequirements. The collection of user views is given a name that provides some indication of the application area covered \\nby all the merged user views. In the database design stage, a global data model is created, which represents all user views. \\nView Integration Approach: Requirements for each user view remain as separate lists. Data models representing each user \\nview are created and then merged later during the database design stage. \\nThe view integration approach involves leaving the requirements for each user view as separate lists of requirements. In \\nthe database design stage, we  first create a data model for ea ch user view. A data model that represents a single user \\nview (or a subset of all user views) is called a local data model. Each model is composed of diagrams and documentation'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='view (or a subset of all user views) is called a local data model. Each model is composed of diagrams and documentation \\nthat formally describes the requirements of one or moreâ€”but not allâ€”user views of the database. The local data models \\nare then merged at a later stage of database design to produce a global data model, which represents all user \\nrequirements for the database. \\n \\nDatabase Design: \\nThe process of creating a design that will support the en terpriseâ€™s mission statement and mission objectives for the \\nrequired database system. \\nThe two main approaches to the design of a database are: \\n\\uf0b7 â€œbottom-upâ€ \\n\\uf0b7 â€œtop-down.â€ \\nThe bottom-up approach begins at the fundamental level of attributes (that is, properties  of entities and relationships), \\nwhich through analysis of the associations between attributes are grouped into relations that represent types of entities \\nand relationships between entities.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='A more appropriate strategy for the design of complex databases is to use the top-down approach. This approach starts \\nwith the development of data models that contain a few high-level entities and relationships and then applies successive \\ntop-down refinements to identify lower-level entities, relationships, and the associated attributes. \\nThere are other approaches to database design, such as the inside -out approach and the mixed strategy approach. The \\ninside-out approach is related to the bottom- up approach, but differs by first identifying a set of major entities and then \\nspreading out to consider other entities, relationships, and attributes associated with those first identified. The mixed \\nstrategy approach uses both the bottom -up and top -down approach for various parts of the model before finally \\ncombining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='combining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design \\n \\nConceptual Database Design: The process of constructing a model of the data used in an enterprise, independent of all \\nphysical considerations. \\nLogical Database Design: The process of constructing a model of the data used in an enterprise based on a specific data \\nmodel, but independent of a particular DBMS and other physical considerations. \\nPhysical Database Design: The process of producing a description  of the implementation of the database on secondary \\nstorage; it describes the base relations, file organizations, and indexes used to achieve efficient access to the data, and \\nany associated integrity constraints and security measures. \\nDBMS Selection:  \\nThe selection of an appropriate DBMS to support the database system. \\nThe steps involved in database selection are: \\n\\uf0b7 Define Terms of Reference of study \\n\\uf0b7 Shortlist two or three products'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='The selection of an appropriate DBMS to support the database system. \\nThe steps involved in database selection are: \\n\\uf0b7 Define Terms of Reference of study \\n\\uf0b7 Shortlist two or three products \\n\\uf0b7 Evaluate products \\n\\uf0b7 Recommend selection and produce report \\nApplication Design: \\nThe design of the user interface and the application programs that use and process the database.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Database and application design are parallel activities of the database system development lifecycle. In most cases, it is \\nnot possible to complete the application design until the design of the database itself has taken place. \\nThe steps involved in application design are: \\n\\uf0b7 Transaction Design \\n\\uf0b7 User interface Design Guidelines \\nTransaction Design: An action, or series of actions, carried out by a single user or app lication program, that accesses or \\nchanges the content of the database. \\nThe purpose of transaction design is to define and document the high-level characteristics of the transactions required on \\nthe database, including: \\n\\uf0b7 data to be used by the transaction \\n\\uf0b7 functional characteristics of the transaction \\n\\uf0b7 output of the transaction \\n\\uf0b7 importance to the users \\n\\uf0b7 expected rate of usage \\nUser interface Design Guidelines: \\n\\uf0b7 Meaningful title \\n\\uf0b7 Comprehensible instructions \\n\\uf0b7 Logical grouping and sequencing of fields \\n\\uf0b7 Visually appealing layout of the form/report'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='User interface Design Guidelines: \\n\\uf0b7 Meaningful title \\n\\uf0b7 Comprehensible instructions \\n\\uf0b7 Logical grouping and sequencing of fields \\n\\uf0b7 Visually appealing layout of the form/report \\n\\uf0b7 Familiar field labels \\n\\uf0b7 Consistent terminology and abbreviations \\n\\uf0b7 Consistent use of color \\n\\uf0b7 Visible space and boundaries for data entry fields \\n\\uf0b7 Convenient cursor movement \\n\\uf0b7 Error correction for individual characters and entire fields \\n\\uf0b7 Error messages for unacceptable values \\n\\uf0b7 Optional fields marked clearly \\n\\uf0b7 Explanatory messages for fields \\n\\uf0b7 Completion signal \\nPrototyping: \\nBuilding a working model of a database system. \\nA prototype is a working model that does not normally have all the required fe atures or provide all the functionality of \\nthe final system. The main purpose of developing a prototype database system is to allow users to use the prototype to \\nidentify the features of the system that work well or are inadequate, and if possible to suggest improvements or even new'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 4, 'page_label': '5', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='identify the features of the system that work well or are inadequate, and if possible to suggest improvements or even new \\nfeatures to the database system. \\nThere are two prototyping strategies: \\n\\uf0b7 requirements prototyping - uses a prototype to determine the requirements of a proposed database system, and \\nonce the requirements are complete, the prototype is discarded \\n\\uf0b7 evolutionary prototyping - used for the same purposes, the important difference is that the prototype is not \\ndiscarded, but with further development becomes the working database system'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Implementation: \\nThe physical realization of the database and application designs. \\nThe database implementation is achieved using the DDL of the selected DBMS or a GUI, which provides the same \\nfunctionality while hiding the low-level DDL statements. The application programs are implemented using the preferred \\nthird- or fourth generation language (3GL or 4GL). \\nData Conversion and Loading: \\nTransferring any existing data into the new database and converting any existing applications to run on the new database. \\nThis stage is required only when a new database system is replacing an old system. \\nTesting: \\nThe process of running the database system with the intent of finding errors. \\nBefore going live, the newly developed database system should be thoroughly tested. This is achieved using carefully \\nplanned test strategies and realistic data, so that the entire testing process is methodically and rigorously carried out. \\nOperational Maintenance:'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='planned test strategies and realistic data, so that the entire testing process is methodically and rigorously carried out. \\nOperational Maintenance: \\nThe process of monitoring and maintaining the database system following installation. \\n\\uf0b7 Monitoring the performance of the system. If th e performance falls below an acceptable level, tuning or \\nreorganization of the database may be required. \\n\\uf0b7 Maintaining and upgrading the database system (when required). New requirements are incorporated into the \\ndatabase system through the preceding stages of the lifecycle. \\n \\nCASE Tools: \\nA computer -aided software engineering (CASE) tool is a software package that provides support for the design and \\nimplementation of information systems. It can document a database design and provide invaluable help in maintain ing \\nthe consistency of a design. By integrating many of the techniques used to document a system design  including the data'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 5, 'page_label': '6', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='the consistency of a design. By integrating many of the techniques used to document a system design  including the data \\ndictionary, data flows, and entity relationships, CASE tool can increase the consistency and accuracy of a database design. \\nIt can also ease the task of creating the diagrams that accompany a system design. \\nThere is no software in the world that can examine a database environment and identify the entities, attributes, and \\nrelationships that should be represented in a database. The model created with CASE tool is therefore only as good as the \\nanalysis of the database environment provided by the people using the tool. \\nCASE support may include: \\n\\uf0b7 a data dictionary to store information about the database systemâ€™s data \\n\\uf0b7 design tools to support data analysis \\n\\uf0b7 tools to permit development of the corporate data model, and the conceptual and logical data models \\n\\uf0b7 tools to enable the prototyping of applications'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 6, 'page_label': '7', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Requirements Collection: \\nFact Finding Technique: \\nThe formal process of using techniques suc h as interviews and questionnaires to collect facts about systems, \\nrequirements, and preferences.  Fact-finding is particularly crucial to the early stages of the lifecycle, including the \\ndatabase planning, system definition, and requirements collection and analysis stages. \\nThere are five commonly used fact-finding techniques: \\n\\uf0b7 examining documentation \\n\\uf0b7 interviewing \\n\\uf0b7 observing the enterprise in operation \\n\\uf0b7 research \\n\\uf0b7 questionnaires \\nthe below diagram depicts the examples of data captured in each of the stages of the development life cycle.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 7, 'page_label': '8', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='DreamHome Case Study: \\nDreamHome specializes in property management, taking an intermediate role between owners who wish to rent out their \\nfurnished property and clients of DreamHome who require to rent furnished property for a fi xed period. DreamHome \\ncurrently has about 2000 staff working in 100 branches. \\n \\nMission Statement for the Case Study: \\n \\n \\nMission Objectives for the Case Study:'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 8, 'page_label': '9', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='System boundary for the Case Study: \\n \\n \\nENTITY-RELATIONSHIP MODELING: \\nAn entity is a \"thing\" or \"object\" in the real world that is distinguishable from all other objects. For example, each person \\nin an enterprise is an entity. An entity set is a set of entities of the same type that share the same properties, or attributes. \\nThe set of all persons who are customers at a given bank, for example, can be defined as the entity set customer. \\nAn entity is represented by a set of attributes. Attributes are descriptive properties possessed by each member of an \\nentity set. \\nAttribute domain: The set of allowable values (data type) for one or more attributes. \\nTypes of Attributes: \\nSimple Attribute: An attribute composed of a single component with an independent existence.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Composite Attribute: An attribute composed of multiple components, each with an independent existence. \\nSingle-Valued Attributes: An attribute that holds a single value for each occurrence of an entity type. \\nMulti-Valued Attributes: An attribute that holds multiple values for each occurrence of an entity type. \\nDerived Attributes: An attribute that represents a value that is derivable from the value of a related attribute or set of \\nattributes, not necessarily in the same entity type. \\n \\nA relationship is an association among several entities.  Relationship set is a set of relationships of the same type. \\nThe association between entity set is referred to as participation. That is, the entity sets E1, E2, . ..,En participate in \\nrelationship set R. \\nA uniquely identifiable association that includes one occurrence from each participating entity type. A relatio nship \\noccurrence indicates the particular entity occurrences that are related. Relationship type and Relationship occurrences'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 9, 'page_label': '10', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='occurrence indicates the particular entity occurrences that are related. Relationship type and Relationship occurrences \\nare one and the same.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 10, 'page_label': '11', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Degree of a relationship: The number of participating entity types in a relationship. Binary relationship set is of degree 2; \\na tertiary relationship set is of degree 3. \\nUnary relationship: A unary relationship exists when an association is maintained within a single entity. \\n \\nBinary relationship: A binary relationship exists when two entities are associated. \\n \\n \\nTernary relationship: A ternary relationship exists when there are three entities associated. \\n \\n \\nQuaternary relationship: A quaternary relationship exists when there are four entities associated. \\n \\n \\nEntity role: The function that an entity plays in a relationship is called that entityâ€˜s role. A role is one end of an association. \\nIn the below ER model, the publisher entity plays the publishes role. \\n \\n \\nRecursive Relationship: A relationship type in which the same entity type participates more than once in different roles.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Keys: \\nSuper Key: Super key is a single attribute or a group of multiple attributes that can uniquely identify each occurrence of \\nan entity type. \\nCandidate Key: The minimal set of attributes that uniquely identifies each occurrence of an entity type. \\nPrimary Key: The candidate key that is selected to uniquely identify each occurrence of an entity type. \\nComposite Key: A candidate key that consists of two or more attributes. \\nForeign Key: Foreign key is an attribute which is a Primary key in its parent entity, but is included as an attribute in another \\nentity. A Foreign key generates a relationship between the parent entity and the child entity. \\nAlternate or Secondary Key: Alternate keys are those candidate keys which are not the Primary key. \\n \\nAn entity set may not have sufficient attributes to form a primary key. Such an entity set is termed a weak entity set. An \\nentity set that has a primary key is termed a strong entity set.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 11, 'page_label': '12', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='An entity set may not have sufficient attributes to form a primary key. Such an entity set is termed a weak entity set. An \\nentity set that has a primary key is termed a strong entity set. \\nWeak entity set is associated with another entity set called the identifying or owner entity set. i.e., weak entity set is said \\nto be existence dependent on the identifying entity set. Identifying entity set is said to own the weak entity set. \\nThe relationship among the weak and identifying entity set is called the identifying relationship. \\n \\nSTRUCTURAL CONSTRAINTS: \\nMultiplicity: The number (or range) of possible occurrences of an entity type that may relate to a single occurrence of an \\nassociated entity type through a particular relationship. \\n\\uf0b7 one-to-one (1:1) \\n\\uf0b7 one-tomany (1:*) \\n\\uf0b7 many-to-many (*:*)'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 12, 'page_label': '13', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='One-to-one: An entity in A is associated with at most one entity in B, and an entity in B is associated  with at most one \\nentity in A. \\n \\nExample: Relationship between Manager and Branch of a Bank. \\n \\nOne-to-many: An entity in A is associated with any number of entities (zero or more) in B. An entity in B, however, can be \\nassociated with at most one entity in A. \\n \\nExample: Relationship between Department and Employee. \\n \\nMany-to-many: An entity in A is associated with any number (zero or more) of entities in B, and an entity in B is associated \\nwith any number (zero or more) of entities in A. \\n \\nExample: Relationship between Supplier and Products. \\n \\nCardinality and Participation Constraints : Multiplicity actually consists of two separate constra ints known as cardinality \\nand participation.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Cardinality: Describes the maximum number of possible relationship occurrences for an entity participating in a given \\nrelationship type. \\n \\nParticipation: Determines whether all or only some entity occurrences participate in a relationship \\nThe participation constraint represents whether all entity occurrences are involved in a particular relationship (referred \\nto as mandatory participation) or only some (referred to as optional participation). \\n \\n \\nProblems with ER Models: \\nFan Trap: Where a model represents a relationship between entity types, but the pathway between certain entity \\noccurrences is ambiguous. \\nChasm Trap: Where a model suggests the existence of a relationship between entity types, but the pathway does not exist \\nbetween certain entity occurrences \\n \\n \\nENHANCED ER MODEL \\nIt is a diagrammatic technique for displaying the following concepts \\n\\uf0b7 Sub Class and Super Class \\n\\uf0b7 Specialization and Generalization \\n\\uf0b7 Aggregation \\n\\uf0b7 Composition'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 14, 'page_label': '15', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Super Class: An entity type that includes one or more distinct subgroupings of its occurrences, which must be represented \\nin a data model. \\nSub Class: A distinct subgrouping of occurrences of an entity type, which must be represented in a data model. \\nSpecialization: Specialization is the process of defining a set of subclasses of an entity type. The process of maximizing the \\ndifferences between members of an entity by identifying their distinguishing characteristics. The set of subclasses that \\nforms a specialization is defined on the basis of some distinguishing characteristic of the entities in the superclass. \\nGeneralization: A reverse process of abstraction . Suppress the differences among several entity types . The process of \\nminimizing the differences between entities by identifying their common characteristics. Identify their common features, \\nand generalize them into a single superclass of which the original entity types are special subclasses.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Constraints on Specialization/Generalization : In some specializations we can determine exa ctly the entities that will \\nbecome members of each subclass by placing a condition on the value of some attribute of the superclass. Such subclasses \\nare called predicate-defined (or condition-defined) subclasses. \\nâ€¢ Participation Constraints: Determines whether every member in the superclass must participate as a member of \\na subclass \\nâ€¢ Disjoint Constraints: Describes the relationship between members of the subclasses and indicates whether it is \\npossible for a member of a superclass to be a member of one, or more than one, subclass. \\nIf all subclasses in a specialization have their membership condition on the same attribute of the superclass, the \\nspecialization itself is called an attribute -defined specialization . The attribute is called the defining attribute of t he \\nspecialization. When we do not have a condition for determining membership in a subclass, the subclass is called user -'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 15, 'page_label': '16', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='specialization. When we do not have a condition for determining membership in a subclass, the subclass is called user -\\ndefined subclass. \\nA total specialization constraint specifies that every entity in the superclass must be a member of at least one subclass in \\nthe specialization. A partial specialization, which allows an entity not to belong to any of the subclasses. \\nA specialization Lattice: \\nA set of entities that are at two or more levels is called as a specialization lattice. It is also called as mul ti-level \\nspecialization.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Aggregation: \\nâ€¢ Aggregation is an abstraction concept for building composite objects from their component objects.  \\nâ€¢ Represents a â€œhas-aâ€ or â€œis-part-ofâ€ relationship between entity types, where one represents the â€œwholeâ€ and the \\nother the â€œpart.â€ \\nThree Cases \\nâ€¢ We aggregate attribute values of an object to form the whole object \\nâ€¢ We represent an aggregation relationship as an ordinary relationship \\nâ€¢ Combining objects that are related by a particular relationship instance into a higher-level aggregate \\nobject \\nâ€¢ IS-A-PART-OF and IS-A-COMPONENT-OF \\nComposition: \\nA specific form of aggregation that represents an association between entities, where there is a strong ownership and \\ncoincidental lifetime between the â€œwholeâ€ and the â€œpart.â€ \\nEg.: A newspaper displays an advertisement \\n \\nUML Class Diagram: \\nIn UML class diagrams, \\nâ€“ a class (similar to an entity type in ER) is displayed as a box that includes three sections:'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 16, 'page_label': '17', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='Eg.: A newspaper displays an advertisement \\n \\nUML Class Diagram: \\nIn UML class diagrams, \\nâ€“ a class (similar to an entity type in ER) is displayed as a box that includes three sections: \\nâ€¢ The top section gives the class name (similar to entity type name) \\nâ€¢ the middle section includes the attributes \\nâ€¢ last section includes operations that can be applied to individual objects \\nâ€“ Operations are not specified in ER diagrams.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='â€¢ The designer can optionally specify the domain (or data type) of an attribute if desired, by placing a colon (: ) \\nfollowed by the domain name or description \\nâ€¢ A composite attribute is modeled as a structured domain \\nâ€¢ A multivalued attribute will generally be modeled as a separate class \\nâ€¢ Relationship types are called associations in UML terminology, and relationship instances are called links \\n \\nAssociations: \\nA binary association is represented as a line connecting the participating classes, and may optionally have a name \\nâ€¢ A relationship attribute, called a link attribute, is placed in a box that is connected to the associati onâ€™s line by a \\ndashed line \\nâ€¢ The (min, max) notation is used to specify relationship constraints, which are called multiplicities in UML \\nterminology \\nâ€“ Multiplicities are specified in the form min..max, and an asterisk (*) indicates no maximum limit on \\nparticipation  \\nIn UML, there are two types of relationships: \\nâ€“ Association \\nâ€“ Aggregation'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 17, 'page_label': '18', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='â€“ Multiplicities are specified in the form min..max, and an asterisk (*) indicates no maximum limit on \\nparticipation  \\nIn UML, there are two types of relationships: \\nâ€“ Association \\nâ€“ Aggregation \\nAggregation is meant to represent a relationship between a whole object and its component parts, and it has a distinct \\ndiagrammatic notation. \\nUML also distinguishes between unidirectional and bidirectional associations/aggregations. In the unidirectional case, the \\nline connecting the classes is displayed with an arrow to indicate that only one direction for accessing related objects is \\nneeded. If no arrow is displayed, the bidirectional case is assumed, which is the default. In addition, relationship instances \\nmay be specified to be ordered.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-02T01:47:26-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-02T01:47:26-07:00', 'source': '..\\\\data\\\\PDF\\\\Data Modelling.pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'source_file': 'Data Modelling.pdf', 'file_type': 'pdf'}, page_content='ER Model for a Banking System: \\n \\nER Model for a University System'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='AD8401 Database Design and Management \\n \\n \\nA database is an organized collection of data elements (facts) stored in a computer in a systematic way, \\nsuch that a computer program can consult it to answer questions. The answers to those questions become \\ninformation that can be used to make decisions t hat may not be made with the data elements alone. A \\nsoftware system that enables users to define, create, maintain, query, and control access to the database.is \\nknown as a database management system (DBMS). A computer program that interacts with the databa se \\nby issuing an appropriate request (typically an SQL statement) to the DBMS is known as a database \\napplication program. \\n \\nTraditional File Processing System: File-based systems were an early attempt to computerize the manual \\nfiling system. However, rather  than establish a centralized store for the organizationâ€™s operational data, a \\ndecentralized approach was taken, where each department stored and controlled its own data.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='decentralized approach was taken, where each department stored and controlled its own data. \\n \\nIssues in File Based Systems: \\nâ— Separation and isolation of data: When data is isolated in separate files, it is more difficult to \\naccess data that should be available. \\nâ— Duplication of data: Owing to the decentralized approach taken by each department, the file-\\nbased approach encouraged, if not necessitated, the uncontrolled duplication of data. \\nâ— Difficulty in accessing data In order to retrieve, access and use stored data, need to write a \\nnew program to carry out each new task. \\nâ— Programâ€“Data dependence: The physical structure and storage of the data files and records \\nare defined in the application code.  \\nâ— Data Inconsistency: Data is updated in one file and not in other files and thus some data \\nbecomes invalid. \\nâ— Data Integrity: Allows some invalid data to enter into the system. \\nâ— Data Security: Everyone who has access to the file can view all the data.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='becomes invalid. \\nâ— Data Integrity: Allows some invalid data to enter into the system. \\nâ— Data Security: Everyone who has access to the file can view all the data. \\nâ— Atomicity of updates Failures of files may leave database in an inconsistent state with partial \\nupdates carried out.  \\n \\nThree Level Architecture (Abstraction): \\n \\nExternal View: The external or view level includes a number of external schemas or user views. Each external \\nschema describes the part of the database that a particular user group is interested in and hides the rest of \\nthe database from that user group.  \\nConceptual View: The conceptual level has a conceptual schema, which describes the structure of the whole \\ndatabase for a community of users. The conceptual schema hides the details of physical storage structures \\nand concentrates on describing entities, data types, relationships, user operations, and constraints'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='and concentrates on describing entities, data types, relationships, user operations, and constraints \\nPhysical View (Internal V iew): The internal level has an internal schema, which describes the physical \\nstorage structure of the database. The internal schema uses a physical data model and describes the \\ncomplete details of data storage and access paths for the database.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 1, 'page_label': '2', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Logical data independence is the capacity to change the conceptual schema without having to change \\nexternal schemas or application programs. We may change the conceptual schema to expand the database \\n(by adding a record type or data item), to change constrai nts, or to reduce the database (by removing a \\nrecord type or data item).\\nPhysical data independence is the capacity to change the internal schema without having to change the \\nconceptual schema. Hence, the external schemas need not be changed as well. Changes to the internal \\nschema may be needed because some physical files were reorganizedâ€”for example, by creating additional \\naccess structuresâ€”to improve the performance of retrieval or update.  \\nUsers of the Database: \\n \\nNaive User: The end-users are the â€œclientsâ€ of the databaseNaÃ¯ve users are typically unaware of the DBMS. \\nThey access the database through specially written application programs that attempt to make the operations \\nas simple as possible.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 1, 'page_label': '2', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='They access the database through specially written application programs that attempt to make the operations \\nas simple as possible.  \\n \\nApplication Programmer : Each program contains statements that request the DBMS to perform some \\noperation on the database, whi ch includes retrieving data, inserting, updating, and deleting data. The \\nprograms may be written in a third-generation or fourth-generation programming language. \\n \\nDatabase Designer: The logical database designer must have a thorough and complete understanding  of \\nthe organizationâ€™s data and any constraints on this data (the constraints are sometimes called business \\nrules).  \\n \\nDatabase Administrator: The Database Administrator (DBA) is responsible for the physical realization of the \\ndatabase, including physi cal database design and implementation, security and integrity control, \\nmaintenance of the operational system, and ensuring satisfactory performance of the applications for users.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Advantages of DBMSs\\nControl of data redundancy: the database approach attempts to eliminate the redundancy by integrating the \\nfiles so that multiple copies of the same data are not stored.\\nData consistency: By eliminating or controlling redundancy, we reduce the risk of inconsistencies occurring. \\nIf a data item is stored only once in the database, any update to its value has to be performed only once and \\nthe new value is available immediately to all users.\\nMore information from the same amount of data : With the integra tion of the operational data, it may be \\npossible for the organization to derive additional information from the same data. \\nSharing of data the database belongs to the entire organization and can be shared by all authorized users. \\nIn this way, more users share more of the data. \\nImproved data integrity: Integrity is usually expressed in terms of constraints, which are consistency rules'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='In this way, more users share more of the data. \\nImproved data integrity: Integrity is usually expressed in terms of constraints, which are consistency rules \\nthat the database is not permitted to violate. Constraints may apply to data items within a single record or to \\nrelationships between records.\\nDatabase security is the protection of the database from unauthorized users. This security may take the form \\nof usernames and passwords to identify people authorized to use the database. Granti ng restricted access \\nto the users.\\nEnforcement of standards : integration allows the DBA to define and the DBMS to enforce the necessary \\nstandards.\\nEconomy of scale: Combining all the organizationâ€™s operational data into one database and creating a set of \\napplications that work on this one source of data can result in cost savings. \\nBalance of conflicting requirements : Each user or depart ment has needs that may be in conflict with the \\nneeds of other users.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Balance of conflicting requirements : Each user or depart ment has needs that may be in conflict with the \\nneeds of other users. \\nImproved data accessibility and responsiveness : Again, as a result of integration, data that crosses \\ndepartmental boundaries is directly accessible to the end users. \\n \\nIncreased productivity: As mentioned previously, the DBMS provides many of the standard functions that the \\nprogrammer would normally have to write in a file based application. Eg: low-level file-handling routines \\nImproved maintenance  through data independence: A DBMS separates the data descriptions from the \\napplications, thereby making applications immune to changes in the data descriptions.\\nIncreased concurrency: Many DBMSs manage concurrent database access and ensure that multiple users \\ncan access the data simultaneously.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Improved backup and recovery services: Modern DBMSs provide facilities to minimize the amount of \\nprocessing that is lost following a failure.\\nDisadvantages of DBMSs\\nComplexity: The provision of the functionality that we expect of a good DBMS makes the DBMS an extremely \\ncomplex piece of software. \\nSize: The complexity and breadth of functionality makes the DBMS an extremely large piece of software, \\noccupying many megabytes of disk space and requiring substantial amounts of memory to run efficiently. \\nCost: The cost of DBMSs varies significantly, depending on the environment and functionality provided. For \\nexample, a single-user DBMS costs less than a large mainframe multi-user DBMS. There is also the recurrent \\nannual maintenance cost. \\nAdditional hardware costs The disk storage requirements for the DBMS and the database may necessitate \\nthe purchase of additional storage space. \\nCost of conversion: The cost of converting existing applications to run on the new DBMS and hardware.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='the purchase of additional storage space. \\nCost of conversion: The cost of converting existing applications to run on the new DBMS and hardware.\\nPerformance: DBMS is written to be more general, to cater for many applications rather than just one. The \\nresult is that some applications may not run as fast as they used to. \\nGreater impact of a failure The centralization of resources increases the vulnerability of the system. Because \\nall users and applications rely on the availability of the DBMS, the failure of certain components can bring \\noperations to a halt.\\n \\nDBMS environment\\nThe DBMS and the applications require hardware to run. The hardware can range from a single personal \\ncomputer to a single mainframe or a network of computers. The particular hardware depends on the \\norganizationâ€™s requirements and the DBMS used.  \\n \\nThe software component comprises the DBMS software itself and the application programs, together with'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='organizationâ€™s requirements and the DBMS used.  \\n \\nThe software component comprises the DBMS software itself and the application programs, together with \\nthe operating system, including network software if the DBMS is being used over a network.  \\n \\nData:  Perhaps the most important component of the DBMS environment certainly from the end-usersâ€™ point \\nof view is the data. The data acts as a bridge between the machine and the human components.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Procedures: Procedures refer to the instructions and rules that govern the design and use of the database. \\nThe users of the system and the staff who manage the database require documented procedures on how to \\nuse or run the system. \\n \\nPeople: The final component is the people involved with the system.  \\n \\nDatabase Architecture:\\n \\n \\nData model: An integrated collection of concepts for describing and manipulating data, relationships between \\ndata, and constraints on the data in an organization. A model is a representation of real -world objects and \\nevents, and their associations.\\nA data model can be thought of as comprising three components: \\n(1) a structural part, consisting of a set of rules according to which databases can be constructed; \\n(2) a manipulative part, defining the  types of operation that are allowed on the data (updating or \\nretrieving data from the database and changing the structure of the database);'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='(2) a manipulative part, defining the  types of operation that are allowed on the data (updating or \\nretrieving data from the database and changing the structure of the database); \\n(3) a set of integrity constraints, which ensures that the data is accurate.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Types of Data Model: \\n(1) an external data model, to represent each userâ€™s view of the organization, sometimes called the \\nUniverse of Discourse (UoD); \\n(2) a conceptual data model, to represent the logical (or community) view that is DBMS-independent; \\n(3) an int ernal data model, to represent the conceptual schema in such a way that it can be \\nunderstood by the DBMS \\n \\nObject-based data models use concepts such as entities, attributes, and relationships. \\nIn a record-based model, the database consists of a number of f ixed-format records, possibly of differing \\ntypes. Each record type defines a fixed number of fields, typically of a fixed length. There are three principal \\ntypes of record -based logical data model: the relational data model, the network data model, and the  \\nhierarchical data model.  \\nThe relational data model is based on the concept of mathematical relations. In the relational model, data'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='hierarchical data model.  \\nThe relational data model is based on the concept of mathematical relations. In the relational model, data \\nand relationships are represented as tables, each of which has a number of columns with a unique name. \\nIn the network model, data is represented as collections of records, and relationships are represented by \\nsets.  \\n \\nThe hierarchical model is a restricted type of network model. Again, data is represented as collections of \\nrecords and relationships are represented by sets.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='Physical data models describe how data is stored in the computer, representing information such as record \\nstructures, record orderings, and access paths. There are not as many physical data models as logical data \\nmodels; the most common ones are the unifying model and the frame memory.\\n \\nConceptual modeling or conceptual database design  is the process  of constructing a model of the \\ninformation use in an enterprise that is independent of implementation details, such as the target DBMS, \\napplication programs, programming languages, or any other physical considerations.\\n \\nFunctions of a DBMS \\n \\n(1) Data storage, retrieval, and update: A DBMS must furnish users with the ability to store, retrieve, and \\nupdate data in the database \\n \\n(2) A user-accessible catalog: A DBMS must furnish a catalog in which descriptions of data items are stored \\nand which is accessible to users.\\n(3) Transaction support: A DBMS must furnish a mechanism that will ensure either that all the updates'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='and which is accessible to users.\\n(3) Transaction support: A DBMS must furnish a mechanism that will ensure either that all the updates \\ncorresponding to a given transaction are made or that none of them is made\\n(4) Concurrency control services: A DBMS must furnish a mechanism to ensure that the database is updated \\ncorrectly when multiple users are updating the database concurrently.\\n(5) Recovery services: A DBMS must furnish a mechanism for recovering the database in the event that the \\ndatabase is damaged in any way. \\n(6) Authorization services: A DBMS must furnish a mechanism to ensure that only authorized users can \\naccess the database.\\n \\n(7) Support for data communication: A DBMS must be capable of integrating with communication software. \\n(8) Integrity services: A DBMS must furnish a means to ensure that both the data in the database and \\nchanges to the data follow certain rules.'),\n",
       " Document(metadata={'producer': 'MicrosoftÂ® Word 2013', 'creator': 'MicrosoftÂ® Word 2013', 'creationdate': '2022-04-04T23:50:27-07:00', 'author': 'TERMINAL', 'moddate': '2022-04-04T23:50:27-07:00', 'source': '..\\\\data\\\\PDF\\\\DBMS.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7', 'source_file': 'DBMS.pdf', 'file_type': 'pdf'}, page_content='(8) Integrity services: A DBMS must furnish a means to ensure that both the data in the database and \\nchanges to the data follow certain rules. \\n \\n(9) Services to promote data independence: A DBMS must include facilities to support the independence of \\nprograms from the actual structure of the database.\\n(10) Utility services: A DBMS should provide a set of utility services like backup, restore, etc.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 0, 'page_label': '1', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Introduction to Machine Learning \\n \\n \\nMachine learning is a method of data analysis that automates analytical \\nmodel building. It is a branch of artificial intelligence based on the idea that \\nsystems can learn from data,  identify patterns and make decisions with minimal \\nhuman intervention. \\nExample: Image recognition, Speech recognition, Medical diagnosis, Statistical \\narbitrage, Predictive analytics, etc. \\n \\n Artificial Intelligence, Machine Learning and Deep Learning \\n \\n\\uf0b7 Artificial Intelligence is defined as a program that exhibits cognitive \\nability similar to  that of a human being. It makes computers think like \\nhumans and solve problems the  way we do is one  of the main tenets of \\nartificial intelligence. \\n\\uf0b7 Any computer program that shows characteristi cs, such as self -\\nimprovement, learning  through inference, or even basic human tasks, \\nsuch as image recognition and language  processing, is considered to be a  \\nform of AI.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 0, 'page_label': '1', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='improvement, learning  through inference, or even basic human tasks, \\nsuch as image recognition and language  processing, is considered to be a  \\nform of AI. \\n\\uf0b7 The field of artificial intelligence includes within it the sub -fields of \\nmachine learning and deep learning. \\n\\uf0b7 Deep Learning is a more specialized version of machine learning that \\nutilizes more complex methods for difficult problems.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 2, 'page_label': '3', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Definition of machine learning \\nArthur Samuel, an early American leader in the field of  computer gaming and \\nartificial intelligence, coined the  term â€œMachine Learningâ€  in 1959  while at \\nIBM. \\nHe defined machine learning as â€œthe field of study that gives computers the \\nability to learn  without being explicitly programmed.â€ However, there is no \\nuniversally accepted definition  for machine learning. Different authors define \\nthe term differently. We give below two more definitions. \\n1. Machine learning is programming computers to optimize a performance \\ncriterion using example data or past experience. We have a model defined up to \\nsome parameters, and learning is the execution of a computer program to \\noptimize the parameters of the model using the  training data or past experience. \\nThe model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 2, 'page_label': '3', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question \\nof how to  construct computer programs that automatically improve  with \\nexperience \\n \\n Definition of learning \\nA computer program is said to learn from experience E with respect to some \\nclass of tasks T  and performance measure P, if its performance at tasks T, as \\nmeasured by P, improves with experience E. \\n \\nExamples : \\ni) Handwriting recognition learning problem \\nâ€¢ Task T: Recognising and classifying handwritten words within images \\nâ€¢ Performance P: Percent of words correctly classified \\nâ€¢ Training experience E: A dataset of handwritten words with given classifications'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 3, 'page_label': '4', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='ii) A robot driving learning problem \\nâ€¢ Task T: Driving on highways using vision sensors'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 4, 'page_label': '5', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='â€¢ Performance measure P: Average distance traveled before an error \\nâ€¢ training experience: A sequence of images and steering commands recorded \\nwhile observing a human driver \\n \\niii) A chess learning problem \\nâ€¢ Task T: Playing chess \\nâ€¢ Performance measure P: Percent of games won against opponents \\nâ€¢ Training experience E: Playing practice games against itself \\n \\n \\nDefinition: A computer program which learns from experience is called a \\nmachine learning  program or simply a learning program. Such a program i s \\nsometimes also referred to as a learner. \\nBasic components of learning process \\nThe learning process, whether by a human or a machine, can be divided into four \\ncomponents, namely, data storage, abstraction, generalization and evaluation. \\nFigure 1.1 illustrates the  various components and  the steps involved in the  \\nlearning process. \\n \\n1. Data storage \\n \\n \\nFacilities for storing and retrieving huge amounts of data are an important'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 4, 'page_label': '5', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Figure 1.1 illustrates the  various components and  the steps involved in the  \\nlearning process. \\n \\n1. Data storage \\n \\n \\nFacilities for storing and retrieving huge amounts of data are an important \\ncomponent of the  learning process. Humans and computers alike utilize data \\nstorage as a foundation for advanced reasoning. \\nâ€¢ In a human being, the data is stored in the brain and data is retrieved using \\nelectrochemical signals. \\nâ€¢ Computers use hard disk drives, flash memory, random access memory and \\nsimilar devices  to store data and use cables and other  technology to retrieve'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 5, 'page_label': '6', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='data.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 6, 'page_label': '7', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='2. Abstraction \\n \\n \\nThe second component of the learning process is known as abstraction. \\nAbstraction is the  process of extracting knowledge about stored data. This \\ninvolves creating general concepts about the data as a whole. The creation of \\nknowledge involves application of known models  and creation of new models. \\nThe process of fitting a model to a dataset is known as training.  When the model \\nhas been trained, the data is transformed into an abstract form that summarizes the \\noriginal information. \\n \\n3. Generalization \\n \\n \\nThe third component of the learning process is known as generalisation. The \\nterm generalization describes the process of turning the knowledge about stored \\ndata into a form that can be utilized for future action. These actions are to be \\ncarried out on tasks that are similar,  but not identical, to those what have been \\nseen before. In generalization, the goal is to discover those properties of the data \\nthat will be most relevant to future tasks.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 6, 'page_label': '7', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='seen before. In generalization, the goal is to discover those properties of the data \\nthat will be most relevant to future tasks. \\n \\n4. Evaluation \\n \\n \\nEvaluation is the last component of the learning process. It is the process of \\ngiving feedback to the user to measure the utility of the learned knowledge. This \\nfeedback is then utilised to effect improvements in the whole learning process. \\n \\n        Applications of machine learning \\nThe following is a list of some of the typical applications of machine learning. \\n1. In retail business, machine learning is used to study consumer behaviour.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 7, 'page_label': '8', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='2. In finance, banks analyze their past data to build models to use in credit \\napplications, fraud detection, and the stock market. \\n3. In manufacturing, learning models are used for optimization, control, and troubleshooting. \\n4. In medicine, learning programs are used for medical diagnosis. \\n5. In telecommunications, call patterns are analyzed for network optimization \\nand maximizing the quality of service.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 8, 'page_label': '9', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='6. In science, large amounts of data in physics, astronomy, and biology can only \\nbe analyzed  fast enough by computers. The World Wide Web is huge; it is \\nconstantly growing and searching for relevant information  cannot be done \\nmanually. \\n7. In artificial intelligence, it is used to teach a system to learn and adapt to \\nchanges so that the system designer need  not foresee and provide solutions for \\nall possible situations. \\n8. It is used to find solutions to many problems in vision, speech recognition, and robotics. \\n9. Machine learning methods are applied in the design of computer-controlled \\nvehicles to steer correctly when driving on a variety of roads. \\n10. Machine learning methods have been used to develop programmes for \\nplaying games such as chess, backgammon and Go. \\n \\n Statistics vs Machine Learning \\n \\n \\nThe major difference between  machine learning and statistics is their purpose.  \\nMachine learning models are designed to make the most accurate predictions'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 8, 'page_label': '9', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Statistics vs Machine Learning \\n \\n \\nThe major difference between  machine learning and statistics is their purpose.  \\nMachine learning models are designed to make the most accurate predictions \\npossible. Statistical models are designed for  inference about the  relationships \\nbetween variables \\n1. Machine Learning is an algorithm that can learn from data without \\nrelying on rules- based programming. \\nStatistical modeling is a formalization of relationships between variables \\nin the data in the form of mathematical equations. \\n2. Machine learning is all about predictions, supervised learning, \\nunsupervised learning, etc. \\nStatistics is about sample, population, hypothesis, etc. \\n \\n3. Machine learning is a subfield of computer science and artificial \\nintelligence. It deals  with building systems that can learn from data, \\ninstead of explicitly programmed instructions.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 9, 'page_label': '10', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='A statistical model, on the other hand, is a subfield of mathematics. \\n4. Machine Learning is automated and requires less human intervention and \\nit deals with large datasets. \\nStatistics require a lot of human effort and deals with small datasets.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 10, 'page_label': '11', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Types of Machine Learning Algorithms: \\n \\nThese are three types of machine learning:  \\n \\n1. Supervised Learning \\n2. Unsupervised Learning \\n3. Reinforcement Learning \\n \\n \\n \\n \\n Supervised Learning: \\n \\n \\n\\uf0b7 Supervised learning is one of the most basic types of machine learning. \\n\\uf0b7 In this type, the machine learning algorithm is trained on labelled data. \\n\\uf0b7 In supervised learning, the ML algorithm is given a small training dataset to work \\nwith. \\n\\uf0b7 This training dataset is a smaller part of the bigger dataset and \\nserves to give the    algorithm a basic idea of the problem, solution, and \\ndata points to be dealt with. \\n\\uf0b7 At the end of the training, the algorithm has an idea of how the data'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 11, 'page_label': '12', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='works and the relationship between the input and the output. \\n\\uf0b7 Example: Risk Assessment, Image classification, Fraud Detection, spam filtering, \\netc. \\n \\n   How Supervised Learning Works? \\n \\nIn supervised learning, models are trained using labelled dataset, where the \\nmodel learns about each type of data. Once the training process is completed, the \\nmodel is tested on the basis of  test data (a subset of the training set), and then it \\npredicts the output. \\n \\nSuppose we have a dataset of different types of shapes which inclu des square, \\nrectangle, triangle, and Polygon. Now the first step is that we need to train the \\nmodel for each shape. \\n \\no If the given shape has four sides, and all the sides are equal, then it will \\nbe labelled as a Square. \\no If the given shape has three sides, then it will be labelled as a triangle. \\no If the given shape has six equal sides, then it will be labelled as hexagon. \\n \\nNow, after training, we test our model using the test set, and the task of the'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 11, 'page_label': '12', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='o If the given shape has six equal sides, then it will be labelled as hexagon. \\n \\nNow, after training, we test our model using the test set, and the task of the \\nmodel is to identify the shape. The machine is already trained on all types of \\nshapes, and when it finds a new shape, it classifies the shape  on the bases of a \\nnumber of sides, and predicts the output.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 13, 'page_label': '14', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Advantages of Supervised learning: \\no With the help of supervised learning, the model can predict the output on \\nthe basis of prior experiences. \\no In supervised learning, we can have an exact idea about the classes of objects. \\n \\nDisadvantages of supervised learning: \\no Supervised learning models are not suitable for handling the complex tasks. \\no Supervised learning cannot predict the correct output if the test data is \\ndifferent from the training dataset. \\no Training required lots of computation times. \\n \\n Unsupervised Learning: \\n \\n\\uf0b7 Unsupervised machine learning holds the advantage of being able to work with \\nunlabelled data. \\n\\uf0b7 This means that human labour is not required to make the dataset \\nmachine-readable, allowing much larger datasets to be  worked on by  \\nthe program. \\n\\uf0b7 This offers more post-deployment development than supervised learning algorithms. \\n\\uf0b7 Example : Principal Component Analysis, Clustering \\n \\nHow Unsupervised Learning Works?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 14, 'page_label': '15', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=\"Here, we have taken an unlabelled input data, which \\nmeans it is not categorized and corresponding outputs \\nare also not given.  \\nNow, this unlabelled input data is fed to the machine \\nlearning model in order to train it. \\nFirstly, it will interpret the raw data  to find the hidden  \\npatterns from the data and then will apply suitable \\nalgorithms such as k-means clustering,  Decision tree, \\netc.  \\nOnce it applies the suitable algorithm, the algorithm \\ndivides the data objects into groups according to  the \\nsimilarities and difference between the objects. \\n \\nAdvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is used for more complex \\ntasks as compared to supervised learning because, \\nin unsupervised learning, we don't have labelled \\ninput data. \\n\\uf0b7 Unsupervised learning is preferable as it is easy to \\nget unlabelled data in comparison to labelled data. \\n \\nDisadvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is intrinsically more difficult\"),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 14, 'page_label': '15', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='get unlabelled data in comparison to labelled data. \\n \\nDisadvantages of Unsupervised Learning \\n\\uf0b7 Unsupervised learning is intrinsically more difficult \\nthan supervised learning as it does not have \\ncorresponding output.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 15, 'page_label': '16', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='\\uf0b7 The result of the unsupervised learning algorithm \\nmight be less accurate as input data is not labelled, \\nand algorithms do not know the exact output in \\nadvance. \\n \\n Semi-Supervised learning \\nSemi-supervised learning bridges supervised learning \\nand unsupervised learning techniques  to solve their \\nkey challenges. With it, you train an initial model on a \\nfew labeled samples and then iteratively apply it to the  \\ngreater number of unlabeled data. \\n \\nâ€¢ SSL works for a variety of problems from \\nclassification and  regression to clustering  and \\nassociation. \\nâ€¢ uses small amounts of labeled data and also large  \\namounts of unlabeled data, which reduces expenses on \\nmanual annotation and cuts data preparation time. \\n \\nWorking of Semi-Supervised Learning \\nSemi-supervised learning uses pseudo labeling to train the \\nmodel with less labeled training data than supervised \\nlearning. The process can combine various neural network \\nmodels and training ways.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 15, 'page_label': '16', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Semi-supervised learning uses pseudo labeling to train the \\nmodel with less labeled training data than supervised \\nlearning. The process can combine various neural network \\nmodels and training ways. \\nâ€¢ Firstly, it trains the model with less amount of \\ntraining data similar to the supervised learning \\nmodels. The training continues until the model gives'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 16, 'page_label': '17', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='accurate results. \\nâ€¢ The input data in labeled training data and unlabeled training \\ndata are also linked. \\nâ€¢ In the end, again train the model with the new \\ncombined input . \\nâ€¢ It will reduce errors and improve the accuracy of \\nthe model. \\n \\nSemi-supervised learning models applications \\no Speech Analysis \\no Web content classification \\no Text document classifier \\n \\n Reinforcement Learning \\n It is a part of ML where an agent is put in an \\nenvironment and he learns to behave in this \\nenvironment by performing certain actions and \\nobserving the rewards which it gets from those \\nactions. \\nFavourable outputs are encouraged or  â€˜reinforcedâ€™, \\nand non -favourable outputs  are discouraged or  \\nâ€˜punishedâ€™. \\n\\uf0b7 In every iteration of the algorithm, the output \\nresult is given to the interpreter, which  decides \\nwhether the outcome is favourable or not. \\n\\uf0b7 In case of the program finding the correct'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 17, 'page_label': '18', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='solution, the interpreter reinforces the solution by \\nproviding a reward to the algorithm.  \\n\\uf0b7 If the outcome is not favourable, the algorithm  is \\nforced to reiterate until it finds a better result.  \\n\\uf0b7 In most cases, the reward system is  directly tied to \\nthe effectiveness of the result. \\n\\uf0b7 In typical reinforcement learning use -cases, such \\nas finding the shortest route between  two points \\non a map. The higher this percentage value is,  the \\nmore reward is given to the algorithm. \\n\\uf0b7 Thus, the program is trained to give the best \\npossible solution for the best possible reward. \\nReinforcement Learning Applications'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 20, 'page_label': '21', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Difference Between Supervised, Unsupervised and Reinforcement \\nLearning'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 21, 'page_label': '22', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Types of Reinforcement learning \\n \\nThere are mainly two types of reinforcement learning, which are: \\n \\n\\uf0b7 Positive Reinforcement \\nThe positive reinforcement learning means \\nadding something to increase the tendency that expected \\nbehaviour would occur again. It impacts positively on \\nthe behaviour of the agent and increases the strength of \\nthe behaviour. This type of reinforcement can sustain the \\nchanges for a long time, but too much positive \\nreinforcement may lead to an overload of  states that can \\nreduce the consequences. \\n \\n\\uf0a7 Negative Reinforcement: \\nThe negative reinforcement learning is \\nopposite to the positive reinforcement as it increases the \\ntendency that the specific behaviour will occur again by \\navoiding the negative \\ncondition. It can be more effective than the positive \\nreinforcement depending on situation and behaviour, but it \\nprovides reinforcement only to meet minimum behaviour.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 22, 'page_label': '23', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='ML  Understanding Hypothesis \\n \\nIn most supervised machine learning algorithm, our main goal is to find \\nout a possible hypothesis from the hypothesis space that could \\npossibly map out the inputs to the proper outputs. \\nThe following figure shows the common method to find out the possible \\nhypothesis from the Hypothesis space: \\n \\n \\nHypothesis Space (H): \\nHypothesis space is the set of all the possible legal hypothesis. This is \\nthe set from which the machine learning algorithm would determine the \\nbest possible (only one) which would best describe the target function or \\nthe outputs. \\nHypothesis (h): \\nA hypothesis is a function that best describes the target in supervised'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 23, 'page_label': '24', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='machine learning. The hypothesis that an algorithm would come up \\ndepends upon the data and also depends upon the restrictions and \\nbias that we have imposed on the data. To better understand the \\nHypothesis Space and Hypothesis consider the following coordinate that \\nshows the distribution of some data:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 24, 'page_label': '25', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Say suppose we have test data for which we have to determine the \\noutputs or results. The test data is as shown below:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 25, 'page_label': '26', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='We can predict the outcomes by dividing the coordinate as shown \\nbelow:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 26, 'page_label': '27', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='So the test data would yield the following result: \\n \\nBut note here that we could have divided the coordinate plane as:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 27, 'page_label': '28', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The way in which the coordinate would be divided depends on the data, \\nalgorithm and constraints. \\n  All these legal possible ways in which we can divide the coordinate \\nplane to predict the outcome of the test data composes of the \\nHypothesis Space. \\n  Each individual possible way is known as the hypothesis. \\nHence, in this example the hypothesis space would be like:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 29, 'page_label': '30', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Hypothesis Testing in statistics \\n \\nHypothesis are statement about the given problem. \\n Hypothesis testing is a statistical method that is used in making a \\nstatistical decision using experimental data. \\n Hypothesis testing is basically an assumption that we make about a \\npopulation parameter. It evaluates two mutually exclusive statements \\nabout a population to determine which statement is best supported by the \\nsampledata    \\nExample: \\nYou say an average student in the class is 30  or a boy is taller than \\ngirls. All those are an example in which we assume or need some \\nstatistic way to prove those. We need some mathematical conclusion \\nwhatever we are assuming is true. \\nNeed for Hypothesis Testing \\nHypothesis testing is an important procedure in statistics. Hypothesis \\ntesting evaluates two mutually exclusive population statements to \\ndetermine which statement is most supported by sample data. When we \\nsay that the findings are statistically significant.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 29, 'page_label': '30', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='testing evaluates two mutually exclusive population statements to \\ndetermine which statement is most supported by sample data. When we \\nsay that the findings are statistically significant. \\n \\nParameters of hypothesis testing \\n \\n\\uf0b7 Null hypothesis(H0):  In statistics, the null hypothesis is a general \\ngiven statement or default position that there is no relationship \\nbetween two measured cases or no relationship among groups.  \\nIn other words, it is a basic assumption or made based on the problem \\nknowledge. \\n\\uf0b7 This hypothesis is either rejected or not rejected based on the \\nviability of the given   population or sample . \\nExample: A company production is = 50 unit/per day etc. \\n\\uf0b7 Alternative hypothesis(H1):  The alternative hypothesis is the \\nhypothesis used in hypothesis testing that is contrary to the null \\nhypothesis.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 30, 'page_label': '31', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Example : A company production is not equal to 50 unit/per day etc. \\n\\uf0b7 Level of significance \\nIt refers to the degree of significance in which we accept or reject the \\nnull-hypothesis. 100% accuracy is not possible for accepting a \\nhypothesis, so we, therefore, select a level of significance that is \\nusually 5%. This is normally denoted with and generally, it is 0.05 or \\n5%, which means your output should be 95% confident(significance \\nlevel is accepted) to give similar kind of result in each sample. \\n\\uf0b7 P-value \\nThe P value, or calculated probability, is the probability of finding the \\nobserved/extreme results when the  null hypothesis(H0) of a study \\ngiven problem is true.  \\n-If your P-value is less than the chosen significance level then you \\nreject the null hypothesis i.e. accept that your sample claims to \\nsupport the alternative hypothesis. \\n-P-Value is a statistical measure, that helps to determine whether \\nthe hypothesis is correct or not. \\nExample :'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 30, 'page_label': '31', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='support the alternative hypothesis. \\n-P-Value is a statistical measure, that helps to determine whether \\nthe hypothesis is correct or not. \\nExample : \\nGiven a coin and it is not known whether that is fair or tricky so letâ€™s \\ndecide null and alternate hypothesis \\n\\uf0b7 Null Hypothesis(H0): a coin is a fair coin. \\n\\uf0b7 Alternative Hypothesis(H1) : a coin is a tricky coin. \\n \\nNow letâ€™s toss the coin and calculate p-value (probability value). \\n\\uf0b7 Toss a coin 1st time and assume that result is head- P-value =50  (as \\nhead and tail have equal probability) \\n\\uf0b7 Toss a coin 2nd time and assume that result again is head, now p-\\nvalue = (1/2) * 50 ==50/2= 25 \\nError in Hypothesis Testing \\n\\uf0b7 Type I error: When we reject the null hypothesis, although that \\nhypothesis was true. Type I error is denoted by alpha. \\n\\uf0b7 Type II errors: When we accept the null hypothesis but it is false. \\nType II errors are denoted by beta.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 31, 'page_label': '32', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='What is Generalization in Machine Learning? \\nDefinition of generalization \\nIn machine learning, generalization is a definition to demonstrate how \\nwell is a trained model to classify or forecast unseen data.  \\nAn example is when we train a model to classify between dogs and \\ncats. If the model is provided with dogs images dataset with only two \\nbreeds, it may obtain a good performance.  \\nBut, it possibly gets a low classification score when it is tested by other \\nbreeds of dogs as well.  \\nTherefore, data diversity (decrease redundancy) is very important factor \\nin order to make a good prediction. In the sample above, the model may  \\nobtain 85% performance score when it is tested by only two dog breeds \\nand gains 70% if trained by all breeds. \\n However, the first possibly gets a very low score (e.g. 45%) if it is \\nevaluated by an unseen dataset with all breed dogs. This for the latter \\ncan be unchanged given than it has been trained by high data diversity'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 31, 'page_label': '32', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='evaluated by an unseen dataset with all breed dogs. This for the latter \\ncan be unchanged given than it has been trained by high data diversity \\nincluding all possible breeds. \\nIt should be taken into account that data diversity is not the only point to \\ncare in order to have a generalized model.  \\nIn this post we explain all determinant factors. There are some \\nmethods (regularization) to apply during model training to ensure \\nabout generalization. But before, we explain bias and variance as \\nwell as underfitting and overfitting. \\nVariance and bias (overfitting and underfitting) \\nVariance and bias are two important terms in machine learning.  \\nVariance means the variety of predictions values  made by a machine \\nlearning model (target function). (Variance describes how much a \\nrandom variable differs from its expected value. )'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 32, 'page_label': '33', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Bias means the distance of the predictions from the actual (true) target \\nvalues (bias is the amount that a modelâ€™s prediction differs from the \\ntarget value, compared to the training data. ) \\n A high -biased model means its prediction values (average) are far \\nfrom the actual values. (High bias would cause an algorithm to miss \\nrelevant relations between the input features and the target outputs. This \\nis sometimes referred to as underfitting.) \\nAlso, high-variance prediction means the prediction values are highly \\nvaried.(  a model that tries to fit most of the training dataset points making it \\ncomplex) \\nVariance-bias trade-off \\nThe prediction results of a machine learning model stand somewhere \\nbetween \\na) low-bias, low-variance,  \\nb) low-bias, high-variance (overfit) \\nc) high-bias, low-variance, and  \\nd) high-bias, high-variance.(underfit) \\n \\nA low-biased, high-variance model is called overfit and a high -biased, \\nlow-variance model is called underfit.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 32, 'page_label': '33', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='c) high-bias, low-variance, and  \\nd) high-bias, high-variance.(underfit) \\n \\nA low-biased, high-variance model is called overfit and a high -biased, \\nlow-variance model is called underfit.  \\nBy generalization, we find the best trade -off between underfitting and \\noverfitting so that a trained model obtains the best performance. \\n An overfit model obtains a  high prediction score on seen data and low \\none from unseen datsets. (data new to the model that was not part of the \\ntraining. ) \\nAn underfit model has low performance in both seen and unseen \\ndatasets.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 33, 'page_label': '34', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Three models with underfitting (left), goodfit ( middle), and overfitting \\n(right). Credit: https://scikit -learn.org/\\nOverfitting/overtraining in supervised learning (e.g., neural network). \\nTraining error is shown in blue, validation error in red, both as a \\nfunction of the number of training cycles. I f th e validation error \\nincreases(positive slope) while the training error steadily \\ndecreases(negative slope) then a situation of overfitting may have'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 34, 'page_label': '35', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='occurred. The best predictive and fitted model would be where the \\nvalidation error has its global minimum.  \\nDeterminant factors to train generalized models \\nThere are different ways to secure that a machine learning model is \\ngeneralized. Below we explain them. \\nDataset \\nIn order to train a classifier and generate a generalized machine learning \\nmodel, a used dataset should contain diversity. It should be noted that it \\ndoesnâ€™t mean a huge dataset but a dataset containing all different \\nsamples. This helps classifier to be trained not only from a specific \\nsubset of data and therefore, the generalization is better fulfil led. In \\naddition, during training, it is recommended to use  \\ncross validation techniques such as K -fold or Monte -Carlo cross \\nvalidations. These techniques better secure to exploit all possible \\nportions of data and to avoid generating an overfit model. \\nMachine Learning algorithm \\nMachine learning algorithms differently act against overfitting,'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 34, 'page_label': '35', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='portions of data and to avoid generating an overfit model. \\nMachine Learning algorithm \\nMachine learning algorithms differently act against overfitting, \\nunderfitting. Overfitting is more likely with nonlinear, non -parametric \\nmachine learning algorithms. For instance, Decision Tree is a non -\\nparametric machine learning algorithms, meaning its model is more \\nlikely with overfitting.  On the other hand, some machine learning \\nmodels are too simple to capture complex underlying patterns in data. \\nThis cause to build an underfit model. Examples are linear and \\nlogistic regression. \\nModel complexity \\nWhen a machine learning models becomes too complex, it is usually \\nprone to overfitting. There are methods that help to make the model \\nsimpler. They are called Regularization methods. Following we explain \\nit.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 35, 'page_label': '36', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Regularization \\nRegularization i s collection of methods to make a machine learning \\nmodel simpler. To this end, certain approaches are applied to different \\nmachine learning algorithms, for instance, pruning for decision trees, \\ndropout techniques for neural networks (reduction in overfittin g), \\nand adding a penalty parameters to the cost function in Regression.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 37, 'page_label': '38', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Bias and Variance in Machine Learning \\n\\uf0b7 Machine learning is a branch of Artificial Intelligence, which allows machines to  \\nPerform data analysis and make predictions.  \\n\\uf0b7 However, if the machine learning model is not accurate, it can make predictions errors, \\n and these prediction errors are usually known as Bias and Variance. \\n\\uf0b7 In machine learning, these errors will always be present as there is always a slight  \\ndifference  between the model predictions and actual predictions.  \\n\\uf0b7 The main aim of ML/data science analysts is to reduce these errors in order to get more \\n accurate results. In this topic,  we are going to discuss bias and variance, Bias-variance \\n trade-off,  Underfitting  and Overfitting.  \\n \\n \\nwhat errors in Machine learning are?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 38, 'page_label': '39', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content=\"Errors in Machine Learning? \\nIn machine learning, an error is a measure of how accurately an algorithm can make  \\npredictions for the previously unknown dataset. On the basis of these errors, the machine \\n learning model is selected that can perform best on the particular dataset. There are mainly  \\ntwo types of errors in machine learning, which are: \\no Reducible errors: These errors can be reduced to improve the model accuracy.  \\nSuch errors can further be classified into bias and  Variance. \\no Irreducible errors: These errors will always be present in the model \\n   regardless of which algorithm has been used. The cause of these errors is unknown  \\n   variables whose value can't be reduced. \\no\"),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 39, 'page_label': '40', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='What is Bias? \\n  In general, a machine learning model analyses the data, find patterns in it and make \\n predictions.  \\n While training, the model learns these patterns in the dataset and applies them to test data \\n for prediction.  \\nWhile making predictions, a difference occurs between prediction values  \\nmade by the model and actual values/expected values, and this difference is known as \\n bias errors or Errors due to bias.  \\nIt can be defined as an inability of machine learning algorithms such as Linear  \\nRegression to capture the true relationship between the data points.  \\nEach algorithm begins with some amount of bias because bias occurs from assumptions'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 40, 'page_label': '41', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='in the model, which makes the target function simple to learn. A model has either: \\no Low Bias: A low bias model will make fewer assumptions about the form of the target  \\nfunction. \\no High Bias: A model with a high bias makes more assumptions, and the model  \\nbecomes unable to capture the important features of our dataset. A high bias model  \\nalso cannot perform well on new data. \\nGenerally, a linear algorithm has a high bias, as it makes them learn fast. The simpler the \\n algorithm, the higher the bias it has likely to be introduced. Whereas a nonlinear algorithm  \\noften has low bias. \\nSome examples of machine learning algorithms with low bias are Decision Trees,  \\nk-Nearest  Neighbours and Support Vector Machines. At the same time, an algorithm  \\nwith high bias  is Linear Regression, Linear Discriminant Analysis and Logistic \\n Regression. \\nWays to reduce High Bias: \\nHigh bias mainly occurs due to a much simple model. Below are some ways to reduce \\n the high bias:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 40, 'page_label': '41', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Regression. \\nWays to reduce High Bias: \\nHigh bias mainly occurs due to a much simple model. Below are some ways to reduce \\n the high bias: \\no Increase the input features as the model is underfitted. \\no Decrease the regularization term. \\no Use more complex models, such as including some polynomial features. \\nWhat is a Variance Error?'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 41, 'page_label': '42', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='The variance would specify the amount of variation in the prediction if the different training  \\ndata was used. In simple words, variance tells that how much a random variable is  \\ndifferent from its expected value. Ideally, a model should not vary too much from one  \\ntraining dataset to another, which means the algorithm should be good in understanding \\n the hidden mapping between inputs and output variables. Variance errors are either of  \\nlow variance or high variance. \\nLow variance means there is a small variation in the prediction of the target function with  \\nchanges in the training data set.  \\nAt the same time, High variance shows a large variation in the prediction of the target \\n function with changes in the training dataset. \\nA model that shows high variance learns a lot and perform well with the training dataset,  \\nand does not generalize well with the unseen dataset. As a result, such a model gives'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 41, 'page_label': '42', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='A model that shows high variance learns a lot and perform well with the training dataset,  \\nand does not generalize well with the unseen dataset. As a result, such a model gives  \\ngood results with the training dataset but shows high error rates on the test dataset. \\nSince, with high variance, the model learns too much from the dataset, it leads to overfitting  \\nof the model. A model with high variance has the below problems: \\no A high variance model leads to overfitting. \\no Increase model complexities. \\nUsually, nonlinear algorithms have a lot of flexibility to fit the model, have high variance.'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 42, 'page_label': '43', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='Some examples of machine learning algorithms with low variance are, Linear Regression,  \\nLogistic Regression, and Linear discriminant analysis. At the same time, algorithms with high  \\nvariance are decision tree, Support Vector Machine, and K-nearest neighbours. \\nWays to Reduce High Variance: \\no Reduce the input features or number of parameters as a model is overfitted. \\no Do not use a much complex model. \\no Increase the training data. \\no Increase the Regularization term. \\nDifferent Combinations of Bias-Variance \\nThere are four possible combinations of bias and variances, which are represented by the  \\nbelow diagram:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 43, 'page_label': '44', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='1. Low-Bias,LowVariance Low-Variance: \\nThe combination of low bias and low variance shows an ideal machine learning \\n model. However, it is not possible practically. \\n2. Low-Bias, High-Variance: With low bias and high variance, model predictions \\n are inconsistent and accurate on average. This case occurs when the model learns \\n with a large number of parameters and hence leads to an overfitting \\n3. High-Bias, Low-Variance: With High bias and low variance, predictions are  \\nconsistent but inaccurate on average. This case occurs when a model does not learn \\n well with the training dataset or uses few numbers of the parameter. It leads to \\n underfitting problems in the model. \\n4. HighBias,HighVariance  High-Variance:'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 44, 'page_label': '45', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='With high bias and high variance, predictions are inconsistent and also inaccurate \\non average. \\nHow to identify High variance or High Bias? \\nHigh variance can be identified if the model has: \\n \\no Low training error and high test error. \\nHigh Bias can be identified if the model has: \\no High training error and the test error is almost similar to training error. \\n \\n \\nBias-Variance Trade-Off \\nWhile building the machine learning model, it is really important to take care of bias and \\n variance in order to avoid overfitting and underfitting in the model. If the model \\nis very simple with fewer parameters, it may have low variance and high bias. Whereas,'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 45, 'page_label': '46', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='if the model has a large number of parameters, it will have high variance and low bias.  \\nSo, it is required to make a balance between bias and variance errors, and this balance  \\nbetween the bias error and variance error is known as the Bias-Variance trade-off. \\n \\nFor an accurate prediction of the model, algorithms need a low variance and low bias.  \\nBut this is not possible because bias and variance are related to each other: \\no If we decrease the variance, it will increase the bias. \\no If we decrease the bias, it will increase the variance. \\nBias-Variance trade-off is a central issue in supervised learning. Ideally, we need a model \\n that accurately captures the regularities in training data and simultaneously generalizes \\n well with the unseen dataset. Unfortunately, doing this is not possible simultaneously.  \\nBecause a high variance algorithm may perform well with training data, but it may lead to'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'MicrosoftÂ® Word 2016', 'creationdate': '2024-01-30T15:55:18+00:00', 'author': 'harini purushothaman', 'moddate': '2024-01-30T15:55:20+00:00', 'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf', 'total_pages': 47, 'page': 46, 'page_label': '47', 'source_file': 'ML Notes.pdf', 'file_type': 'pdf'}, page_content='overfitting to noisy data. Whereas, high bias algorithm generates a much simple model  \\nthat may not even capture important regularities in the data. So, we need to find a  \\nsweet spot between bias and variance to make an optimal model. \\nHence, the Bias-Variance trade-off is about finding the sweet spot to make a balance \\n between bias and variance errors.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5733c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 146 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:08<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape:(146, 384)\n",
      "Adding 146 documents to vector store...\n",
      "Successfully added 146 documents to vector store\n",
      "Total documents in collection:584\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embedding\n",
    "texts=[doc.page_content for doc in chunks ]\n",
    "\n",
    "## Generate the embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## Store in the vector database\n",
    "\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a310b",
   "metadata": {},
   "source": [
    "#### Retrieve Pipeline from VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de1cf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query based retrieval from the vetcor stores\"\"\"\n",
    "    def __init__(self,vector_store:VectorStore,embedding_manager=EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "\n",
    "        Args:\n",
    "           vetcor_store: Vector store containing document embeddings\n",
    "           embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "\n",
    "        self.vector_store=vector_store\n",
    "        self.embedding_manager=embedding_manager\n",
    "        \n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbe43d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x185c33641d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3065b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is machine learning'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 71.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape:(1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_0a6c28a6_92',\n",
       "  'content': 'Definition of machine learning \\nArthur Samuel, an early American leader in the field of  computer gaming and \\nartificial intelligence, coined the  term â€œMachine Learningâ€  in 1959  while at \\nIBM. \\nHe defined machine learning as â€œthe field of study that gives computers the \\nability to learn  without being explicitly programmed.â€ However, there is no \\nuniversally accepted definition  for machine learning. Different authors define \\nthe term differently. We give below two more definitions. \\n1. Machine learning is programming computers to optimize a performance \\ncriterion using example data or past experience. We have a model defined up to \\nsome parameters, and learning is the execution of a computer program to \\noptimize the parameters of the model using the  training data or past experience. \\nThe model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question',\n",
       "  'metadata': {'source_file': 'ML Notes.pdf',\n",
       "   'moddate': '2024-01-30T15:55:20+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'page_label': '3',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'author': 'harini purushothaman',\n",
       "   'doc_index': 92,\n",
       "   'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf',\n",
       "   'total_pages': 47,\n",
       "   'page': 2,\n",
       "   'creationdate': '2024-01-30T15:55:18+00:00',\n",
       "   'content_length': 996},\n",
       "  'similarity_score': 0.6278616786003113,\n",
       "  'distance': 0.3721383213996887,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_1f2680fb_92',\n",
       "  'content': 'Definition of machine learning \\nArthur Samuel, an early American leader in the field of  computer gaming and \\nartificial intelligence, coined the  term â€œMachine Learningâ€  in 1959  while at \\nIBM. \\nHe defined machine learning as â€œthe field of study that gives computers the \\nability to learn  without being explicitly programmed.â€ However, there is no \\nuniversally accepted definition  for machine learning. Different authors define \\nthe term differently. We give below two more definitions. \\n1. Machine learning is programming computers to optimize a performance \\ncriterion using example data or past experience. We have a model defined up to \\nsome parameters, and learning is the execution of a computer program to \\noptimize the parameters of the model using the  training data or past experience. \\nThe model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question',\n",
       "  'metadata': {'doc_index': 92,\n",
       "   'page_label': '3',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf',\n",
       "   'page': 2,\n",
       "   'creationdate': '2024-01-30T15:55:18+00:00',\n",
       "   'total_pages': 47,\n",
       "   'content_length': 996,\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'author': 'harini purushothaman',\n",
       "   'moddate': '2024-01-30T15:55:20+00:00',\n",
       "   'source_file': 'ML Notes.pdf',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.6278616786003113,\n",
       "  'distance': 0.3721383213996887,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_60d5a090_92',\n",
       "  'content': 'Definition of machine learning \\nArthur Samuel, an early American leader in the field of  computer gaming and \\nartificial intelligence, coined the  term â€œMachine Learningâ€  in 1959  while at \\nIBM. \\nHe defined machine learning as â€œthe field of study that gives computers the \\nability to learn  without being explicitly programmed.â€ However, there is no \\nuniversally accepted definition  for machine learning. Different authors define \\nthe term differently. We give below two more definitions. \\n1. Machine learning is programming computers to optimize a performance \\ncriterion using example data or past experience. We have a model defined up to \\nsome parameters, and learning is the execution of a computer program to \\noptimize the parameters of the model using the  training data or past experience. \\nThe model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question',\n",
       "  'metadata': {'file_type': 'pdf',\n",
       "   'content_length': 996,\n",
       "   'total_pages': 47,\n",
       "   'doc_index': 92,\n",
       "   'moddate': '2024-01-30T15:55:20+00:00',\n",
       "   'creationdate': '2024-01-30T15:55:18+00:00',\n",
       "   'source_file': 'ML Notes.pdf',\n",
       "   'page': 2,\n",
       "   'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'page_label': '3',\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'author': 'harini purushothaman'},\n",
       "  'similarity_score': 0.6278616786003113,\n",
       "  'distance': 0.3721383213996887,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_c1101c03_92',\n",
       "  'content': 'Definition of machine learning \\nArthur Samuel, an early American leader in the field of  computer gaming and \\nartificial intelligence, coined the  term â€œMachine Learningâ€  in 1959  while at \\nIBM. \\nHe defined machine learning as â€œthe field of study that gives computers the \\nability to learn  without being explicitly programmed.â€ However, there is no \\nuniversally accepted definition  for machine learning. Different authors define \\nthe term differently. We give below two more definitions. \\n1. Machine learning is programming computers to optimize a performance \\ncriterion using example data or past experience. We have a model defined up to \\nsome parameters, and learning is the execution of a computer program to \\noptimize the parameters of the model using the  training data or past experience. \\nThe model may be predictive to make predictions in the future, or descriptive to \\ngain knowledge from data, or both. \\n2. The field of study known as machine learning is concerned with the question',\n",
       "  'metadata': {'author': 'harini purushothaman',\n",
       "   'file_type': 'pdf',\n",
       "   'source_file': 'ML Notes.pdf',\n",
       "   'content_length': 996,\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'moddate': '2024-01-30T15:55:20+00:00',\n",
       "   'page_label': '3',\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'doc_index': 92,\n",
       "   'creationdate': '2024-01-30T15:55:18+00:00',\n",
       "   'page': 2,\n",
       "   'total_pages': 47,\n",
       "   'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf'},\n",
       "  'similarity_score': 0.6278616786003113,\n",
       "  'distance': 0.3721383213996887,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_6a568e47_90',\n",
       "  'content': 'Introduction to Machine Learning \\n \\n \\nMachine learning is a method of data analysis that automates analytical \\nmodel building. It is a branch of artificial intelligence based on the idea that \\nsystems can learn from data,  identify patterns and make decisions with minimal \\nhuman intervention. \\nExample: Image recognition, Speech recognition, Medical diagnosis, Statistical \\narbitrage, Predictive analytics, etc. \\n \\n Artificial Intelligence, Machine Learning and Deep Learning \\n \\n\\uf0b7 Artificial Intelligence is defined as a program that exhibits cognitive \\nability similar to  that of a human being. It makes computers think like \\nhumans and solve problems the  way we do is one  of the main tenets of \\nartificial intelligence. \\n\\uf0b7 Any computer program that shows characteristi cs, such as self -\\nimprovement, learning  through inference, or even basic human tasks, \\nsuch as image recognition and language  processing, is considered to be a  \\nform of AI.',\n",
       "  'metadata': {'content_length': 951,\n",
       "   'creationdate': '2024-01-30T15:55:18+00:00',\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'page': 0,\n",
       "   'moddate': '2024-01-30T15:55:20+00:00',\n",
       "   'source': '..\\\\data\\\\PDF\\\\ML Notes.pdf',\n",
       "   'total_pages': 47,\n",
       "   'author': 'harini purushothaman',\n",
       "   'source_file': 'ML Notes.pdf',\n",
       "   'doc_index': 90,\n",
       "   'file_type': 'pdf',\n",
       "   'page_label': '1',\n",
       "   'producer': 'www.ilovepdf.com'},\n",
       "  'similarity_score': 0.41869956254959106,\n",
       "  'distance': 0.5813004374504089,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3808c7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is K-Fold Cross-Validation '\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 52.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape:(1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_773df510_14',\n",
       "  'content': 'lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 We then get N separate pairs by leaving out a different instance at each \\niteration. \\n\\uf0b7 This is typically used in applications such as medical diagnosis, where \\nlabeled data is hard to find. \\n\\uf0b7  Leave-one-out does not permit stratification. Recently, with computation \\ngetting cheaper, it has also become possible to have multiple runs of K-fold \\ncross-validation, for example, 10Ã—10- fold, and use average over averages to \\nget more reliable error estimates \\n5Ã—2 Cross-Validation \\n\\uf0b7 Dietterich (1998) proposed the 5 Ã— 2 cross-validation, which uses training \\nand validation sets of equal size. \\n\\uf0b7 We divide the dataset X randomly into two parts, X(1) 1and X(2) 1, which gives \\nour first pair of training and validation sets, T1 = X(1) 1and V1 = X(2) 1. \\n\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we',\n",
       "  'metadata': {'page': 4,\n",
       "   'total_pages': 12,\n",
       "   'page_label': '5',\n",
       "   'doc_index': 14,\n",
       "   'file_type': 'pdf',\n",
       "   'moddate': '2024-01-30T16:08:48+00:00',\n",
       "   'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'creationdate': '2024-01-30T16:08:48+00:00',\n",
       "   'author': 'Lakshmanan Kathiresan',\n",
       "   'title': 'Untitled',\n",
       "   'source_file': 'Cross Validation.pdf',\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'content_length': 965},\n",
       "  'similarity_score': 0.24717235565185547,\n",
       "  'distance': 0.7528276443481445,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_513dffc3_14',\n",
       "  'content': 'lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 We then get N separate pairs by leaving out a different instance at each \\niteration. \\n\\uf0b7 This is typically used in applications such as medical diagnosis, where \\nlabeled data is hard to find. \\n\\uf0b7  Leave-one-out does not permit stratification. Recently, with computation \\ngetting cheaper, it has also become possible to have multiple runs of K-fold \\ncross-validation, for example, 10Ã—10- fold, and use average over averages to \\nget more reliable error estimates \\n5Ã—2 Cross-Validation \\n\\uf0b7 Dietterich (1998) proposed the 5 Ã— 2 cross-validation, which uses training \\nand validation sets of equal size. \\n\\uf0b7 We divide the dataset X randomly into two parts, X(1) 1and X(2) 1, which gives \\nour first pair of training and validation sets, T1 = X(1) 1and V1 = X(2) 1. \\n\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we',\n",
       "  'metadata': {'page': 4,\n",
       "   'doc_index': 14,\n",
       "   'moddate': '2024-01-30T16:08:48+00:00',\n",
       "   'author': 'Lakshmanan Kathiresan',\n",
       "   'content_length': 965,\n",
       "   'title': 'Untitled',\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'source_file': 'Cross Validation.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'total_pages': 12,\n",
       "   'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf',\n",
       "   'page_label': '5',\n",
       "   'creationdate': '2024-01-30T16:08:48+00:00'},\n",
       "  'similarity_score': 0.24717235565185547,\n",
       "  'distance': 0.7528276443481445,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_ec5b833c_14',\n",
       "  'content': 'lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 We then get N separate pairs by leaving out a different instance at each \\niteration. \\n\\uf0b7 This is typically used in applications such as medical diagnosis, where \\nlabeled data is hard to find. \\n\\uf0b7  Leave-one-out does not permit stratification. Recently, with computation \\ngetting cheaper, it has also become possible to have multiple runs of K-fold \\ncross-validation, for example, 10Ã—10- fold, and use average over averages to \\nget more reliable error estimates \\n5Ã—2 Cross-Validation \\n\\uf0b7 Dietterich (1998) proposed the 5 Ã— 2 cross-validation, which uses training \\nand validation sets of equal size. \\n\\uf0b7 We divide the dataset X randomly into two parts, X(1) 1and X(2) 1, which gives \\nour first pair of training and validation sets, T1 = X(1) 1and V1 = X(2) 1. \\n\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we',\n",
       "  'metadata': {'content_length': 965,\n",
       "   'creationdate': '2024-01-30T16:08:48+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'moddate': '2024-01-30T16:08:48+00:00',\n",
       "   'source_file': 'Cross Validation.pdf',\n",
       "   'total_pages': 12,\n",
       "   'page': 4,\n",
       "   'title': 'Untitled',\n",
       "   'page_label': '5',\n",
       "   'doc_index': 14,\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf',\n",
       "   'author': 'Lakshmanan Kathiresan'},\n",
       "  'similarity_score': 0.24717235565185547,\n",
       "  'distance': 0.7528276443481445,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_d5d63854_14',\n",
       "  'content': 'lOMoARcPSD|285 747 87 \\n \\n \\n\\uf0b7 We then get N separate pairs by leaving out a different instance at each \\niteration. \\n\\uf0b7 This is typically used in applications such as medical diagnosis, where \\nlabeled data is hard to find. \\n\\uf0b7  Leave-one-out does not permit stratification. Recently, with computation \\ngetting cheaper, it has also become possible to have multiple runs of K-fold \\ncross-validation, for example, 10Ã—10- fold, and use average over averages to \\nget more reliable error estimates \\n5Ã—2 Cross-Validation \\n\\uf0b7 Dietterich (1998) proposed the 5 Ã— 2 cross-validation, which uses training \\nand validation sets of equal size. \\n\\uf0b7 We divide the dataset X randomly into two parts, X(1) 1and X(2) 1, which gives \\nour first pair of training and validation sets, T1 = X(1) 1and V1 = X(2) 1. \\n\\uf0b7 Then we swap the role of the two halves and get the second pair: T2 = X(2) \\n1and V2 = X(1) 1. \\n\\uf0b7 This is the first fold; X(j) idenotes half j of fold i. To get the second fold, we',\n",
       "  'metadata': {'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'doc_index': 14,\n",
       "   'total_pages': 12,\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'title': 'Untitled',\n",
       "   'content_length': 965,\n",
       "   'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf',\n",
       "   'creationdate': '2024-01-30T16:08:48+00:00',\n",
       "   'source_file': 'Cross Validation.pdf',\n",
       "   'author': 'Lakshmanan Kathiresan',\n",
       "   'file_type': 'pdf',\n",
       "   'page_label': '5',\n",
       "   'moddate': '2024-01-30T16:08:48+00:00',\n",
       "   'page': 4},\n",
       "  'similarity_score': 0.24717235565185547,\n",
       "  'distance': 0.7528276443481445,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_b95b9380_12',\n",
       "  'content': 'prior probabilities; this is called stratification. \\n\\uf0b7 If a class has 20 percent examples in the whole dataset, in all samples  \\ndrawn from the dataset, it should also have approximately 20 percent \\nexamples. \\n5.3K-Fold Cross-Validation \\n\\uf0b7 K-fold In K-fold cross-validation, the dataset X is divided randomly into K \\nequalcross-validation sized parts, Xi, i = 1,...,K. \\n\\uf0b7 To generate each pair, we keep one of the K parts out as the validation set \\nand combine the remaining K âˆ’ 1 parts to form the training set. \\n\\uf0b7 Doing this K times, each time leaving out another one of the K parts out, we \\nget K pairs: V1 = X1 T1 = X2 ð–´ X3 ð–´Â·Â·Â·ð–´XK V2 = X2 T2 = X1 ð–´ X3 ð–´Â·Â·Â·ð–´XK . . . \\nVK = XK TK = X1 ð–´ X2 ð–´Â·Â·Â·ð–´XKâˆ’1 \\n\\uf0b7 There are two problems with this. First, to keep the training set large, we \\nallow validation sets that are small. \\n\\uf0b7 Second, the training sets overlap considerably, namely, any two training sets \\nshare K âˆ’ 2 parts. K is typically 10 or 30.',\n",
       "  'metadata': {'creationdate': '2024-01-30T16:08:48+00:00',\n",
       "   'source': '..\\\\data\\\\PDF\\\\Cross Validation.pdf',\n",
       "   'producer': 'www.ilovepdf.com',\n",
       "   'total_pages': 12,\n",
       "   'doc_index': 12,\n",
       "   'title': 'Untitled',\n",
       "   'page': 3,\n",
       "   'author': 'Lakshmanan Kathiresan',\n",
       "   'content_length': 946,\n",
       "   'page_label': '4',\n",
       "   'creator': 'MicrosoftÂ® Word 2016',\n",
       "   'moddate': '2024-01-30T16:08:48+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'source_file': 'Cross Validation.pdf'},\n",
       "  'similarity_score': 0.202508807182312,\n",
       "  'distance': 0.797491192817688,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What is K-Fold Cross-Validation \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a302809",
   "metadata": {},
   "source": [
    "Integration Vectordb Context pipeline with LLM Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c48bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple RAG pipeline with Groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "### Initialize the Groq LLM (set your GROQ_API_KEY in environment)\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"llama-3.1-8b-instant\",temperature=0.1,max_tokens=1024)\n",
    "\n",
    "## 2. Simple RAG function: retrieve context + generate response\n",
    "def rag_simple(query,retriever,llm,top_k=3):\n",
    "    ## retriever the context\n",
    "    results=retriever.retrieve(query,top_k=top_k)\n",
    "    context=\"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "    \n",
    "    ## generate the answwer using GROQ LLM\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "    response=llm.invoke([prompt.format(context=context,query=query)])\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fd9637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is dbms?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape:(1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBMS stands for Database Management System. It is a software component that manages and controls the organization's data, comprising the DBMS software itself, application programs, operating system, and network software if used over a network.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"What is dbms?\", rag_retriever, llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ff96c",
   "metadata": {},
   "source": [
    "#### Enhaced RAG Pipeline Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0901887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is database design'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape:(1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Database design is the process of constructing a model of the data used in an enterprise, which involves three stages: \n",
      "\n",
      "1. Conceptual Database Design: Constructing a model of the data used in an enterprise, independent of all physical considerations.\n",
      "2. Logical Database Design: Constructing a model of the data used in an enterprise based on a specific data model, but independent of a particular DBMS and other physical considerations.\n",
      "3. Physical Database Design: Producing a description of the implementation of the database on secondary storage, including base relations, file organizations, and indexes.\n",
      "\n",
      "This process is followed by DBMS Selection, which involves choosing an appropriate DBMS to support the database system.\n",
      "Sources: [{'source': 'Data Modelling.pdf', 'page': 3, 'score': 0.42769527435302734, 'preview': 'combining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design \\n \\nConceptual Database Design: The process of constructing a model of the data used in an enterprise, independent of all \\nphysical considerations. \\nLogical Database De...'}, {'source': 'Data Modelling.pdf', 'page': 3, 'score': 0.42769527435302734, 'preview': 'combining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design \\n \\nConceptual Database Design: The process of constructing a model of the data used in an enterprise, independent of all \\nphysical considerations. \\nLogical Database De...'}, {'source': 'Data Modelling.pdf', 'page': 3, 'score': 0.42769527435302734, 'preview': 'combining all parts together. \\nDatabase Design: \\n\\uf0b7 Conceptual Database Design \\n\\uf0b7 Logical Database Design \\n\\uf0b7 Physical Database Design \\n \\nConceptual Database Design: The process of constructing a model of the data used in an enterprise, independent of all \\nphysical considerations. \\nLogical Database De...'}]\n",
      "Confidence: 0.42769527435302734\n",
      "Context Preview: combining all parts together. \n",
      "Database Design: \n",
      "ï‚· Conceptual Database Design \n",
      "ï‚· Logical Database Design \n",
      "ï‚· Physical Database Design \n",
      " \n",
      "Conceptual Database Design: The process of constructing a model of the data used in an enterprise, independent of all \n",
      "physical considerations. \n",
      "Logical Database De\n"
     ]
    }
   ],
   "source": [
    "# Enhanced RAG Pipeline\n",
    "def rag_advanced(query,retriever,llm,top_k=5,min_score=0.2,return_context=False):\n",
    "    \"\"\"\n",
    "    RAG Pipeline with extra features:\n",
    "     - Return answer,sources,confidence score, and optionally full context.\n",
    "    \n",
    "    \"\"\"\n",
    "    results=retriever.retrieve(query,top_k=top_k,score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer':'No Relevant Context Found.','sources':[],'confidence':0.0,'context':''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context=\"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources=[{\n",
    "        'source': doc ['metadata'].get('source_file',doc['metadata'].get('source','unknown')),\n",
    "        'page':doc['metadata'].get('page','unknown'),\n",
    "        'score':doc['similarity_score'],\n",
    "        'preview':doc['content'][:300]+'...'\n",
    "    } for doc in results]\n",
    "    confidence=max([doc['similarity_score'] for doc in results])\n",
    "\n",
    "    # Generate answer\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion:{query}\\n\\nAnswer:\"\"\"\n",
    "    response=llm.invoke([prompt.format(context=context,query=query)])\n",
    "\n",
    "    output={\n",
    "        'answer':response.content,\n",
    "        'sources':sources,\n",
    "        'confidence':confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context']=context\n",
    "    return output\n",
    "# Example Usage\n",
    "result=rag_advanced(\"What is database design\",rag_retriever,llm,top_k=3,min_score=0.1,return_context=True) \n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182814f",
   "metadata": {},
   "source": [
    "#### Advanced RAG pipeline: Streaming,Citations,History,Summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2cd1109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is database planning'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 26.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape:(1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Streaming answer:\n",
      "Use the following context to answer the questions concisely.\n",
      "Context:\n",
      "should identify a particular task that the database system must support. The assumption is that if the database system \n",
      "supports the mission objectives, then the mission "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement should be met. \n",
      "Database planning should also include the development of standards that govern how data will be collected, how the \n",
      "format should be specified, what documentation will be needed, and how design and implementation should proceed. \n",
      "System Definition: \n",
      "Describes the scope and boundaries of the database system and the major user views.\n",
      "\n",
      "should identify a particular task that the database system must support. The assumption is that if the database system \n",
      "supports the mission objectives, then the mission statement should be met. \n",
      "Database planning should also include the development of standards that govern how data will be collected, how the \n",
      "format should be specified, what documentation will be needed, and how design and implementation should proceed. \n",
      "System Definition: \n",
      "Describes the scope and boundaries of the database system and the major user views.\n",
      "\n",
      "should identify a particular task that the database system must support. The assumption is that if the database system \n",
      "supports the mission objectives, then the mission statement should be met. \n",
      "Database planning should also include the development of standards that govern how data will be collected, how the \n",
      "format should be specified, what documentation will be needed, and how design and implementation should proceed. \n",
      "System Definition: \n",
      "Describes the scope and boundaries of the database system and the major user views.\n",
      "\n",
      "Question:what is database planning\n",
      "\n",
      "Answer:\n",
      "\n",
      "Final Answer: Database planning is the process of identifying the tasks a database system must support, developing standards for data collection and format, determining necessary documentation, and outlining the design and implementation procedures.\n",
      "\n",
      "Citations:\n",
      "[1] Data Modelling.pdf (page 0)\n",
      "[2] Data Modelling.pdf (page 0)\n",
      "[3] Data Modelling.pdf (page 0)\n",
      "Summary: Here is a 2-sentence summary:\n",
      "\n",
      "Database planning involves identifying the tasks a database system must support and developing standards for data collection and format. It also includes determining necessary documentation and outlining the design and implementation procedures for the database system.\n",
      "History: {'question': 'what is database planning', 'answer': 'Database planning is the process of identifying the tasks a database system must support, developing standards for data collection and format, determining necessary documentation, and outlining the design and implementation procedures.', 'sources': [{'source': 'Data Modelling.pdf', 'page': 0, 'score': 0.40647441148757935, 'preview': 'should identify a particular task that the database system must support. The assumption is that if the database system \\n...'}, {'source': 'Data Modelling.pdf', 'page': 0, 'score': 0.40647441148757935, 'preview': 'should identify a particular task that the database system must support. The assumption is that if the database system \\n...'}, {'source': 'Data Modelling.pdf', 'page': 0, 'score': 0.40647441148757935, 'preview': 'should identify a particular task that the database system must support. The assumption is that if the database system \\n...'}], 'summary': 'Here is a 2-sentence summary:\\n\\nDatabase planning involves identifying the tasks a database system must support and developing standards for data collection and format. It also includes determining necessary documentation and outlining the design and implementation procedures for the database system.'}\n"
     ]
    }
   ],
   "source": [
    "#Advance RAG pipeline\n",
    "from typing import List,Dict,Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self,retriever,llm):\n",
    "        self.retriever=retriever\n",
    "        self.llm=llm\n",
    "        self.history=[]\n",
    "    def query(self,question:str,top_k:int=5,min_score:float=0.2,stream:bool=False,summarize:bool=False) -> Dict[str,Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results=self.retriever.retrieve(question,top_k=top_k,score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer=\"No relevant context found.\"\n",
    "            sorces=[]\n",
    "            context=\"\"\n",
    "        else:\n",
    "            context=\"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]     \n",
    "            # Streaming answer simulation\n",
    "            prompt=f\"\"\"Use the following context to answer the questions concisely.\\nContext:\\n{context}\\n\\nQuestion:{question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0,len(prompt),80):\n",
    "                    print(prompt[i:i+80],end='',flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response=self.llm.invoke([prompt.format(context=context,question=question)])\n",
    "            answer=response.content     \n",
    "\n",
    "            # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"what is database planning\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
